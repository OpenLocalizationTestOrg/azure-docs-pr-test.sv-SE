---
title: "aaaKernels för Jupyter notebook i Spark-kluster i Azure HDInsight | Microsoft Docs"
description: "Läs mer om hello PySpark och PySpark3 Spark kärnor för Jupyter-anteckningsbok med Spark-kluster i Azure HDInsight."
keywords: "jupyter-anteckningsbok på spark jupyter spark"
services: hdinsight
documentationcenter: 
author: nitinme
manager: jhubbard
editor: cgronlun
tags: azure-portal
ms.assetid: 0719e503-ee6d-41ac-b37e-3d77db8b121b
ms.service: hdinsight
ms.custom: hdinsightactive,hdiseo17may2017
ms.workload: big-data
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 05/15/2017
ms.author: nitinme
ms.openlocfilehash: 560c944fe850c5753ac9fa90550b804f0c47d14c
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: sv-SE
ms.lasthandoff: 10/06/2017
---
# <a name="kernels-for-jupyter-notebook-on-spark-clusters-in-azure-hdinsight"></a><span data-ttu-id="ca48d-104">Kärnor för Jupyter notebook i Spark-kluster i Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="ca48d-104">Kernels for Jupyter notebook on Spark clusters in Azure HDInsight</span></span> 

<span data-ttu-id="ca48d-105">HDInsight Spark-kluster tillhandahåller kernlar som du kan använda med hello Jupyter notebook i Spark för att testa ditt program.</span><span class="sxs-lookup"><span data-stu-id="ca48d-105">HDInsight Spark clusters provide kernels that you can use with hello Jupyter notebook on Spark for testing your applications.</span></span> <span data-ttu-id="ca48d-106">En kernel är ett program som körs och tolkar din kod.</span><span class="sxs-lookup"><span data-stu-id="ca48d-106">A kernel is a program that runs and interprets your code.</span></span> <span data-ttu-id="ca48d-107">hello tre kärnor är:</span><span class="sxs-lookup"><span data-stu-id="ca48d-107">hello three kernels are:</span></span>

- <span data-ttu-id="ca48d-108">**PySpark** - för appar som skrivits i Python2</span><span class="sxs-lookup"><span data-stu-id="ca48d-108">**PySpark** - for applications written in Python2</span></span>
- <span data-ttu-id="ca48d-109">**PySpark3** - för appar som skrivits i Python3</span><span class="sxs-lookup"><span data-stu-id="ca48d-109">**PySpark3** - for applications written in Python3</span></span>
- <span data-ttu-id="ca48d-110">**Spark** - för program som skrivits i Scala</span><span class="sxs-lookup"><span data-stu-id="ca48d-110">**Spark** - for applications written in Scala</span></span>

<span data-ttu-id="ca48d-111">I den här artikeln får du lära dig hur toouse dessa kärnor och hello fördelarna med att använda dem.</span><span class="sxs-lookup"><span data-stu-id="ca48d-111">In this article, you learn how toouse these kernels and hello benefits of using them.</span></span>

## <a name="prerequisites"></a><span data-ttu-id="ca48d-112">Krav</span><span class="sxs-lookup"><span data-stu-id="ca48d-112">Prerequisites</span></span>

* <span data-ttu-id="ca48d-113">Ett Apache Spark-kluster i HDInsight.</span><span class="sxs-lookup"><span data-stu-id="ca48d-113">An Apache Spark cluster in HDInsight.</span></span> <span data-ttu-id="ca48d-114">Instruktioner finns i [skapa Apache Spark-kluster i Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="ca48d-114">For instructions, see [Create Apache Spark clusters in Azure HDInsight](hdinsight-apache-spark-jupyter-spark-sql.md).</span></span>

## <a name="create-a-jupyter-notebook-on-spark-hdinsight"></a><span data-ttu-id="ca48d-115">Skapa en Jupyter-anteckningsbok på Spark HDInsight</span><span class="sxs-lookup"><span data-stu-id="ca48d-115">Create a Jupyter notebook on Spark HDInsight</span></span>

1. <span data-ttu-id="ca48d-116">Från hello [Azure-portalen](https://portal.azure.com/), öppna ditt kluster.</span><span class="sxs-lookup"><span data-stu-id="ca48d-116">From hello [Azure portal](https://portal.azure.com/), open your cluster.</span></span>  <span data-ttu-id="ca48d-117">Se [listan och visa](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) hello-instruktioner.</span><span class="sxs-lookup"><span data-stu-id="ca48d-117">See [List and show clusters](hdinsight-administer-use-portal-linux.md#list-and-show-clusters) for hello instructions.</span></span> <span data-ttu-id="ca48d-118">hello kluster öppnas i ett nytt portalblad.</span><span class="sxs-lookup"><span data-stu-id="ca48d-118">hello cluster is opened in a new portal blade.</span></span>

2. <span data-ttu-id="ca48d-119">Från hello **snabblänkar** klickar du på **kluster instrumentpaneler** tooopen hello **kluster instrumentpaneler** bladet.</span><span class="sxs-lookup"><span data-stu-id="ca48d-119">From hello **Quick links** section, click **Cluster dashboards** tooopen hello **Cluster dashboards** blade.</span></span>  <span data-ttu-id="ca48d-120">Om du inte ser **snabblänkar**, klickar du på **översikt** hello vänstra menyn hello-bladet.</span><span class="sxs-lookup"><span data-stu-id="ca48d-120">If you don't see **Quick Links**, click **Overview** from hello left menu on hello blade.</span></span>

    <span data-ttu-id="ca48d-121">![Jupyter-anteckningsbok på Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Jupyter notebook i Spark")</span><span class="sxs-lookup"><span data-stu-id="ca48d-121">![Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/hdinsight-jupyter-notebook-on-spark.png "Jupyter notebook on Spark")</span></span> 

3. <span data-ttu-id="ca48d-122">Klicka på **Jupyter-anteckningsbok**.</span><span class="sxs-lookup"><span data-stu-id="ca48d-122">Click **Jupyter Notebook**.</span></span> <span data-ttu-id="ca48d-123">Om du uppmanas ange hello administratörsautentiseringsuppgifter för hello klustret.</span><span class="sxs-lookup"><span data-stu-id="ca48d-123">If prompted, enter hello admin credentials for hello cluster.</span></span>
   
   > [!NOTE]
   > <span data-ttu-id="ca48d-124">Du kan också nå hello Jupyter notebook i Spark-kluster genom att öppna hello följande URL i webbläsaren.</span><span class="sxs-lookup"><span data-stu-id="ca48d-124">You may also reach hello Jupyter notebook on Spark cluster by opening hello following URL in your browser.</span></span> <span data-ttu-id="ca48d-125">Ersätt **KLUSTERNAMN** med hello namnet på klustret:</span><span class="sxs-lookup"><span data-stu-id="ca48d-125">Replace **CLUSTERNAME** with hello name of your cluster:</span></span>
   >
   > `https://CLUSTERNAME.azurehdinsight.net/jupyter`
   > 
   > 

3. <span data-ttu-id="ca48d-126">Klicka på **ny**, och klicka sedan på antingen **Pyspark**, **PySpark3**, eller **Spark** toocreate en bärbar dator.</span><span class="sxs-lookup"><span data-stu-id="ca48d-126">Click **New**, and then click either **Pyspark**, **PySpark3**, or **Spark** toocreate a notebook.</span></span> <span data-ttu-id="ca48d-127">Använd hello Spark kernel för Scala program, PySpark-kerneln för Python2 program och PySpark3 kernel för Python3 program.</span><span class="sxs-lookup"><span data-stu-id="ca48d-127">Use hello Spark kernel for Scala applications, PySpark kernel for Python2 applications, and PySpark3 kernel for Python3 applications.</span></span>
   
    <span data-ttu-id="ca48d-128">![Kärnor för Jupyter notebook i Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "kärnor för Jupyter notebook i Spark")</span><span class="sxs-lookup"><span data-stu-id="ca48d-128">![Kernels for Jupyter notebook on Spark](./media/hdinsight-apache-spark-jupyter-notebook-kernels/kernel-jupyter-notebook-on-spark.png "Kernels for Jupyter notebook on Spark")</span></span> 

4. <span data-ttu-id="ca48d-129">En bärbar dator öppnas med hello kernel du valt.</span><span class="sxs-lookup"><span data-stu-id="ca48d-129">A notebook opens with hello kernel you selected.</span></span>

## <a name="benefits-of-using-hello-kernels"></a><span data-ttu-id="ca48d-130">Fördelarna med att använda hello kärnor</span><span class="sxs-lookup"><span data-stu-id="ca48d-130">Benefits of using hello kernels</span></span>

<span data-ttu-id="ca48d-131">Här är några fördelar med att använda hello nya kärnor med Jupyter notebook i Spark HDInsight-kluster.</span><span class="sxs-lookup"><span data-stu-id="ca48d-131">Here are a few benefits of using hello new kernels with Jupyter notebook on Spark HDInsight clusters.</span></span>

- <span data-ttu-id="ca48d-132">**Förinställningen kontexter**.</span><span class="sxs-lookup"><span data-stu-id="ca48d-132">**Preset contexts**.</span></span> <span data-ttu-id="ca48d-133">Med **PySpark**, **PySpark3**, eller hello **Spark** kärnor, behöver du inte tooset hello Spark- eller Hive kontexter explicit innan du börjar arbeta med dina program.</span><span class="sxs-lookup"><span data-stu-id="ca48d-133">With  **PySpark**, **PySpark3**, or hello **Spark** kernels, you do not need tooset hello Spark or Hive contexts explicitly before you start working with your applications.</span></span> <span data-ttu-id="ca48d-134">Dessa är tillgängliga som standard.</span><span class="sxs-lookup"><span data-stu-id="ca48d-134">These are available by default.</span></span> <span data-ttu-id="ca48d-135">Dessa kontexter är:</span><span class="sxs-lookup"><span data-stu-id="ca48d-135">These contexts are:</span></span>
   
   * <span data-ttu-id="ca48d-136">**SC** - Spark-kontexten</span><span class="sxs-lookup"><span data-stu-id="ca48d-136">**sc** - for Spark context</span></span>
   * <span data-ttu-id="ca48d-137">**sqlContext** - Hive-kontexten</span><span class="sxs-lookup"><span data-stu-id="ca48d-137">**sqlContext** - for Hive context</span></span>

    <span data-ttu-id="ca48d-138">Så att du inte har toorun uttryck som hello följande tooset hello kontexter:</span><span class="sxs-lookup"><span data-stu-id="ca48d-138">So, you don't have toorun statements like hello following tooset hello contexts:</span></span>

        <span data-ttu-id="ca48d-139">SC = SparkContext('yarn-client') sqlContext = HiveContext(sc)</span><span class="sxs-lookup"><span data-stu-id="ca48d-139">sc = SparkContext('yarn-client')    sqlContext = HiveContext(sc)</span></span>

    <span data-ttu-id="ca48d-140">I stället kan du kan använda direkt hello förinställningen kontexter i ditt program.</span><span class="sxs-lookup"><span data-stu-id="ca48d-140">Instead, you can directly use hello preset contexts in your application.</span></span>

- <span data-ttu-id="ca48d-141">**Cell användbara**.</span><span class="sxs-lookup"><span data-stu-id="ca48d-141">**Cell magics**.</span></span> <span data-ttu-id="ca48d-142">Hej PySpark-kerneln innehåller vissa fördefinierade ”användbara”, som är särskilda kommandon som kan anropas med `%%` (till exempel `%%MAGIC` <args>).</span><span class="sxs-lookup"><span data-stu-id="ca48d-142">hello PySpark kernel provides some predefined “magics”, which are special commands that you can call with `%%` (for example, `%%MAGIC` <args>).</span></span> <span data-ttu-id="ca48d-143">hello magiskt kommandot måste vara hello första ordet i en cell i koden och tillåter flera rader med innehåll.</span><span class="sxs-lookup"><span data-stu-id="ca48d-143">hello magic command must be hello first word in a code cell and allow for multiple lines of content.</span></span> <span data-ttu-id="ca48d-144">hello magiskt word ska hello första ordet i hello cell.</span><span class="sxs-lookup"><span data-stu-id="ca48d-144">hello magic word should be hello first word in hello cell.</span></span> <span data-ttu-id="ca48d-145">Lägger till något innan hello magic, även kommentarer orsakar ett fel.</span><span class="sxs-lookup"><span data-stu-id="ca48d-145">Adding anything before hello magic, even comments, causes an error.</span></span>     <span data-ttu-id="ca48d-146">Mer information om användbara finns [här](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span><span class="sxs-lookup"><span data-stu-id="ca48d-146">For more information on magics, see [here](http://ipython.readthedocs.org/en/stable/interactive/magics.html).</span></span>
   
    <span data-ttu-id="ca48d-147">hello visar följande tabell hello olika användbara via hello kärnor.</span><span class="sxs-lookup"><span data-stu-id="ca48d-147">hello following table lists hello different magics available through hello kernels.</span></span>

   | <span data-ttu-id="ca48d-148">Magiskt tal</span><span class="sxs-lookup"><span data-stu-id="ca48d-148">Magic</span></span> | <span data-ttu-id="ca48d-149">Exempel</span><span class="sxs-lookup"><span data-stu-id="ca48d-149">Example</span></span> | <span data-ttu-id="ca48d-150">Beskrivning</span><span class="sxs-lookup"><span data-stu-id="ca48d-150">Description</span></span> |
   | --- | --- | --- |
   | <span data-ttu-id="ca48d-151">Hjälp</span><span class="sxs-lookup"><span data-stu-id="ca48d-151">help</span></span> |`%%help` |<span data-ttu-id="ca48d-152">Genererar en tabell med alla tillgängliga hello-användbara med exempel och beskrivning</span><span class="sxs-lookup"><span data-stu-id="ca48d-152">Generates a table of all hello available magics with example and description</span></span> |
   | <span data-ttu-id="ca48d-153">Info</span><span class="sxs-lookup"><span data-stu-id="ca48d-153">info</span></span> |`%%info` |<span data-ttu-id="ca48d-154">Utdata sessionsinformation för hello aktuella Livius slutpunkt</span><span class="sxs-lookup"><span data-stu-id="ca48d-154">Outputs session information for hello current Livy endpoint</span></span> |
   | <span data-ttu-id="ca48d-155">Konfigurera</span><span class="sxs-lookup"><span data-stu-id="ca48d-155">configure</span></span> |`%%configure -f`<br><span data-ttu-id="ca48d-156">`{"executorMemory": "1000M"`,</span><span class="sxs-lookup"><span data-stu-id="ca48d-156">`{"executorMemory": "1000M"`,</span></span><br><span data-ttu-id="ca48d-157">`"executorCores": 4`}</span><span class="sxs-lookup"><span data-stu-id="ca48d-157">`"executorCores": 4`}</span></span> |<span data-ttu-id="ca48d-158">Konfigurerar hello parametrar för att skapa en session.</span><span class="sxs-lookup"><span data-stu-id="ca48d-158">Configures hello parameters for creating a session.</span></span> <span data-ttu-id="ca48d-159">Hej flaggan force (-f) är obligatorisk om en session redan har skapats, vilket säkerställer att hello-session är släppas och återskapas.</span><span class="sxs-lookup"><span data-stu-id="ca48d-159">hello force flag (-f) is mandatory if a session has already been created, which ensures that hello session is dropped and recreated.</span></span> <span data-ttu-id="ca48d-160">Titta på [Liviuss POST /sessions brödtext i begäran](https://github.com/cloudera/livy#request-body) en lista över giltiga parametrar.</span><span class="sxs-lookup"><span data-stu-id="ca48d-160">Look at [Livy's POST /sessions Request Body](https://github.com/cloudera/livy#request-body) for a list of valid parameters.</span></span> <span data-ttu-id="ca48d-161">Parametrar måste överföras i som en JSON-sträng och måste vara hello nästa rad efter hello magic enligt hello exempel kolumn.</span><span class="sxs-lookup"><span data-stu-id="ca48d-161">Parameters must be passed in as a JSON string and must be on hello next line after hello magic, as shown in hello example column.</span></span> |
   | <span data-ttu-id="ca48d-162">SQL</span><span class="sxs-lookup"><span data-stu-id="ca48d-162">sql</span></span> |`%%sql -o <variable name>`<br> `SHOW TABLES` |<span data-ttu-id="ca48d-163">Kör en Hive-fråga mot hello sqlContext.</span><span class="sxs-lookup"><span data-stu-id="ca48d-163">Executes a Hive query against hello sqlContext.</span></span> <span data-ttu-id="ca48d-164">Om hello `-o` -parameter har skickats, hello resultatet av hello fråga sparas i hello %% lokala Python kontext som en [Pandas](http://pandas.pydata.org/) dataframe.</span><span class="sxs-lookup"><span data-stu-id="ca48d-164">If hello `-o` parameter is passed, hello result of hello query is persisted in hello %%local Python context as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> |
   | <span data-ttu-id="ca48d-165">lokala</span><span class="sxs-lookup"><span data-stu-id="ca48d-165">local</span></span> |`%%local`<br>`a=1` |<span data-ttu-id="ca48d-166">Alla hello koden i efterföljande rader körs lokalt.</span><span class="sxs-lookup"><span data-stu-id="ca48d-166">All hello code in subsequent lines is executed locally.</span></span> <span data-ttu-id="ca48d-167">Koden måste vara giltig Python2 kod även oavsett hello kernel som du använder.</span><span class="sxs-lookup"><span data-stu-id="ca48d-167">Code must be valid Python2 code even irrespective of hello kernel you are using.</span></span> <span data-ttu-id="ca48d-168">Så även om du har valt **PySpark3** eller **Spark** kärnor när du skapar hello bärbar dator, om du använder hello `%%local` magiskt i en cell, cellen får bara ha giltig Python2 kod...</span><span class="sxs-lookup"><span data-stu-id="ca48d-168">So, even if you selected **PySpark3** or **Spark** kernels while creating hello notebook, if you use hello `%%local` magic in a cell, that cell must only have valid Python2 code..</span></span> |
   | <span data-ttu-id="ca48d-169">loggar</span><span class="sxs-lookup"><span data-stu-id="ca48d-169">logs</span></span> |`%%logs` |<span data-ttu-id="ca48d-170">Utdata hello loggar för hello Livius sessionen.</span><span class="sxs-lookup"><span data-stu-id="ca48d-170">Outputs hello logs for hello current Livy session.</span></span> |
   | <span data-ttu-id="ca48d-171">ta bort</span><span class="sxs-lookup"><span data-stu-id="ca48d-171">delete</span></span> |`%%delete -f -s <session number>` |<span data-ttu-id="ca48d-172">Tar bort en viss session hello aktuella Livius slutpunkt.</span><span class="sxs-lookup"><span data-stu-id="ca48d-172">Deletes a specific session of hello current Livy endpoint.</span></span> <span data-ttu-id="ca48d-173">Observera att du inte kan ta bort hello-session som har initierats för hello kernel sig själv.</span><span class="sxs-lookup"><span data-stu-id="ca48d-173">Note that you cannot delete hello session that is initiated for hello kernel itself.</span></span> |
   | <span data-ttu-id="ca48d-174">Rensa</span><span class="sxs-lookup"><span data-stu-id="ca48d-174">cleanup</span></span> |`%%cleanup -f` |<span data-ttu-id="ca48d-175">Tar bort alla hello-sessioner för hello aktuella Livius-slutpunkten, inklusive anteckningsbokens session.</span><span class="sxs-lookup"><span data-stu-id="ca48d-175">Deletes all hello sessions for hello current Livy endpoint, including this notebook's session.</span></span> <span data-ttu-id="ca48d-176">hello kraft flaggan -f är obligatoriskt.</span><span class="sxs-lookup"><span data-stu-id="ca48d-176">hello force flag -f is mandatory.</span></span> |

   > [!NOTE]
   > <span data-ttu-id="ca48d-177">Dessutom toohello användbara lagts till av hello PySpark-kerneln, du kan också använda hello [inbyggda IPython användbara](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), inklusive `%%sh`.</span><span class="sxs-lookup"><span data-stu-id="ca48d-177">In addition toohello magics added by hello PySpark kernel, you can also use hello [built-in IPython magics](https://ipython.org/ipython-doc/3/interactive/magics.html#cell-magics), including `%%sh`.</span></span> <span data-ttu-id="ca48d-178">Du kan använda hello `%%sh` magiska toorun skript och kodblock på hello klustret headnode.</span><span class="sxs-lookup"><span data-stu-id="ca48d-178">You can use hello `%%sh` magic toorun scripts and block of code on hello cluster headnode.</span></span>
   >
   >
2. <span data-ttu-id="ca48d-179">**Automatisk visualiseringen**.</span><span class="sxs-lookup"><span data-stu-id="ca48d-179">**Auto visualization**.</span></span> <span data-ttu-id="ca48d-180">Hej **Pyspark** kernel automatiskt visualizes hello utdata från Hive och SQL-frågor.</span><span class="sxs-lookup"><span data-stu-id="ca48d-180">hello **Pyspark** kernel automatically visualizes hello output of Hive and SQL queries.</span></span> <span data-ttu-id="ca48d-181">Du kan välja mellan flera olika typer av visualiseringar inklusive tabell, cirkeldiagram, rad, område, fältet.</span><span class="sxs-lookup"><span data-stu-id="ca48d-181">You can choose between several different types of visualizations including Table, Pie, Line, Area, Bar.</span></span>

## <a name="parameters-supported-with-hello-sql-magic"></a><span data-ttu-id="ca48d-182">Parametrar som stöds med hello %% Magiskt tal för sql</span><span class="sxs-lookup"><span data-stu-id="ca48d-182">Parameters supported with hello %%sql magic</span></span>
<span data-ttu-id="ca48d-183">Hej `%%sql` magic stöder olika parametrar som du kan använda toocontrol hello typ av utdata som visas när du kör frågor.</span><span class="sxs-lookup"><span data-stu-id="ca48d-183">hello `%%sql` magic supports different parameters that you can use toocontrol hello kind of output that you receive when you run queries.</span></span> <span data-ttu-id="ca48d-184">hello i den följande tabellen listas hello utdata.</span><span class="sxs-lookup"><span data-stu-id="ca48d-184">hello following table lists hello output.</span></span>

| <span data-ttu-id="ca48d-185">Parameter</span><span class="sxs-lookup"><span data-stu-id="ca48d-185">Parameter</span></span> | <span data-ttu-id="ca48d-186">Exempel</span><span class="sxs-lookup"><span data-stu-id="ca48d-186">Example</span></span> | <span data-ttu-id="ca48d-187">Beskrivning</span><span class="sxs-lookup"><span data-stu-id="ca48d-187">Description</span></span> |
| --- | --- | --- |
| <span data-ttu-id="ca48d-188">-o</span><span class="sxs-lookup"><span data-stu-id="ca48d-188">-o</span></span> |`-o <VARIABLE NAME>` |<span data-ttu-id="ca48d-189">Använd den här parametern toopersist hello resultatet av hello-fråga i hello %% lokala Python kontext som en [Pandas](http://pandas.pydata.org/) dataframe.</span><span class="sxs-lookup"><span data-stu-id="ca48d-189">Use this parameter toopersist hello result of hello query, in hello %%local Python context, as a [Pandas](http://pandas.pydata.org/) dataframe.</span></span> <span data-ttu-id="ca48d-190">hello heter hello dataframe variabeln hello variabelnamn som du anger.</span><span class="sxs-lookup"><span data-stu-id="ca48d-190">hello name of hello dataframe variable is hello variable name you specify.</span></span> |
| <span data-ttu-id="ca48d-191">-q</span><span class="sxs-lookup"><span data-stu-id="ca48d-191">-q</span></span> |`-q` |<span data-ttu-id="ca48d-192">Använd den här tooturn av visualiseringar för hello cell.</span><span class="sxs-lookup"><span data-stu-id="ca48d-192">Use this tooturn off visualizations for hello cell.</span></span> <span data-ttu-id="ca48d-193">Om du inte vill tooauto-visualisera hello innehållet i en cell och bara vill toocapture sedan använda den som en dataframe `-q -o <VARIABLE>`.</span><span class="sxs-lookup"><span data-stu-id="ca48d-193">If you don't want tooauto-visualize hello content of a cell and just want toocapture it as a dataframe, then use `-q -o <VARIABLE>`.</span></span> <span data-ttu-id="ca48d-194">Om du vill tooturn av visualiseringar utan fånga hello resultat (till exempel för att köra en SQL-fråga som en `CREATE TABLE` instruktionen), Använd `-q` utan att ange en `-o` argumentet.</span><span class="sxs-lookup"><span data-stu-id="ca48d-194">If you want tooturn off visualizations without capturing hello results (for example, for running a SQL query, like a `CREATE TABLE` statement), use `-q` without specifying a `-o` argument.</span></span> |
| <span data-ttu-id="ca48d-195">-m</span><span class="sxs-lookup"><span data-stu-id="ca48d-195">-m</span></span> |`-m <METHOD>` |<span data-ttu-id="ca48d-196">Där **metoden** är antingen **ta** eller **exempel** (standard är **ta**).</span><span class="sxs-lookup"><span data-stu-id="ca48d-196">Where **METHOD** is either **take** or **sample** (default is **take**).</span></span> <span data-ttu-id="ca48d-197">Om hello-metoden är **ta**, hello kernel hämtar element från hello överkant hello resultatet som anges av MAXROWS (beskrivs senare i den här tabellen).</span><span class="sxs-lookup"><span data-stu-id="ca48d-197">If hello method is **take**, hello kernel picks elements from hello top of hello result data set specified by MAXROWS (described later in this table).</span></span> <span data-ttu-id="ca48d-198">Om hello-metoden är **exempel**, hello kernel slumpmässigt exempel element i hello datauppsättning enligt för`-r` parametern beskrivs nedan i den här tabellen.</span><span class="sxs-lookup"><span data-stu-id="ca48d-198">If hello method is **sample**, hello kernel randomly samples elements of hello data set according too`-r` parameter, described next in this table.</span></span> |
| <span data-ttu-id="ca48d-199">-r</span><span class="sxs-lookup"><span data-stu-id="ca48d-199">-r</span></span> |`-r <FRACTION>` |<span data-ttu-id="ca48d-200">Här **bråk** är ett flyttal mellan 0,0 och 1,0.</span><span class="sxs-lookup"><span data-stu-id="ca48d-200">Here **FRACTION** is a floating-point number between 0.0 and 1.0.</span></span> <span data-ttu-id="ca48d-201">Om hello exempelmetoden för hello SQL-frågan är `sample`, och sedan hello kernel slumpmässigt exempel hello angivna bråkdel av hello element i hello resultatmängden du.</span><span class="sxs-lookup"><span data-stu-id="ca48d-201">If hello sample method for hello SQL query is `sample`, then hello kernel randomly samples hello specified fraction of hello elements of hello result set for you.</span></span> <span data-ttu-id="ca48d-202">Om du kör en SQL-fråga med hello argument exempelvis `-m sample -r 0.01`, och sedan 1% av hello resultatet rader samplas slumpmässigt.</span><span class="sxs-lookup"><span data-stu-id="ca48d-202">For example, if you run a SQL query with hello arguments `-m sample -r 0.01`, then 1% of hello result rows are randomly sampled.</span></span> |
| -n |`-n <MAXROWS>` |<span data-ttu-id="ca48d-203">**MAXROWS** är ett heltal.</span><span class="sxs-lookup"><span data-stu-id="ca48d-203">**MAXROWS** is an integer value.</span></span> <span data-ttu-id="ca48d-204">hello kernel begränsar hello antalet rader som utdata för**MAXROWS**.</span><span class="sxs-lookup"><span data-stu-id="ca48d-204">hello kernel limits hello number of output rows too**MAXROWS**.</span></span> <span data-ttu-id="ca48d-205">Om **MAXROWS** är ett negativt tal som **-1**, och sedan hello antalet rader i resultatmängden hello inte begränsas.</span><span class="sxs-lookup"><span data-stu-id="ca48d-205">If **MAXROWS** is a negative number such as **-1**, then hello number of rows in hello result set is not limited.</span></span> |

<span data-ttu-id="ca48d-206">**Exempel:**</span><span class="sxs-lookup"><span data-stu-id="ca48d-206">**Example:**</span></span>

    %%sql -q -m sample -r 0.1 -n 500 -o query2
    SELECT * FROM hivesampletable

<span data-ttu-id="ca48d-207">hello instruktionen ovan hello följande:</span><span class="sxs-lookup"><span data-stu-id="ca48d-207">hello statement above does hello following:</span></span>

* <span data-ttu-id="ca48d-208">Markera alla poster från **hivesampletable**.</span><span class="sxs-lookup"><span data-stu-id="ca48d-208">Selects all records from **hivesampletable**.</span></span>
* <span data-ttu-id="ca48d-209">Eftersom vi använder - q, inaktiverar automatisk visualiseringen.</span><span class="sxs-lookup"><span data-stu-id="ca48d-209">Because we use -q, it turns off auto-visualization.</span></span>
* <span data-ttu-id="ca48d-210">Eftersom vi använder `-m sample -r 0.1 -n 500` den slumpmässigt exempel 10% av hello rader i hello hivesampletable och gränser hello hello rader med resultatmängd too500 storlek.</span><span class="sxs-lookup"><span data-stu-id="ca48d-210">Because we use `-m sample -r 0.1 -n 500` it randomly samples 10% of hello rows in hello hivesampletable and limits hello size of hello result set too500 rows.</span></span>
* <span data-ttu-id="ca48d-211">Slutligen, eftersom vi använde `-o query2` sparas även hello utdata till en dataframe kallas **fråga2**.</span><span class="sxs-lookup"><span data-stu-id="ca48d-211">Finally, because we used `-o query2` it also saves hello output into a dataframe called **query2**.</span></span>

## <a name="considerations-while-using-hello-new-kernels"></a><span data-ttu-id="ca48d-212">Att tänka på när du använder hello nya kärnor</span><span class="sxs-lookup"><span data-stu-id="ca48d-212">Considerations while using hello new kernels</span></span>

<span data-ttu-id="ca48d-213">Oavsett vilken kernel som du använder förbrukar lämnar hello-datorer som kör hello klusterresurser.</span><span class="sxs-lookup"><span data-stu-id="ca48d-213">Whichever kernel you use, leaving hello notebooks running consumes hello cluster resources.</span></span>  <span data-ttu-id="ca48d-214">Med dessa kärnor eftersom hello kontexter är förinställda bara avslutas hello anteckningsböcker inte avsluta hello kontext och därför hello klusterresurser fortsätta toobe används.</span><span class="sxs-lookup"><span data-stu-id="ca48d-214">With these kernels, because hello contexts are preset, simply exiting hello notebooks does not kill hello context and hence hello cluster resources continue toobe in use.</span></span> <span data-ttu-id="ca48d-215">Är en bra idé toouse hello **Stäng och stoppa** alternativet från hello anteckningsbok **filen** menyn när du är klar med hello bärbar dator, vilket avslutar hello kontext och sedan avslutar hello bärbar dator.</span><span class="sxs-lookup"><span data-stu-id="ca48d-215">A good practice is toouse hello **Close and Halt** option from hello notebook's **File** menu when you are finished using hello notebook, which kills hello context and then exits hello notebook.</span></span>     

## <a name="show-me-some-examples"></a><span data-ttu-id="ca48d-216">Visa exempel</span><span class="sxs-lookup"><span data-stu-id="ca48d-216">Show me some examples</span></span>

<span data-ttu-id="ca48d-217">När du öppnar en Jupyter-anteckningsbok kan se du två mappar på rotnivå hello.</span><span class="sxs-lookup"><span data-stu-id="ca48d-217">When you open a Jupyter notebook, you see two folders available at hello root level.</span></span>

* <span data-ttu-id="ca48d-218">Hej **PySpark** mappen innehåller exempel bärbara datorer att använda hello nya **Python** kernel.</span><span class="sxs-lookup"><span data-stu-id="ca48d-218">hello **PySpark** folder has sample notebooks that use hello new **Python** kernel.</span></span>
* <span data-ttu-id="ca48d-219">Hej **Scala** mappen innehåller exempel bärbara datorer att använda hello nya **Spark** kernel.</span><span class="sxs-lookup"><span data-stu-id="ca48d-219">hello **Scala** folder has sample notebooks that use hello new **Spark** kernel.</span></span>

<span data-ttu-id="ca48d-220">Du kan öppna hello **00 - [läsa mig första] Spark Magic Kernel funktioner** anteckningsboken från hello **PySpark** eller **Spark** mappen toolearn om hello olika användbara.</span><span class="sxs-lookup"><span data-stu-id="ca48d-220">You can open hello **00 - [READ ME FIRST] Spark Magic Kernel Features** notebook from hello **PySpark** or **Spark** folder toolearn about hello different magics available.</span></span> <span data-ttu-id="ca48d-221">Du kan också använda hello andra exempel anteckningsböcker som är tillgängliga under hello två mappar toolearn hur tooachieve olika scenarier med Jupyter-anteckningsböcker med HDInsight Spark-kluster.</span><span class="sxs-lookup"><span data-stu-id="ca48d-221">You can also use hello other sample notebooks available under hello two folders toolearn how tooachieve different scenarios using Jupyter notebooks with HDInsight Spark clusters.</span></span>

## <a name="where-are-hello-notebooks-stored"></a><span data-ttu-id="ca48d-222">Var lagras hello bärbara datorer?</span><span class="sxs-lookup"><span data-stu-id="ca48d-222">Where are hello notebooks stored?</span></span>

<span data-ttu-id="ca48d-223">Jupyter-anteckningsböcker sparas toohello storage-konto som är associerade med hello kluster under hello **/HdiNotebooks** mapp.</span><span class="sxs-lookup"><span data-stu-id="ca48d-223">Jupyter notebooks are saved toohello storage account associated with hello cluster under hello **/HdiNotebooks** folder.</span></span>  <span data-ttu-id="ca48d-224">Bärbara datorer, textfiler och mappar som du skapar från i Jupyter kan nås från hello storage-konto.</span><span class="sxs-lookup"><span data-stu-id="ca48d-224">Notebooks, text files, and folders that you create from within Jupyter are accessible from hello storage account.</span></span>  <span data-ttu-id="ca48d-225">Till exempel om du använder Jupyter toocreate en mapp **MinMapp** och en bärbar dator **myfolder/mynotebook.ipynb**, du kan komma åt den bärbara på `/HdiNotebooks/myfolder/mynotebook.ipynb` inom hello storage-konto.</span><span class="sxs-lookup"><span data-stu-id="ca48d-225">For example, if you use Jupyter toocreate a folder **myfolder** and a notebook **myfolder/mynotebook.ipynb**, you can access that notebook at `/HdiNotebooks/myfolder/mynotebook.ipynb` within hello storage account.</span></span>  <span data-ttu-id="ca48d-226">hello omvänd gäller även, det vill säga om du överför en bärbar dator direkt tooyour storage-konto på `/HdiNotebooks/mynotebook1.ipynb`, hello bärbara datorer som är synliga från Jupyter samt.</span><span class="sxs-lookup"><span data-stu-id="ca48d-226">hello reverse is also true, that is, if you upload a notebook directly tooyour storage account at `/HdiNotebooks/mynotebook1.ipynb`, hello notebook is visible from Jupyter as well.</span></span>  <span data-ttu-id="ca48d-227">Bärbara datorer är kvar i hello storage-konto även efter hello kluster har tagits bort.</span><span class="sxs-lookup"><span data-stu-id="ca48d-227">Notebooks remain in hello storage account even after hello cluster is deleted.</span></span>

<span data-ttu-id="ca48d-228">Hej hur anteckningsböcker sparas toohello storage-konto är kompatibelt med HDFS.</span><span class="sxs-lookup"><span data-stu-id="ca48d-228">hello way notebooks are saved toohello storage account is compatible with HDFS.</span></span> <span data-ttu-id="ca48d-229">Så, om du SSH till hello-kluster som du kan använda filen management kommandon som visas i följande fragment hello:</span><span class="sxs-lookup"><span data-stu-id="ca48d-229">So, if you SSH into hello cluster you can use file management commands as shown in hello following snippet:</span></span>

    hdfs dfs -ls /HdiNotebooks                               # List everything at hello root directory – everything in this directory is visible tooJupyter from hello home page
    hdfs dfs –copyToLocal /HdiNotebooks                    # Download hello contents of hello HdiNotebooks folder
    hdfs dfs –copyFromLocal example.ipynb /HdiNotebooks   # Upload a notebook example.ipynb toohello root folder so it’s visible from Jupyter


<span data-ttu-id="ca48d-230">Om det finns problem med att komma åt hello storage-konto för hello kluster, hello anteckningsböcker sparas också på hello headnode `/var/lib/jupyter`.</span><span class="sxs-lookup"><span data-stu-id="ca48d-230">In case there are issues accessing hello storage account for hello cluster, hello notebooks are also saved on hello headnode `/var/lib/jupyter`.</span></span>

## <a name="supported-browser"></a><span data-ttu-id="ca48d-231">Webbläsare som stöds</span><span class="sxs-lookup"><span data-stu-id="ca48d-231">Supported browser</span></span>

<span data-ttu-id="ca48d-232">Jupyter-anteckningsböcker på HDInsight Spark-kluster stöds bara på Google Chrome.</span><span class="sxs-lookup"><span data-stu-id="ca48d-232">Jupyter notebooks on Spark HDInsight clusters are supported only on Google Chrome.</span></span>

## <a name="feedback"></a><span data-ttu-id="ca48d-233">Feedback</span><span class="sxs-lookup"><span data-stu-id="ca48d-233">Feedback</span></span>
<span data-ttu-id="ca48d-234">hello nya kärnor i utvecklingen av steg och kommer mogna över tid.</span><span class="sxs-lookup"><span data-stu-id="ca48d-234">hello new kernels are in evolving stage and will mature over time.</span></span> <span data-ttu-id="ca48d-235">Detta kan också innebära att API: er kan ändra som dessa kärnor mogna.</span><span class="sxs-lookup"><span data-stu-id="ca48d-235">This could also mean that APIs could change as these kernels mature.</span></span> <span data-ttu-id="ca48d-236">Vi gärna feedback som du har när du använder dessa nya kärnor.</span><span class="sxs-lookup"><span data-stu-id="ca48d-236">We would appreciate any feedback that you have while using these new kernels.</span></span> <span data-ttu-id="ca48d-237">Detta är användbart i shaping hello slutversionen av dessa kärnor.</span><span class="sxs-lookup"><span data-stu-id="ca48d-237">This is useful in shaping hello final release of these kernels.</span></span> <span data-ttu-id="ca48d-238">Du kan lämna kommentarer/feedback under hello **kommentarer** avsnittet längst ned hello i den här artikeln.</span><span class="sxs-lookup"><span data-stu-id="ca48d-238">You can leave your comments/feedback under hello **Comments** section at hello bottom of this article.</span></span>

## <span data-ttu-id="ca48d-239"><a name="seealso"></a>Se även</span><span class="sxs-lookup"><span data-stu-id="ca48d-239"><a name="seealso"></a>See also</span></span>
* [<span data-ttu-id="ca48d-240">Översikt: Apache Spark i Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="ca48d-240">Overview: Apache Spark on Azure HDInsight</span></span>](hdinsight-apache-spark-overview.md)

### <a name="scenarios"></a><span data-ttu-id="ca48d-241">Scenarier</span><span class="sxs-lookup"><span data-stu-id="ca48d-241">Scenarios</span></span>
* [<span data-ttu-id="ca48d-242">Spark med BI: Utföra interaktiv dataanalys med hjälp av Spark i HDInsight med BI-verktyg</span><span class="sxs-lookup"><span data-stu-id="ca48d-242">Spark with BI: Perform interactive data analysis using Spark in HDInsight with BI tools</span></span>](hdinsight-apache-spark-use-bi-tools.md)
* [<span data-ttu-id="ca48d-243">Spark med Machine Learning: Använda Spark i HDInsight för analys av byggnadstemperatur med HVAC-data</span><span class="sxs-lookup"><span data-stu-id="ca48d-243">Spark with Machine Learning: Use Spark in HDInsight for analyzing building temperature using HVAC data</span></span>](hdinsight-apache-spark-ipython-notebook-machine-learning.md)
* [<span data-ttu-id="ca48d-244">Spark med Machine Learning: använda Spark i HDInsight toopredict livsmedelskontroll</span><span class="sxs-lookup"><span data-stu-id="ca48d-244">Spark with Machine Learning: Use Spark in HDInsight toopredict food inspection results</span></span>](hdinsight-apache-spark-machine-learning-mllib-ipython.md)
* [<span data-ttu-id="ca48d-245">Spark Streaming: Använda Spark i HDInsight för att bygga program för strömning i realtid</span><span class="sxs-lookup"><span data-stu-id="ca48d-245">Spark Streaming: Use Spark in HDInsight for building real-time streaming applications</span></span>](hdinsight-apache-spark-eventhub-streaming.md)
* [<span data-ttu-id="ca48d-246">Webbplatslogganalys med Spark i HDInsight</span><span class="sxs-lookup"><span data-stu-id="ca48d-246">Website log analysis using Spark in HDInsight</span></span>](hdinsight-apache-spark-custom-library-website-log-analysis.md)

### <a name="create-and-run-applications"></a><span data-ttu-id="ca48d-247">Skapa och köra program</span><span class="sxs-lookup"><span data-stu-id="ca48d-247">Create and run applications</span></span>
* [<span data-ttu-id="ca48d-248">Skapa ett fristående program med hjälp av Scala</span><span class="sxs-lookup"><span data-stu-id="ca48d-248">Create a standalone application using Scala</span></span>](hdinsight-apache-spark-create-standalone-application.md)
* [<span data-ttu-id="ca48d-249">Köra jobb via fjärranslutning på ett Spark-kluster med Livy</span><span class="sxs-lookup"><span data-stu-id="ca48d-249">Run jobs remotely on a Spark cluster using Livy</span></span>](hdinsight-apache-spark-livy-rest-interface.md)

### <a name="tools-and-extensions"></a><span data-ttu-id="ca48d-250">Verktyg och tillägg</span><span class="sxs-lookup"><span data-stu-id="ca48d-250">Tools and extensions</span></span>
* [<span data-ttu-id="ca48d-251">Använda HDInsight Tools-Plugin för IntelliJ IDEA toocreate och skicka Spark Scala-program</span><span class="sxs-lookup"><span data-stu-id="ca48d-251">Use HDInsight Tools Plugin for IntelliJ IDEA toocreate and submit Spark Scala applications</span></span>](hdinsight-apache-spark-intellij-tool-plugin.md)
* [<span data-ttu-id="ca48d-252">Använda HDInsight Tools-Plugin för IntelliJ IDEA toodebug Spark-program via fjärranslutning</span><span class="sxs-lookup"><span data-stu-id="ca48d-252">Use HDInsight Tools Plugin for IntelliJ IDEA toodebug Spark applications remotely</span></span>](hdinsight-apache-spark-intellij-tool-plugin-debug-jobs-remotely.md)
* [<span data-ttu-id="ca48d-253">Använda Zeppelin-anteckningsböcker med ett Spark-kluster i HDInsight</span><span class="sxs-lookup"><span data-stu-id="ca48d-253">Use Zeppelin notebooks with a Spark cluster on HDInsight</span></span>](hdinsight-apache-spark-zeppelin-notebook.md)
* [<span data-ttu-id="ca48d-254">Använda externa paket med Jupyter-anteckningsböcker</span><span class="sxs-lookup"><span data-stu-id="ca48d-254">Use external packages with Jupyter notebooks</span></span>](hdinsight-apache-spark-jupyter-notebook-use-external-packages.md)
* [<span data-ttu-id="ca48d-255">Installera Jupyter på datorn och ansluta tooan HDInsight Spark-kluster</span><span class="sxs-lookup"><span data-stu-id="ca48d-255">Install Jupyter on your computer and connect tooan HDInsight Spark cluster</span></span>](hdinsight-apache-spark-jupyter-notebook-install-locally.md)

### <a name="manage-resources"></a><span data-ttu-id="ca48d-256">Hantera resurser</span><span class="sxs-lookup"><span data-stu-id="ca48d-256">Manage resources</span></span>
* [<span data-ttu-id="ca48d-257">Hantera resurser för hello Apache Spark-kluster i Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="ca48d-257">Manage resources for hello Apache Spark cluster in Azure HDInsight</span></span>](hdinsight-apache-spark-resource-manager.md)
* [<span data-ttu-id="ca48d-258">Följa och felsöka jobb som körs i ett Apache Spark-kluster i HDInsight</span><span class="sxs-lookup"><span data-stu-id="ca48d-258">Track and debug jobs running on an Apache Spark cluster in HDInsight</span></span>](hdinsight-apache-spark-job-debugging.md)
