---
title: "Migrera från Windows-baserade HDInsight till Linux-baserat HDInsight - Azure | Microsoft Docs"
description: "Lär dig hur du migrerar från en Windows-baserade HDInsight-kluster till ett Linux-baserade HDInsight-kluster."
services: hdinsight
documentationcenter: 
author: Blackmist
manager: jhubbard
editor: cgronlun
ms.assetid: ff35be59-bae3-42fd-9edc-77f0041bab93
ms.service: hdinsight
ms.custom: hdinsightactive
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: big-data
ms.date: 07/12/2017
ms.author: larryfr
ms.openlocfilehash: 35e80efe27081cd43243f488fa60447b76a20c32
ms.sourcegitcommit: 02e69c4a9d17645633357fe3d46677c2ff22c85a
ms.translationtype: MT
ms.contentlocale: sv-SE
ms.lasthandoff: 08/03/2017
---
# <a name="migrate-from-a-windows-based-hdinsight-cluster-to-a-linux-based-cluster"></a><span data-ttu-id="9b68e-103">Migrera från ett Windows-baserade HDInsight-kluster till ett Linux-baserade kluster</span><span class="sxs-lookup"><span data-stu-id="9b68e-103">Migrate from a Windows-based HDInsight cluster to a Linux-based cluster</span></span>

<span data-ttu-id="9b68e-104">Det här dokumentet innehåller information om skillnaderna mellan HDInsight på Windows- och Linux- och anvisningar om hur du migrerar befintliga arbetsbelastningar till ett Linux-baserade kluster.</span><span class="sxs-lookup"><span data-stu-id="9b68e-104">This document provides details on the differences between HDInsight on Windows and Linux, and guidance on how to migrate existing workloads to a Linux-based cluster.</span></span>

<span data-ttu-id="9b68e-105">När Windows-baserade HDInsight erbjuder ett enkelt sätt att använda Hadoop i molnet, kan du behöva migrera till ett Linux-baserade kluster.</span><span class="sxs-lookup"><span data-stu-id="9b68e-105">While Windows-based HDInsight provides an easy way to use Hadoop in the cloud, you may need to migrate to a Linux-based cluster.</span></span> <span data-ttu-id="9b68e-106">Till exempel för att dra nytta av Linux-baserat verktyg och tekniker som krävs för din lösning.</span><span class="sxs-lookup"><span data-stu-id="9b68e-106">For example, to take advantage of Linux-based tools and technologies that are required for your solution.</span></span> <span data-ttu-id="9b68e-107">Många saker i Hadoop-ekosystemet utvecklas på Linux-baserade system och får inte vara tillgängliga för användning med Windows-baserade HDInsight.</span><span class="sxs-lookup"><span data-stu-id="9b68e-107">Many things in the Hadoop ecosystem are developed on Linux-based systems, and may not be available for use with Windows-based HDInsight.</span></span> <span data-ttu-id="9b68e-108">Många böcker, videor och andra utbildningsmaterial du dessutom förutsätter att du använder ett Linux-system när du arbetar med Hadoop.</span><span class="sxs-lookup"><span data-stu-id="9b68e-108">Additionally, many books, videos, and other training material assume that you are using a Linux system when working with Hadoop.</span></span>

> [!NOTE]
> <span data-ttu-id="9b68e-109">HDInsight-kluster använder Ubuntu långsiktigt stöd (LTS) som operativsystem för noder i klustret.</span><span class="sxs-lookup"><span data-stu-id="9b68e-109">HDInsight clusters use Ubuntu long-term support (LTS) as the operating system for the nodes in the cluster.</span></span> <span data-ttu-id="9b68e-110">Information om versionen av Ubuntu tillgänglig med HDInsight, tillsammans med andra komponenten versionsinformation finns [HDInsight komponenten versioner](hdinsight-component-versioning.md).</span><span class="sxs-lookup"><span data-stu-id="9b68e-110">For information on the version of Ubuntu available with HDInsight, along with other component versioning information, see [HDInsight component versions](hdinsight-component-versioning.md).</span></span>

## <a name="migration-tasks"></a><span data-ttu-id="9b68e-111">Migreringsåtgärder</span><span class="sxs-lookup"><span data-stu-id="9b68e-111">Migration tasks</span></span>

<span data-ttu-id="9b68e-112">Det allmänna arbetsflödet för migrering är som följer.</span><span class="sxs-lookup"><span data-stu-id="9b68e-112">The general workflow for migration is as follows.</span></span>

![Diagram över arbetsflödet för migrering](./media/hdinsight-migrate-from-windows-to-linux/workflow.png)

1. <span data-ttu-id="9b68e-114">Läs avsnitten i det här dokumentet att förstå ändringar som kan krävas när migrera dina befintliga arbetsflöde, jobb, etc. till ett Linux-baserade kluster.</span><span class="sxs-lookup"><span data-stu-id="9b68e-114">Read each section of this document to understand changes that may be required when migrating your existing workflow, jobs, etc. to a Linux-based cluster.</span></span>

2. <span data-ttu-id="9b68e-115">Skapa ett Linux-baserade kluster som en test/kvalitet försäkran miljö.</span><span class="sxs-lookup"><span data-stu-id="9b68e-115">Create a Linux-based cluster as a test/quality assurance environment.</span></span> <span data-ttu-id="9b68e-116">Mer information om hur du skapar ett Linux-baserade kluster finns [skapa Linux-baserade kluster i HDInsight](hdinsight-hadoop-provision-linux-clusters.md).</span><span class="sxs-lookup"><span data-stu-id="9b68e-116">For more information on creating a Linux-based cluster, see [Create Linux-based clusters in HDInsight](hdinsight-hadoop-provision-linux-clusters.md).</span></span>

3. <span data-ttu-id="9b68e-117">Kopiera befintliga jobb, datakällor och sänkor till den nya miljön.</span><span class="sxs-lookup"><span data-stu-id="9b68e-117">Copy existing jobs, data sources, and sinks to the new environment.</span></span>

4. <span data-ttu-id="9b68e-118">Utföra verifiering tester för att se till att dina jobb fungerar som förväntat på det nya klustret.</span><span class="sxs-lookup"><span data-stu-id="9b68e-118">Perform validation testing to make sure that your jobs work as expected on the new cluster.</span></span>

<span data-ttu-id="9b68e-119">När du har kontrollerat att allt fungerar som förväntat, schemalägga avbrottstiden för migreringen.</span><span class="sxs-lookup"><span data-stu-id="9b68e-119">Once you have verified that everything works as expected, schedule downtime for the migration.</span></span> <span data-ttu-id="9b68e-120">Under den här driftstopp, utför följande åtgärder:</span><span class="sxs-lookup"><span data-stu-id="9b68e-120">During this downtime, perform the following actions:</span></span>

1. <span data-ttu-id="9b68e-121">Säkerhetskopiera alla tillfälligt data som lagras lokalt på klusternoderna.</span><span class="sxs-lookup"><span data-stu-id="9b68e-121">Back up any transient data stored locally on the cluster nodes.</span></span> <span data-ttu-id="9b68e-122">Till exempel om du har data som lagras direkt på en huvudnod.</span><span class="sxs-lookup"><span data-stu-id="9b68e-122">For example, if you have data stored directly on a head node.</span></span>

2. <span data-ttu-id="9b68e-123">Ta bort Windows-baserade kluster.</span><span class="sxs-lookup"><span data-stu-id="9b68e-123">Delete the Windows-based cluster.</span></span>

3. <span data-ttu-id="9b68e-124">Skapa ett Linux-baserade kluster med hjälp av samma standard datalager som används av Windows-baserade kluster.</span><span class="sxs-lookup"><span data-stu-id="9b68e-124">Create a Linux-based cluster using the same default data store that the Windows-based cluster used.</span></span> <span data-ttu-id="9b68e-125">Linux-baserade kluster kan fortsätta arbeta mot ditt befintliga produktionsdata.</span><span class="sxs-lookup"><span data-stu-id="9b68e-125">The Linux-based cluster can continue working against your existing production data.</span></span>

4. <span data-ttu-id="9b68e-126">Importera alla tillfälligt säkerhetskopierade data.</span><span class="sxs-lookup"><span data-stu-id="9b68e-126">Import any transient data you backed up.</span></span>

5. <span data-ttu-id="9b68e-127">Starta jobb/fortsätta att bearbeta med det nya klustret.</span><span class="sxs-lookup"><span data-stu-id="9b68e-127">Start jobs/continue processing using the new cluster.</span></span>

### <a name="copy-data-to-the-test-environment"></a><span data-ttu-id="9b68e-128">Kopiera data till testmiljön</span><span class="sxs-lookup"><span data-stu-id="9b68e-128">Copy data to the test environment</span></span>

<span data-ttu-id="9b68e-129">Det finns många sätt att kopiera data och jobb, men de två som beskrivs i det här avsnittet är de enklaste metoderna för att direkt flytta filer till ett testkluster.</span><span class="sxs-lookup"><span data-stu-id="9b68e-129">There are many methods to copy the data and jobs, however the two discussed in this section are the simplest methods to directly move files to a test cluster.</span></span>

#### <a name="hdfs-copy"></a><span data-ttu-id="9b68e-130">HDFS-kopia</span><span class="sxs-lookup"><span data-stu-id="9b68e-130">HDFS copy</span></span>

<span data-ttu-id="9b68e-131">Använd följande steg för att kopiera data från produktionskluster till test-cluster.</span><span class="sxs-lookup"><span data-stu-id="9b68e-131">Use the following steps to copy data from the production cluster to the test cluster.</span></span> <span data-ttu-id="9b68e-132">Använd de här stegen på `hdfs dfs` verktyg som ingår i HDInsight.</span><span class="sxs-lookup"><span data-stu-id="9b68e-132">These steps use the `hdfs dfs` utility that is included with HDInsight.</span></span>

1. <span data-ttu-id="9b68e-133">Hitta storage-konto och standard behållaren informationen för ett befintligt kluster.</span><span class="sxs-lookup"><span data-stu-id="9b68e-133">Find the storage account and default container information for your existing cluster.</span></span> <span data-ttu-id="9b68e-134">I följande exempel använder PowerShell för att hämta den här informationen:</span><span class="sxs-lookup"><span data-stu-id="9b68e-134">The following example uses PowerShell to retrieve this information:</span></span>

    ```powershell
    $clusterName="Your existing HDInsight cluster name"
    $clusterInfo = Get-AzureRmHDInsightCluster -ClusterName $clusterName
    write-host "Storage account name: $clusterInfo.DefaultStorageAccount.split('.')[0]"
    write-host "Default container: $clusterInfo.DefaultStorageContainer"
    ```

2. <span data-ttu-id="9b68e-135">Följ stegen i Skapa Linux-baserade kluster i HDInsight-dokumentet för att skapa en testmiljö.</span><span class="sxs-lookup"><span data-stu-id="9b68e-135">To create a test environment, follow the steps in the Create Linux-based clusters in HDInsight document.</span></span> <span data-ttu-id="9b68e-136">Stoppa innan du skapar klustret och i stället väljer **valfri konfiguration**.</span><span class="sxs-lookup"><span data-stu-id="9b68e-136">Stop before creating the cluster, and instead select **Optional Configuration**.</span></span>

3. <span data-ttu-id="9b68e-137">Valfri konfiguration-bladet välj **länkade Lagringskonton**.</span><span class="sxs-lookup"><span data-stu-id="9b68e-137">From the Optional Configuration blade, select **Linked Storage Accounts**.</span></span>

4. <span data-ttu-id="9b68e-138">Välj **lägga till en nyckel för säkerhetslagring**, och när du uppmanas, Välj lagringskontot som returnerades av PowerShell-skriptet i steg 1.</span><span class="sxs-lookup"><span data-stu-id="9b68e-138">Select **Add a storage key**, and when prompted, select the storage account that was returned by the PowerShell script in step 1.</span></span> <span data-ttu-id="9b68e-139">Klicka på **Välj** på varje blad.</span><span class="sxs-lookup"><span data-stu-id="9b68e-139">Click **Select** on each blade.</span></span> <span data-ttu-id="9b68e-140">Skapa slutligen klustringen.</span><span class="sxs-lookup"><span data-stu-id="9b68e-140">Finally, create the cluster.</span></span>

5. <span data-ttu-id="9b68e-141">När klustret har skapats kan ansluta till den med hjälp av **SSH.**</span><span class="sxs-lookup"><span data-stu-id="9b68e-141">Once the cluster has been created, connect to it using **SSH.**</span></span> <span data-ttu-id="9b68e-142">Mer information finns i [Use SSH with HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md) (Använda SSH med HDInsight).</span><span class="sxs-lookup"><span data-stu-id="9b68e-142">For more information, see [Use SSH with HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span></span>

6. <span data-ttu-id="9b68e-143">Använd följande kommando för att kopiera filer från länkade storage-konto till nya standardkontot för lagring från SSH-session.</span><span class="sxs-lookup"><span data-stu-id="9b68e-143">From the SSH session, use the following command to copy files from the linked storage account to the new default storage account.</span></span> <span data-ttu-id="9b68e-144">Ersätta BEHÅLLAREN med behållaren informationen som returneras av PowerShell.</span><span class="sxs-lookup"><span data-stu-id="9b68e-144">Replace CONTAINER with the container information returned by PowerShell.</span></span> <span data-ttu-id="9b68e-145">Ersätt __konto__ med namnet på kontot.</span><span class="sxs-lookup"><span data-stu-id="9b68e-145">Replace __ACCOUNT__ with the account name.</span></span> <span data-ttu-id="9b68e-146">Ersätt sökvägen till data med sökvägen till en fil.</span><span class="sxs-lookup"><span data-stu-id="9b68e-146">Replace the path to data with the path to a data file.</span></span>

    ```bash
    hdfs dfs -cp wasb://CONTAINER@ACCOUNT.blob.core.windows.net/path/to/old/data /path/to/new/location
    ```

    > [!NOTE]
    > <span data-ttu-id="9b68e-147">Om katalogstrukturen som innehåller data inte finns i testmiljön, kan du skapa den med följande kommando:</span><span class="sxs-lookup"><span data-stu-id="9b68e-147">If the directory structure that contains the data does not exist on the test environment, you can create it using the following command:</span></span>

    ```bash
    hdfs dfs -mkdir -p /new/path/to/create
    ```

    <span data-ttu-id="9b68e-148">Den `-p` växel kan skapa alla kataloger i sökvägen.</span><span class="sxs-lookup"><span data-stu-id="9b68e-148">The `-p` switch enables the creation of all directories in  the path.</span></span>

#### <a name="direct-copy-between-blobs-in-azure-storage"></a><span data-ttu-id="9b68e-149">Direkt kopiera mellan blobbar i Azure Storage</span><span class="sxs-lookup"><span data-stu-id="9b68e-149">Direct copy between blobs in Azure Storage</span></span>

<span data-ttu-id="9b68e-150">Du kanske också vill använda den `Start-AzureStorageBlobCopy` Azure PowerShell-cmdlet för att kopiera BLOB mellan lagringskonton utanför HDInsight.</span><span class="sxs-lookup"><span data-stu-id="9b68e-150">Alternatively, you may want to use the `Start-AzureStorageBlobCopy` Azure PowerShell cmdlet to copy blobs between storage accounts outside of HDInsight.</span></span> <span data-ttu-id="9b68e-151">Mer information finns i Hantera Azure BLOB-avsnittet i med hjälp av Azure PowerShell med Azure Storage.</span><span class="sxs-lookup"><span data-stu-id="9b68e-151">For more information, see the How to manage Azure Blobs section of Using Azure PowerShell with Azure Storage.</span></span>

## <a name="client-side-technologies"></a><span data-ttu-id="9b68e-152">Tekniker på klientsidan</span><span class="sxs-lookup"><span data-stu-id="9b68e-152">Client-side technologies</span></span>

<span data-ttu-id="9b68e-153">Klientsidans tekniker som [Azure PowerShell-cmdlets](/powershell/azureps-cmdlets-docs), [Azure CLI](../cli-install-nodejs.md), eller [.NET SDK för Hadoop](https://hadoopsdk.codeplex.com/) fortsätter att fungera Linux-baserade kluster.</span><span class="sxs-lookup"><span data-stu-id="9b68e-153">Client-side technologies such as [Azure PowerShell cmdlets](/powershell/azureps-cmdlets-docs), [Azure CLI](../cli-install-nodejs.md), or the [.NET SDK for Hadoop](https://hadoopsdk.codeplex.com/) continue to work Linux-based clusters.</span></span> <span data-ttu-id="9b68e-154">Dessa tekniker förlitar sig på REST API: er som är samma för både klustertyper OS.</span><span class="sxs-lookup"><span data-stu-id="9b68e-154">These technologies rely on REST APIs that are the same across both cluster OS types.</span></span>

## <a name="server-side-technologies"></a><span data-ttu-id="9b68e-155">Tekniker för serversidan</span><span class="sxs-lookup"><span data-stu-id="9b68e-155">Server-side technologies</span></span>

<span data-ttu-id="9b68e-156">Följande tabell innehåller råd om migrera server-komponenter som är specifika för Windows.</span><span class="sxs-lookup"><span data-stu-id="9b68e-156">The following table provides guidance on migrating server-side components that are Windows-specific.</span></span>

| <span data-ttu-id="9b68e-157">Om du använder den här tekniken...</span><span class="sxs-lookup"><span data-stu-id="9b68e-157">If you are using this technology...</span></span> | <span data-ttu-id="9b68e-158">Åtgärda...</span><span class="sxs-lookup"><span data-stu-id="9b68e-158">Take this action...</span></span> |
| --- | --- |
| <span data-ttu-id="9b68e-159">**PowerShell** (-skript, inklusive skriptåtgärder användas när klustret skapas)</span><span class="sxs-lookup"><span data-stu-id="9b68e-159">**PowerShell** (server-side scripts, including Script Actions used during cluster creation)</span></span> |<span data-ttu-id="9b68e-160">Skriv om som Bash-skript.</span><span class="sxs-lookup"><span data-stu-id="9b68e-160">Rewrite as Bash scripts.</span></span> <span data-ttu-id="9b68e-161">Skriptåtgärder, se [anpassa Linux-baserade HDInsight med skriptåtgärder](hdinsight-hadoop-customize-cluster-linux.md) och [för Linux-baserade HDInsight utveckling av skriptåtgärder](hdinsight-hadoop-script-actions-linux.md).</span><span class="sxs-lookup"><span data-stu-id="9b68e-161">For Script Actions, see [Customize Linux-based HDInsight with Script Actions](hdinsight-hadoop-customize-cluster-linux.md) and [Script action development for Linux-based HDInsight](hdinsight-hadoop-script-actions-linux.md).</span></span> |
| <span data-ttu-id="9b68e-162">**Azure CLI** (serversidan skript)</span><span class="sxs-lookup"><span data-stu-id="9b68e-162">**Azure CLI** (server-side scripts)</span></span> |<span data-ttu-id="9b68e-163">Azure CLI är tillgängliga på Linux, kommer det inte förinstallerat på HDInsight-klustrets huvudnoder.</span><span class="sxs-lookup"><span data-stu-id="9b68e-163">While the Azure CLI is available on Linux, it does not come pre-installed on the HDInsight cluster head nodes.</span></span> <span data-ttu-id="9b68e-164">Mer information om hur du installerar Azure CLI finns [Kom igång med Azure CLI 2.0](https://docs.microsoft.com/cli/azure/get-started-with-azure-cli).</span><span class="sxs-lookup"><span data-stu-id="9b68e-164">For more information on installing the Azure CLI, see [Get started with Azure CLI 2.0](https://docs.microsoft.com/cli/azure/get-started-with-azure-cli).</span></span> |
| <span data-ttu-id="9b68e-165">**.NET-komponenter**</span><span class="sxs-lookup"><span data-stu-id="9b68e-165">**.NET components**</span></span> |<span data-ttu-id="9b68e-166">.NET stöds på Linux-baserat HDInsight via [Mono](https://mono-project.com).</span><span class="sxs-lookup"><span data-stu-id="9b68e-166">.NET is supported on Linux-based HDInsight through [Mono](https://mono-project.com).</span></span> <span data-ttu-id="9b68e-167">Mer information finns i [migrera .NET lösningar på Linux-baserat HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span><span class="sxs-lookup"><span data-stu-id="9b68e-167">For more information, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span></span> |
| <span data-ttu-id="9b68e-168">**Win32-komponenter eller andra endast Windows-teknik**</span><span class="sxs-lookup"><span data-stu-id="9b68e-168">**Win32 components or other Windows-only technology**</span></span> |<span data-ttu-id="9b68e-169">Vägledning beror på vilken komponent eller teknik.</span><span class="sxs-lookup"><span data-stu-id="9b68e-169">Guidance depends on the component or technology.</span></span> <span data-ttu-id="9b68e-170">Du kanske kan hitta en version som är kompatibel med Linux eller du kan behöva söka efter en annan lösning eller skriva om den här komponenten.</span><span class="sxs-lookup"><span data-stu-id="9b68e-170">You may be able to find a version that is compatible with Linux, or you may need to find an alternate solution or rewrite this component.</span></span> |

> [!IMPORTANT]
> <span data-ttu-id="9b68e-171">Hantering av HDInsight SDK är inte helt kompatibel med Mono.</span><span class="sxs-lookup"><span data-stu-id="9b68e-171">The HDInsight management SDK is not fully compatible with Mono.</span></span> <span data-ttu-id="9b68e-172">Det bör inte användas som en del av lösningar som distribueras till HDInsight-klustret just nu.</span><span class="sxs-lookup"><span data-stu-id="9b68e-172">It should not be used as part of solutions deployed to the HDInsight cluster at this time.</span></span>

## <a name="cluster-creation"></a><span data-ttu-id="9b68e-173">Skapa ett kluster</span><span class="sxs-lookup"><span data-stu-id="9b68e-173">Cluster creation</span></span>

<span data-ttu-id="9b68e-174">Det här avsnittet innehåller information om skillnaderna i klustret har skapats.</span><span class="sxs-lookup"><span data-stu-id="9b68e-174">This section provides information on differences in cluster creation.</span></span>

### <a name="ssh-user"></a><span data-ttu-id="9b68e-175">SSH användare</span><span class="sxs-lookup"><span data-stu-id="9b68e-175">SSH User</span></span>

<span data-ttu-id="9b68e-176">Linux-baserade HDInsight-kluster används den **SSH (Secure Shell)** protokoll för att ge fjärråtkomst till klusternoderna.</span><span class="sxs-lookup"><span data-stu-id="9b68e-176">Linux-based HDInsight clusters use the **Secure Shell (SSH)** protocol to provide remote access to the cluster nodes.</span></span> <span data-ttu-id="9b68e-177">Till skillnad från Remote Desktop för Windows-baserade kluster anger de flesta SSH-klienter inte ett grafiskt användargränssnitt.</span><span class="sxs-lookup"><span data-stu-id="9b68e-177">Unlike Remote Desktop for Windows-based clusters, most SSH clients do not provide a graphical user experience.</span></span> <span data-ttu-id="9b68e-178">SSH-klienter innehåller en kommandorad som gör att du kan köra kommandon på klustret.</span><span class="sxs-lookup"><span data-stu-id="9b68e-178">Instead, SSH clients provide a command line that allows you to run commands on the cluster.</span></span> <span data-ttu-id="9b68e-179">Vissa klienter (exempelvis [MobaXterm](http://mobaxterm.mobatek.net/)) ger ett grafiskt Filhanteraren system förutom en fjärransluten kommandorad.</span><span class="sxs-lookup"><span data-stu-id="9b68e-179">Some clients (such as [MobaXterm](http://mobaxterm.mobatek.net/)) provide a graphical file system browser in addition to a remote command line.</span></span>

<span data-ttu-id="9b68e-180">När klustret skapas måste du ange en SSH-användare och antingen en **lösenord** eller **offentliga nyckelcertifikat** för autentisering.</span><span class="sxs-lookup"><span data-stu-id="9b68e-180">During cluster creation, you must provide an SSH user and either a **password** or **public key certificate** for authentication.</span></span>

<span data-ttu-id="9b68e-181">Du bör använda certifikat med offentlig nyckel, eftersom det är säkrare än att använda ett lösenord.</span><span class="sxs-lookup"><span data-stu-id="9b68e-181">We recommend using Public key certificate, as it is more secure than using a password.</span></span> <span data-ttu-id="9b68e-182">Autentisering med datorcertifikat fungerar genom att generera ett signerat offentliga/privata nyckelpar och sedan tillhandahålla den offentliga nyckeln när du skapar klustret.</span><span class="sxs-lookup"><span data-stu-id="9b68e-182">Certificate authentication works by generating a signed public/private key pair, then providing the public key when creating the cluster.</span></span> <span data-ttu-id="9b68e-183">När du ansluter till servern med SSH, ger den privata nyckeln på klienten autentisering för anslutningen.</span><span class="sxs-lookup"><span data-stu-id="9b68e-183">When connecting to the server using SSH, the private key on the client provides authentication for the connection.</span></span>

<span data-ttu-id="9b68e-184">Mer information finns i [Use SSH with HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md) (Använda SSH med HDInsight).</span><span class="sxs-lookup"><span data-stu-id="9b68e-184">For more information, see [Use SSH with HDInsight](hdinsight-hadoop-linux-use-ssh-unix.md).</span></span>

### <a name="cluster-customization"></a><span data-ttu-id="9b68e-185">Anpassning av kluster</span><span class="sxs-lookup"><span data-stu-id="9b68e-185">Cluster customization</span></span>

<span data-ttu-id="9b68e-186">**Script åtgärder** används med Linux-baserade kluster måste skrivas i Bash-skript.</span><span class="sxs-lookup"><span data-stu-id="9b68e-186">**Script Actions** used with Linux-based clusters must be written in Bash script.</span></span> <span data-ttu-id="9b68e-187">Medan skriptåtgärder kan användas när klustret skapas, för Linux-baserade kluster kan de även vara används för att utföra anpassning när ett kluster som är igång och körs.</span><span class="sxs-lookup"><span data-stu-id="9b68e-187">While Script Actions can be used during cluster creation, for Linux-based clusters they can also be used to perform customization after a cluster is up and running.</span></span> <span data-ttu-id="9b68e-188">Mer information finns i [anpassa Linux-baserade HDInsight med skriptåtgärder](hdinsight-hadoop-customize-cluster-linux.md) och [för Linux-baserade HDInsight utveckling av skriptåtgärder](hdinsight-hadoop-script-actions-linux.md).</span><span class="sxs-lookup"><span data-stu-id="9b68e-188">For more information, see [Customize Linux-based HDInsight with Script Actions](hdinsight-hadoop-customize-cluster-linux.md) and [Script action development for Linux-based HDInsight](hdinsight-hadoop-script-actions-linux.md).</span></span>

<span data-ttu-id="9b68e-189">En annan anpassningsfunktion är **bootstrap**.</span><span class="sxs-lookup"><span data-stu-id="9b68e-189">Another customization feature is **bootstrap**.</span></span> <span data-ttu-id="9b68e-190">För Windows-kluster kan den här funktionen du ange platsen för ytterligare bibliotek för användning med Hive.</span><span class="sxs-lookup"><span data-stu-id="9b68e-190">For Windows clusters, this feature allows you to specify the location of additional libraries for use with Hive.</span></span> <span data-ttu-id="9b68e-191">När klustret skapas dessa bibliotek är automatiskt tillgängliga för användning med Hive-frågor utan att behöva använda `ADD JAR`.</span><span class="sxs-lookup"><span data-stu-id="9b68e-191">After cluster creation, these libraries are automatically available for use with Hive queries without the need to use `ADD JAR`.</span></span>

<span data-ttu-id="9b68e-192">Funktionen Bootstrap för Linux-baserade kluster ger inte den här funktionen.</span><span class="sxs-lookup"><span data-stu-id="9b68e-192">The Bootstrap feature for Linux-based clusters does not provide this functionality.</span></span> <span data-ttu-id="9b68e-193">Använd i stället skriptåtgärd dokumenterade i [lägga till Hive-bibliotek när klustret skapas](hdinsight-hadoop-add-hive-libraries.md).</span><span class="sxs-lookup"><span data-stu-id="9b68e-193">Instead, use script action documented in [Add Hive libraries during cluster creation](hdinsight-hadoop-add-hive-libraries.md).</span></span>

### <a name="virtual-networks"></a><span data-ttu-id="9b68e-194">Virtuella nätverk</span><span class="sxs-lookup"><span data-stu-id="9b68e-194">Virtual Networks</span></span>

<span data-ttu-id="9b68e-195">Windows-baserade HDInsight-kluster endast fungerar med klassiska virtuella nätverk, medan Linux-baserade HDInsight-kluster kräver Resource Manager virtuella nätverk.</span><span class="sxs-lookup"><span data-stu-id="9b68e-195">Windows-based HDInsight clusters only work with Classic Virtual Networks, while Linux-based HDInsight clusters require Resource Manager Virtual Networks.</span></span> <span data-ttu-id="9b68e-196">Om du har resurser i ett klassiskt virtuellt nätverk som Linux-HDInsight-klustret måste ansluta till Se [ansluta ett klassiskt virtuellt nätverk till ett nätverk för virtuella Resource Manager](../vpn-gateway/vpn-gateway-connect-different-deployment-models-portal.md).</span><span class="sxs-lookup"><span data-stu-id="9b68e-196">If you have resources in a Classic Virtual Network that the Linux-HDInsight cluster must connect to, see [Connecting a Classic Virtual Network to a Resource Manager Virtual Network](../vpn-gateway/vpn-gateway-connect-different-deployment-models-portal.md).</span></span>

<span data-ttu-id="9b68e-197">Mer information om konfigurationskrav för att använda virtuella Azure-nätverk med HDInsight finns [utöka HDInsight funktioner med hjälp av ett virtuellt nätverk](hdinsight-extend-hadoop-virtual-network.md).</span><span class="sxs-lookup"><span data-stu-id="9b68e-197">For more information on configuration requirements for using Azure Virtual Networks with HDInsight, see [Extend HDInsight capabilities by using a Virtual Network](hdinsight-extend-hadoop-virtual-network.md).</span></span>

## <a name="management-and-monitoring"></a><span data-ttu-id="9b68e-198">Hantering och övervakning</span><span class="sxs-lookup"><span data-stu-id="9b68e-198">Management and monitoring</span></span>

<span data-ttu-id="9b68e-199">Många av web användargränssnitt som du har använt med Windows-baserade HDInsight, till exempel jobbhistorik eller Yarn-Användargränssnittet är tillgängliga via Ambari.</span><span class="sxs-lookup"><span data-stu-id="9b68e-199">Many of the web UIs you may have used with Windows-based HDInsight, such as Job History or Yarn UI, are available through Ambari.</span></span> <span data-ttu-id="9b68e-200">Dessutom kan Ambari Hive-vy du köra Hive-frågor med hjälp av webbläsaren.</span><span class="sxs-lookup"><span data-stu-id="9b68e-200">In addition, the Ambari Hive View provides a way to run Hive queries using your web browser.</span></span> <span data-ttu-id="9b68e-201">Ambari-Webbgränssnittet är tillgänglig på Linux-baserade kluster på https://CLUSTERNAME.azurehdinsight.net.</span><span class="sxs-lookup"><span data-stu-id="9b68e-201">The Ambari Web UI is available on Linux-based clusters at https://CLUSTERNAME.azurehdinsight.net.</span></span>

<span data-ttu-id="9b68e-202">Mer information om hur du arbetar med Ambari finns i följande dokument:</span><span class="sxs-lookup"><span data-stu-id="9b68e-202">For more information on working with Ambari, see the following documents:</span></span>

* [<span data-ttu-id="9b68e-203">Ambari Web</span><span class="sxs-lookup"><span data-stu-id="9b68e-203">Ambari Web</span></span>](hdinsight-hadoop-manage-ambari.md)
* [<span data-ttu-id="9b68e-204">Ambari REST API</span><span class="sxs-lookup"><span data-stu-id="9b68e-204">Ambari REST API</span></span>](hdinsight-hadoop-manage-ambari-rest-api.md)

### <a name="ambari-alerts"></a><span data-ttu-id="9b68e-205">Ambari aviseringar</span><span class="sxs-lookup"><span data-stu-id="9b68e-205">Ambari Alerts</span></span>

<span data-ttu-id="9b68e-206">Ambari har ett system för varning som anger du eventuella problem med klustret.</span><span class="sxs-lookup"><span data-stu-id="9b68e-206">Ambari has an alert system that can tell you of potential problems with the cluster.</span></span> <span data-ttu-id="9b68e-207">Aviseringar visas som röd eller gul poster i Ambari-Webbgränssnittet, men du kan också hämta dem via REST API.</span><span class="sxs-lookup"><span data-stu-id="9b68e-207">Alerts appear as red or yellow entries in the Ambari Web UI, however you can also retrieve them through the REST API.</span></span>

> [!IMPORTANT]
> <span data-ttu-id="9b68e-208">Ambari-aviseringar anger om det *kan* vara ett problem, inte att det *är* problem.</span><span class="sxs-lookup"><span data-stu-id="9b68e-208">Ambari alerts indicate that there *may* be a problem, not that there *is* a problem.</span></span> <span data-ttu-id="9b68e-209">Exempelvis kan du få en varning att HiveServer2 inte kan nås, även om du har åtkomst till den normalt.</span><span class="sxs-lookup"><span data-stu-id="9b68e-209">For example, you may receive an alert that HiveServer2 cannot be accessed, even though you can access it normally.</span></span>
>
> <span data-ttu-id="9b68e-210">Många aviseringar implementeras som intervallbaserad frågor mot en tjänst och förväntar sig ett svar inom en viss tidsperiod.</span><span class="sxs-lookup"><span data-stu-id="9b68e-210">Many alerts are implemented as interval-based queries against a service, and expect a response within a specific time frame.</span></span> <span data-ttu-id="9b68e-211">Så varningen innebär inte nödvändigtvis att tjänsten är igång, returnerade men det resultat inom den förväntade tidsperiod.</span><span class="sxs-lookup"><span data-stu-id="9b68e-211">So the alert doesn't necessarily mean that the service is down, just that it didn't return results within the expected time frame.</span></span>

<span data-ttu-id="9b68e-212">Du bör utvärdera om en avisering har pågått under en längre tid eller speglar problem som har rapporterats innan du vidtar åtgärden på den.</span><span class="sxs-lookup"><span data-stu-id="9b68e-212">You should evaluate whether an alert has been occurring for an extended period, or mirrors user problems that have been reported before taking action on it.</span></span>

## <a name="file-system-locations"></a><span data-ttu-id="9b68e-213">Sökvägar för system</span><span class="sxs-lookup"><span data-stu-id="9b68e-213">File system locations</span></span>

<span data-ttu-id="9b68e-214">Filsystem för Linux-kluster är placerade annorlunda än Windows-baserade HDInsight-kluster.</span><span class="sxs-lookup"><span data-stu-id="9b68e-214">The Linux cluster file system is laid out differently than Windows-based HDInsight clusters.</span></span> <span data-ttu-id="9b68e-215">Använd följande tabell för att hitta vanliga filer.</span><span class="sxs-lookup"><span data-stu-id="9b68e-215">Use the following table to find commonly used files.</span></span>

| <span data-ttu-id="9b68e-216">Jag vill hitta...</span><span class="sxs-lookup"><span data-stu-id="9b68e-216">I need to find...</span></span> | <span data-ttu-id="9b68e-217">Det finns...</span><span class="sxs-lookup"><span data-stu-id="9b68e-217">It is located...</span></span> |
| --- | --- |
| <span data-ttu-id="9b68e-218">Konfiguration</span><span class="sxs-lookup"><span data-stu-id="9b68e-218">Configuration</span></span> |<span data-ttu-id="9b68e-219">`/etc`.</span><span class="sxs-lookup"><span data-stu-id="9b68e-219">`/etc`.</span></span> <span data-ttu-id="9b68e-220">Till exempel, `/etc/hadoop/conf/core-site.xml`</span><span class="sxs-lookup"><span data-stu-id="9b68e-220">For example, `/etc/hadoop/conf/core-site.xml`</span></span> |
| <span data-ttu-id="9b68e-221">Loggfiler</span><span class="sxs-lookup"><span data-stu-id="9b68e-221">Log files</span></span> |`/var/logs` |
| <span data-ttu-id="9b68e-222">Hortonworks Data Platform (HDP)</span><span class="sxs-lookup"><span data-stu-id="9b68e-222">Hortonworks Data Platform (HDP)</span></span> |<span data-ttu-id="9b68e-223">`/usr/hdp`. Det finns två kataloger finns här, ett som är den aktuella versionen av HDP och `current`.</span><span class="sxs-lookup"><span data-stu-id="9b68e-223">`/usr/hdp`.There are two directories located here, one that is the current HDP version and `current`.</span></span> <span data-ttu-id="9b68e-224">Den `current` katalogen innehåller symboliska länkar till filer och kataloger finns i katalogen för version.</span><span class="sxs-lookup"><span data-stu-id="9b68e-224">The `current` directory contains symbolic links to files and directories located in the version number directory.</span></span> <span data-ttu-id="9b68e-225">Den `current` katalog som är ett bekvämt sätt att komma åt HDP filer eftersom ändras versionsnumret som HDP version är uppdaterad.</span><span class="sxs-lookup"><span data-stu-id="9b68e-225">The `current` directory is provided as a convenient way of accessing HDP files since the version number changes as the HDP version is updated.</span></span> |
| <span data-ttu-id="9b68e-226">hadoop-streaming.jar</span><span class="sxs-lookup"><span data-stu-id="9b68e-226">hadoop-streaming.jar</span></span> |`/usr/hdp/current/hadoop-mapreduce-client/hadoop-streaming.jar` |

<span data-ttu-id="9b68e-227">I allmänhet om du känner till namnet på filen använda du följande kommando från en SSH-session för att hitta sökvägen till filen:</span><span class="sxs-lookup"><span data-stu-id="9b68e-227">In general, if you know the name of the file, you can use the following command from an SSH session to find the file path:</span></span>

    find / -name FILENAME 2>/dev/null

<span data-ttu-id="9b68e-228">Du kan också använda jokertecken med namnet.</span><span class="sxs-lookup"><span data-stu-id="9b68e-228">You can also use wildcards with the file name.</span></span> <span data-ttu-id="9b68e-229">Till exempel `find / -name *streaming*.jar 2>/dev/null` returnerar sökvägen till jar-filer som innehåller ordet strömning som en del av namnet på filen.</span><span class="sxs-lookup"><span data-stu-id="9b68e-229">For example, `find / -name *streaming*.jar 2>/dev/null` returns the path to any jar files that contain the word 'streaming' as part of the file name.</span></span>

## <a name="hive-pig-and-mapreduce"></a><span data-ttu-id="9b68e-230">Hive, Pig och MapReduce</span><span class="sxs-lookup"><span data-stu-id="9b68e-230">Hive, Pig, and MapReduce</span></span>

<span data-ttu-id="9b68e-231">Pig och MapReduce arbetsbelastningar är liknande på Linux-baserade kluster.</span><span class="sxs-lookup"><span data-stu-id="9b68e-231">Pig and MapReduce workloads are similar on Linux-based clusters.</span></span> <span data-ttu-id="9b68e-232">Linux-baserade HDInsight-kluster kan dock skapas med nyare versioner av Hadoop Hive och Pig.</span><span class="sxs-lookup"><span data-stu-id="9b68e-232">However, Linux-based HDInsight clusters can be created using newer versions of Hadoop, Hive, and Pig.</span></span> <span data-ttu-id="9b68e-233">Dessa skillnader mellan versioner införa ändringar i hur din befintliga lösningar-funktion.</span><span class="sxs-lookup"><span data-stu-id="9b68e-233">These version differences may introduce changes in how your existing solutions function.</span></span> <span data-ttu-id="9b68e-234">Mer information om vilka versioner av komponenter som ingår i HDInsight finns [HDInsight component-versioning](hdinsight-component-versioning.md).</span><span class="sxs-lookup"><span data-stu-id="9b68e-234">For more information on the versions of components included with HDInsight, see [HDInsight component versioning](hdinsight-component-versioning.md).</span></span>

<span data-ttu-id="9b68e-235">Linux-baserade HDInsight ger inte remote desktop funktioner.</span><span class="sxs-lookup"><span data-stu-id="9b68e-235">Linux-based HDInsight does not provide remote desktop functionality.</span></span> <span data-ttu-id="9b68e-236">Använd istället SSH för att fjärransluta till head klusternoderna.</span><span class="sxs-lookup"><span data-stu-id="9b68e-236">Instead, you can use SSH to remotely connect to the cluster head nodes.</span></span> <span data-ttu-id="9b68e-237">Mer information finns i följande dokument:</span><span class="sxs-lookup"><span data-stu-id="9b68e-237">For more information, see the following documents:</span></span>

* [<span data-ttu-id="9b68e-238">Använda Hive med SSH</span><span class="sxs-lookup"><span data-stu-id="9b68e-238">Use Hive with SSH</span></span>](hdinsight-hadoop-use-hive-ssh.md)
* [<span data-ttu-id="9b68e-239">Använda Pig med SSH</span><span class="sxs-lookup"><span data-stu-id="9b68e-239">Use Pig with SSH</span></span>](hdinsight-hadoop-use-pig-ssh.md)
* [<span data-ttu-id="9b68e-240">Använda MapReduce med SSH</span><span class="sxs-lookup"><span data-stu-id="9b68e-240">Use MapReduce with SSH</span></span>](hdinsight-hadoop-use-mapreduce-ssh.md)

### <a name="hive"></a><span data-ttu-id="9b68e-241">Hive</span><span class="sxs-lookup"><span data-stu-id="9b68e-241">Hive</span></span>

> [!IMPORTANT]
> <span data-ttu-id="9b68e-242">Om du använder en extern Hive metastore bör du säkerhetskopiera metastore innan du använder med Linux-baserade HDInsight.</span><span class="sxs-lookup"><span data-stu-id="9b68e-242">If you use an external Hive metastore, you should back up the metastore before using it with Linux-based HDInsight.</span></span> <span data-ttu-id="9b68e-243">Linux-baserat HDInsight finns i nyare versioner av Hive, som kan ha inkompatibiliteter med metastores som skapats i tidigare versioner.</span><span class="sxs-lookup"><span data-stu-id="9b68e-243">Linux-based HDInsight is available with newer versions of Hive, which may have incompatibilities with metastores created by earlier versions.</span></span>

<span data-ttu-id="9b68e-244">Följande diagram ger vägledning om hur du migrerar dina Hive-arbetsbelastningar.</span><span class="sxs-lookup"><span data-stu-id="9b68e-244">The following chart provides guidance on migrating your Hive workloads.</span></span>

| <span data-ttu-id="9b68e-245">På Windows-baserade jag använda...</span><span class="sxs-lookup"><span data-stu-id="9b68e-245">On Windows-based, I use...</span></span> | <span data-ttu-id="9b68e-246">På Linux-baserade...</span><span class="sxs-lookup"><span data-stu-id="9b68e-246">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="9b68e-247">**Hive-redigeraren**</span><span class="sxs-lookup"><span data-stu-id="9b68e-247">**Hive Editor**</span></span> |[<span data-ttu-id="9b68e-248">Hive-vyn i Ambari</span><span class="sxs-lookup"><span data-stu-id="9b68e-248">Hive View in Ambari</span></span>](hdinsight-hadoop-use-hive-ambari-view.md) |
| <span data-ttu-id="9b68e-249">`set hive.execution.engine=tez;`Så här aktiverar du Tez</span><span class="sxs-lookup"><span data-stu-id="9b68e-249">`set hive.execution.engine=tez;` to enable Tez</span></span> |<span data-ttu-id="9b68e-250">Tez är standard Körningsmotor för Linux-baserade kluster så set-satsen är inte längre behövs.</span><span class="sxs-lookup"><span data-stu-id="9b68e-250">Tez is the default execution engine for Linux-based clusters, so the set statement is no longer needed.</span></span> |
| <span data-ttu-id="9b68e-251">C# användardefinierade funktioner</span><span class="sxs-lookup"><span data-stu-id="9b68e-251">C# user-defined functions</span></span> | <span data-ttu-id="9b68e-252">Mer information om verifiering C#-komponenter med Linux-baserat HDInsight finns [migrera .NET lösningar på Linux-baserat HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span><span class="sxs-lookup"><span data-stu-id="9b68e-252">For information on validating C# components with Linux-based HDInsight, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span></span> |
| <span data-ttu-id="9b68e-253">CMD-filer eller skript på den server som anropas som en del av ett Hive-jobb</span><span class="sxs-lookup"><span data-stu-id="9b68e-253">CMD files or scripts on the server invoked as part of a Hive job</span></span> |<span data-ttu-id="9b68e-254">Använd Bash-skript</span><span class="sxs-lookup"><span data-stu-id="9b68e-254">use Bash scripts</span></span> |
| <span data-ttu-id="9b68e-255">`hive`kommando från fjärrskrivbord</span><span class="sxs-lookup"><span data-stu-id="9b68e-255">`hive` command from remote desktop</span></span> |<span data-ttu-id="9b68e-256">Använd [Beeline](hdinsight-hadoop-use-hive-beeline.md) eller [Hive från en SSH-session](hdinsight-hadoop-use-hive-ssh.md)</span><span class="sxs-lookup"><span data-stu-id="9b68e-256">Use [Beeline](hdinsight-hadoop-use-hive-beeline.md) or [Hive from an SSH session](hdinsight-hadoop-use-hive-ssh.md)</span></span> |

### <a name="pig"></a><span data-ttu-id="9b68e-257">Pig</span><span class="sxs-lookup"><span data-stu-id="9b68e-257">Pig</span></span>

| <span data-ttu-id="9b68e-258">På Windows-baserade jag använda...</span><span class="sxs-lookup"><span data-stu-id="9b68e-258">On Windows-based, I use...</span></span> | <span data-ttu-id="9b68e-259">På Linux-baserade...</span><span class="sxs-lookup"><span data-stu-id="9b68e-259">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="9b68e-260">C# användardefinierade funktioner</span><span class="sxs-lookup"><span data-stu-id="9b68e-260">C# user-defined functions</span></span> | <span data-ttu-id="9b68e-261">Mer information om verifiering C#-komponenter med Linux-baserat HDInsight finns [migrera .NET lösningar på Linux-baserat HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span><span class="sxs-lookup"><span data-stu-id="9b68e-261">For information on validating C# components with Linux-based HDInsight, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span></span> |
| <span data-ttu-id="9b68e-262">CMD-filer eller skript på den server som anropas som en del av ett Pig-jobb</span><span class="sxs-lookup"><span data-stu-id="9b68e-262">CMD files or scripts on the server invoked as part of a Pig job</span></span> |<span data-ttu-id="9b68e-263">Använd Bash-skript</span><span class="sxs-lookup"><span data-stu-id="9b68e-263">use Bash scripts</span></span> |

### <a name="mapreduce"></a><span data-ttu-id="9b68e-264">MapReduce</span><span class="sxs-lookup"><span data-stu-id="9b68e-264">MapReduce</span></span>

| <span data-ttu-id="9b68e-265">På Windows-baserade jag använda...</span><span class="sxs-lookup"><span data-stu-id="9b68e-265">On Windows-based, I use...</span></span> | <span data-ttu-id="9b68e-266">På Linux-baserade...</span><span class="sxs-lookup"><span data-stu-id="9b68e-266">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="9b68e-267">C# mapper och reducer komponenter</span><span class="sxs-lookup"><span data-stu-id="9b68e-267">C# mapper and reducer components</span></span> | <span data-ttu-id="9b68e-268">Mer information om verifiering C#-komponenter med Linux-baserat HDInsight finns [migrera .NET lösningar på Linux-baserat HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span><span class="sxs-lookup"><span data-stu-id="9b68e-268">For information on validating C# components with Linux-based HDInsight, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md)</span></span> |
| <span data-ttu-id="9b68e-269">CMD-filer eller skript på den server som anropas som en del av ett Hive-jobb</span><span class="sxs-lookup"><span data-stu-id="9b68e-269">CMD files or scripts on the server invoked as part of a Hive job</span></span> |<span data-ttu-id="9b68e-270">Använd Bash-skript</span><span class="sxs-lookup"><span data-stu-id="9b68e-270">use Bash scripts</span></span> |

## <a name="oozie"></a><span data-ttu-id="9b68e-271">Oozie</span><span class="sxs-lookup"><span data-stu-id="9b68e-271">Oozie</span></span>

> [!IMPORTANT]
> <span data-ttu-id="9b68e-272">Om du använder en extern Oozie metastore måste säkerhetskopiera du metastore innan du använder med Linux-baserade HDInsight.</span><span class="sxs-lookup"><span data-stu-id="9b68e-272">If you use an external Oozie metastore, you should back up the metastore before using it with Linux-based HDInsight.</span></span> <span data-ttu-id="9b68e-273">Linux-baserat HDInsight finns i nyare versioner av Oozie som kan ha inkompatibiliteter med metastores som skapats i tidigare versioner.</span><span class="sxs-lookup"><span data-stu-id="9b68e-273">Linux-based HDInsight is available with newer versions of Oozie, which may have incompatibilities with metastores created by earlier versions.</span></span>

<span data-ttu-id="9b68e-274">Shell-åtgärder för att tillåta Oozie arbetsflöden.</span><span class="sxs-lookup"><span data-stu-id="9b68e-274">Oozie workflows allow shell actions.</span></span> <span data-ttu-id="9b68e-275">Shell-åtgärder använder standardgränssnittet för operativsystemet för att köra kommandon på kommandoraden.</span><span class="sxs-lookup"><span data-stu-id="9b68e-275">Shell actions use the default shell for the operating system to run command-line commands.</span></span> <span data-ttu-id="9b68e-276">Om du har Oozie arbetsflöden som förlitar sig på Windows-gränssnittet, måste du skriva om arbetsflöden och förlitar sig på Linux shell-miljö (Bash).</span><span class="sxs-lookup"><span data-stu-id="9b68e-276">If you have Oozie workflows that rely on the Windows shell, you must rewrite the workflows to rely on the Linux shell environment (Bash).</span></span> <span data-ttu-id="9b68e-277">Läs mer om hur du använder shell åtgärder med Oozie [Oozie shell-tillägg för åtgärd](http://oozie.apache.org/docs/3.3.0/DG_ShellActionExtension.html).</span><span class="sxs-lookup"><span data-stu-id="9b68e-277">For more information on using shell actions with Oozie, see [Oozie shell action extension](http://oozie.apache.org/docs/3.3.0/DG_ShellActionExtension.html).</span></span>

<span data-ttu-id="9b68e-278">Om du har Oozie arbetsflöden som förlitar sig på C#-program som anropas via gränssnittet åtgärder måste du verifiera dessa program i en Linux-miljö.</span><span class="sxs-lookup"><span data-stu-id="9b68e-278">If you have Oozie workflows that rely on C# applications invoked through shell actions, you must validate these applications in a Linux environment.</span></span> <span data-ttu-id="9b68e-279">Mer information finns i [migrera .NET lösningar på Linux-baserat HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span><span class="sxs-lookup"><span data-stu-id="9b68e-279">For more information, see [Migrate .NET solutions to Linux-based HDInsight](hdinsight-hadoop-migrate-dotnet-to-linux.md).</span></span>

## <a name="storm"></a><span data-ttu-id="9b68e-280">Storm</span><span class="sxs-lookup"><span data-stu-id="9b68e-280">Storm</span></span>

| <span data-ttu-id="9b68e-281">På Windows-baserade jag använda...</span><span class="sxs-lookup"><span data-stu-id="9b68e-281">On Windows-based, I use...</span></span> | <span data-ttu-id="9b68e-282">På Linux-baserade...</span><span class="sxs-lookup"><span data-stu-id="9b68e-282">On Linux-based...</span></span> |
| --- | --- |
| <span data-ttu-id="9b68e-283">Storm-instrumentpanelen</span><span class="sxs-lookup"><span data-stu-id="9b68e-283">Storm Dashboard</span></span> |<span data-ttu-id="9b68e-284">Storm-instrumentpanelen är inte tillgänglig.</span><span class="sxs-lookup"><span data-stu-id="9b68e-284">The Storm Dashboard is not available.</span></span> <span data-ttu-id="9b68e-285">Se [distribuera och hantera Storm-topologier på Linux-baserade HDInsight](hdinsight-storm-deploy-monitor-topology-linux.md) för sätt att skicka topologier</span><span class="sxs-lookup"><span data-stu-id="9b68e-285">See [Deploy and Manage Storm topologies on Linux-based HDInsight](hdinsight-storm-deploy-monitor-topology-linux.md) for ways to submit topologies</span></span> |
| <span data-ttu-id="9b68e-286">Storm UI</span><span class="sxs-lookup"><span data-stu-id="9b68e-286">Storm UI</span></span> |<span data-ttu-id="9b68e-287">Storm-Användargränssnittet är tillgänglig på https://CLUSTERNAME.azurehdinsight.net/stormui</span><span class="sxs-lookup"><span data-stu-id="9b68e-287">The Storm UI is available at https://CLUSTERNAME.azurehdinsight.net/stormui</span></span> |
| <span data-ttu-id="9b68e-288">Visual Studio för att skapa, distribuera och hantera topologier för C# eller hybrid</span><span class="sxs-lookup"><span data-stu-id="9b68e-288">Visual Studio to create, deploy, and manage C# or hybrid topologies</span></span> |<span data-ttu-id="9b68e-289">Visual Studio kan användas för att skapa, distribuera och hantera C# (SCP.NET) eller hybridtopologier på Linux-baserade Storm på HDInsight-kluster som skapas efter 2016/10/28.</span><span class="sxs-lookup"><span data-stu-id="9b68e-289">Visual Studio can be used to create, deploy, and manage C# (SCP.NET) or hybrid topologies on Linux-based Storm on HDInsight clusters created after 10/28/2016.</span></span> |

## <a name="hbase"></a><span data-ttu-id="9b68e-290">HBase</span><span class="sxs-lookup"><span data-stu-id="9b68e-290">HBase</span></span>

<span data-ttu-id="9b68e-291">På Linux-baserade kluster znode överordnade för HBase är `/hbase-unsecure`.</span><span class="sxs-lookup"><span data-stu-id="9b68e-291">On Linux-based clusters, the znode parent for HBase is `/hbase-unsecure`.</span></span> <span data-ttu-id="9b68e-292">Ange ett värde i konfigurationen för alla Java-klienter program som använder interna HBase Java API.</span><span class="sxs-lookup"><span data-stu-id="9b68e-292">Set this value in the configuration for any Java client applications that use native HBase Java API.</span></span>

<span data-ttu-id="9b68e-293">Se [skapar ett Java-baserade HBase-program](hdinsight-hbase-build-java-maven.md) för en exempel-klient som anger det här värdet.</span><span class="sxs-lookup"><span data-stu-id="9b68e-293">See [Build a Java-based HBase application](hdinsight-hbase-build-java-maven.md) for an example client that sets this value.</span></span>

## <a name="spark"></a><span data-ttu-id="9b68e-294">Spark</span><span class="sxs-lookup"><span data-stu-id="9b68e-294">Spark</span></span>

<span data-ttu-id="9b68e-295">Spark-kluster var tillgängliga på Windows-kluster under förhandsgranskningen.</span><span class="sxs-lookup"><span data-stu-id="9b68e-295">Spark clusters were available on Windows-clusters during preview.</span></span> <span data-ttu-id="9b68e-296">Spark GA är bara tillgänglig med Linux-baserade kluster.</span><span class="sxs-lookup"><span data-stu-id="9b68e-296">Spark GA is only available with Linux-based clusters.</span></span> <span data-ttu-id="9b68e-297">Det finns inga migreringsvägen från en förhandsversion Windows-baserad Spark-kluster till ett versionen Linux-baserade Spark-kluster.</span><span class="sxs-lookup"><span data-stu-id="9b68e-297">There is no migration path from a Windows-based Spark preview cluster to a release Linux-based Spark cluster.</span></span>

## <a name="known-issues"></a><span data-ttu-id="9b68e-298">Kända problem</span><span class="sxs-lookup"><span data-stu-id="9b68e-298">Known issues</span></span>

### <a name="azure-data-factory-custom-net-activities"></a><span data-ttu-id="9b68e-299">Azure Data Factory anpassade .NET-aktiviteter</span><span class="sxs-lookup"><span data-stu-id="9b68e-299">Azure Data Factory custom .NET activities</span></span>

<span data-ttu-id="9b68e-300">Azure Data Factory anpassade .NET aktiviteter stöds inte på Linux-baserade HDInsight-kluster.</span><span class="sxs-lookup"><span data-stu-id="9b68e-300">Azure Data Factory custom .NET activities are not currently supported on Linux-based HDInsight clusters.</span></span> <span data-ttu-id="9b68e-301">Du bör i stället använda någon av följande metoder för att implementera anpassade aktiviteter som en del av din ADF-pipeline.</span><span class="sxs-lookup"><span data-stu-id="9b68e-301">Instead, you should use one of the following methods to implement custom activities as part of your ADF pipeline.</span></span>

* <span data-ttu-id="9b68e-302">Köra .NET-aktiviteter i Azure Batch-pool.</span><span class="sxs-lookup"><span data-stu-id="9b68e-302">Execute .NET activities on Azure Batch pool.</span></span> <span data-ttu-id="9b68e-303">Se Använd Azure Batch länkad tjänst-avsnittet i [använda anpassade aktiviteter i ett Azure Data Factory-pipelinen](../data-factory/data-factory-use-custom-activities.md)</span><span class="sxs-lookup"><span data-stu-id="9b68e-303">See the Use Azure Batch linked service section of [Use custom activities in an Azure Data Factory pipeline](../data-factory/data-factory-use-custom-activities.md)</span></span>
* <span data-ttu-id="9b68e-304">Implementera aktiviteten som en MapReduce activity.</span><span class="sxs-lookup"><span data-stu-id="9b68e-304">Implement the activity as a MapReduce activity.</span></span> <span data-ttu-id="9b68e-305">Mer information finns i [anropa MapReduce program från Data Factory](../data-factory/data-factory-map-reduce.md).</span><span class="sxs-lookup"><span data-stu-id="9b68e-305">For more information, see [Invoke MapReduce Programs from Data Factory](../data-factory/data-factory-map-reduce.md).</span></span>

### <a name="line-endings"></a><span data-ttu-id="9b68e-306">Radbrytningar</span><span class="sxs-lookup"><span data-stu-id="9b68e-306">Line endings</span></span>

<span data-ttu-id="9b68e-307">I allmänhet använder radbrytningar på Windows-datorer CRLF, medan Linux-baserade datorer använder LF.</span><span class="sxs-lookup"><span data-stu-id="9b68e-307">In general, line endings on Windows-based systems use CRLF, while Linux-based systems use LF.</span></span> <span data-ttu-id="9b68e-308">Om du skapar eller förväntar dig data med CRLF radbrytningar kan du behöva ändra producenter och konsumenter att arbeta med LF rad avslutas.</span><span class="sxs-lookup"><span data-stu-id="9b68e-308">If you produce, or expect, data with CRLF line endings, you may need to modify the producers or consumers to work with the LF line ending.</span></span>

<span data-ttu-id="9b68e-309">Till exempel returnerar använda Azure PowerShell för att fråga HDInsight på Windows-baserade kluster data med CRLF.</span><span class="sxs-lookup"><span data-stu-id="9b68e-309">For example, using Azure PowerShell to query HDInsight on a Windows-based cluster returns data with CRLF.</span></span> <span data-ttu-id="9b68e-310">Samma fråga med ett Linux-baserade kluster returnerar LF.</span><span class="sxs-lookup"><span data-stu-id="9b68e-310">The same query with a Linux-based cluster returns LF.</span></span> <span data-ttu-id="9b68e-311">Du bör testa för att se om raden avslutas orsakar problem med din solutuion innan du migrerar till ett Linux-baserade kluster.</span><span class="sxs-lookup"><span data-stu-id="9b68e-311">You should test to see if the line ending causes a problem with your solutuion before migrating to a Linux-based cluster.</span></span>

<span data-ttu-id="9b68e-312">Om du har skript som körs direkt på Linux-klusternoderna, bör du alltid använda LF som rad avslutas.</span><span class="sxs-lookup"><span data-stu-id="9b68e-312">If you have scripts that are executed directly on the Linux-cluster nodes, you should always use LF as the line ending.</span></span> <span data-ttu-id="9b68e-313">Om du använder CRLF får du felmeddelanden när du kör skript på en Linux-baserade kluster.</span><span class="sxs-lookup"><span data-stu-id="9b68e-313">If you use CRLF, you may see errors when running the scripts on a Linux-based cluster.</span></span>

<span data-ttu-id="9b68e-314">Om du vet att skripten inte innehåller strängar med inbäddade CR tecken, kan du massimportera ändra radbrytningar genom att använda någon av följande metoder:</span><span class="sxs-lookup"><span data-stu-id="9b68e-314">If you know that the scripts do not contain strings with embedded CR characters, you can bulk change the line endings using one of the following methods:</span></span>

* <span data-ttu-id="9b68e-315">**Innan du laddar upp till klustret**: använder du följande PowerShell-uttryck för att ändra radbrytningar CRLF till LF innan du laddar upp skriptet till klustret.</span><span class="sxs-lookup"><span data-stu-id="9b68e-315">**Before uploading to the cluster**: Use the following PowerShell statements to change the line endings from CRLF to LF before uploading the script to the cluster.</span></span>

    ```powershell
    $original_file ='c:\path\to\script.py'
    $text = [IO.File]::ReadAllText($original_file) -replace "`r`n", "`n"
    [IO.File]::WriteAllText($original_file, $text)
    ```

* <span data-ttu-id="9b68e-316">**När du överför till klustret**: använder du följande kommando från en SSH-session till Linux-baserade kluster för att ändra skriptet.</span><span class="sxs-lookup"><span data-stu-id="9b68e-316">**After uploading to the cluster**: Use the following command from an SSH session to the Linux-based cluster to modify the script.</span></span>

    ```bash
    hdfs dfs -get wasb:///path/to/script.py oldscript.py
    tr -d '\r' < oldscript.py > script.py
    hdfs dfs -put -f script.py wasb:///path/to/script.py
    ```

## <a name="next-steps"></a><span data-ttu-id="9b68e-317">Nästa steg</span><span class="sxs-lookup"><span data-stu-id="9b68e-317">Next Steps</span></span>

* [<span data-ttu-id="9b68e-318">Lär dig att skapa Linux-baserade HDInsight-kluster</span><span class="sxs-lookup"><span data-stu-id="9b68e-318">Learn how to create Linux-based HDInsight clusters</span></span>](hdinsight-hadoop-provision-linux-clusters.md)
* [<span data-ttu-id="9b68e-319">Använda SSH för att ansluta till HDInsight</span><span class="sxs-lookup"><span data-stu-id="9b68e-319">Use SSH to connect to HDInsight</span></span>](hdinsight-hadoop-linux-use-ssh-unix.md)
* [<span data-ttu-id="9b68e-320">Hantera en Linux-baserade kluster med Ambari</span><span class="sxs-lookup"><span data-stu-id="9b68e-320">Manage a Linux-based cluster using Ambari</span></span>](hdinsight-hadoop-manage-ambari.md)
