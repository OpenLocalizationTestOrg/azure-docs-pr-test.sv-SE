---
title: "aaaHow toochoose maskininlärningsalgoritmer | Microsoft Docs"
description: "Hur toochoose Azure Machine Learning-algoritmer för övervakad och oövervakad inlärning i kluster, klassificerings- eller regressionsmodell experimenten."
services: machine-learning
documentationcenter: 
author: garyericson
manager: jhubbard
editor: cgronlun
tags: 
ms.assetid: a3b23d7f-f083-49c4-b6b1-3911cd69f1b4
ms.service: machine-learning
ms.devlang: na
ms.topic: article
ms.tgt_pltfrm: na
ms.workload: data-services
ms.date: 04/25/2017
ms.author: garye
ms.openlocfilehash: 367b2278acc2435f27f9d24ead8199db58aca283
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: sv-SE
ms.lasthandoff: 10/06/2017
---
# <a name="how-toochoose-algorithms-for-microsoft-azure-machine-learning"></a><span data-ttu-id="43397-103">Hur toochoose algoritmer för Microsoft Azure Machine Learning</span><span class="sxs-lookup"><span data-stu-id="43397-103">How toochoose algorithms for Microsoft Azure Machine Learning</span></span>
<span data-ttu-id="43397-104">hello besvara toohello frågan ”vad machine learning algoritmen ska jag använda”?</span><span class="sxs-lookup"><span data-stu-id="43397-104">hello answer toohello question "What machine learning algorithm should I use?"</span></span> <span data-ttu-id="43397-105">är alltid ”det beror”.</span><span class="sxs-lookup"><span data-stu-id="43397-105">is always "It depends."</span></span> <span data-ttu-id="43397-106">Det beror på hello storlek, kvaliteten och uppbyggnad hello data.</span><span class="sxs-lookup"><span data-stu-id="43397-106">It depends on hello size, quality, and nature of hello data.</span></span> <span data-ttu-id="43397-107">Det beror på vad du vill toodo med hello svar.</span><span class="sxs-lookup"><span data-stu-id="43397-107">It depends on what you want toodo with hello answer.</span></span> <span data-ttu-id="43397-108">Det beror på hur hello matematiska algoritm som hello översattes till instruktioner för hello datorn du använder.</span><span class="sxs-lookup"><span data-stu-id="43397-108">It depends on how hello math of hello algorithm was translated into instructions for hello computer you are using.</span></span> <span data-ttu-id="43397-109">Och det beror på hur lång tid som du har.</span><span class="sxs-lookup"><span data-stu-id="43397-109">And it depends on how much time you have.</span></span> <span data-ttu-id="43397-110">Även hello mest inträffade datavetare går inte att avgöra vilken algoritm utför bäst innan du försöker dem.</span><span class="sxs-lookup"><span data-stu-id="43397-110">Even hello most experienced data scientists can't tell which algorithm will perform best before trying them.</span></span>

## <a name="hello-machine-learning-algorithm-cheat-sheet"></a><span data-ttu-id="43397-111">hello Machine Learning algoritmen Cheat blad</span><span class="sxs-lookup"><span data-stu-id="43397-111">hello Machine Learning Algorithm Cheat Sheet</span></span>
<span data-ttu-id="43397-112">Hej **Microsoft Azure Machine Learning algoritmen Cheat blad** val hello höger datorn Inlärningsalgoritmen för din förutsägelseanalyslösningar från hello Microsoft Azure Machine Learning-biblioteket med algoritmer.</span><span class="sxs-lookup"><span data-stu-id="43397-112">hello **Microsoft Azure Machine Learning Algorithm Cheat Sheet** helps you choose hello right machine learning algorithm for your predictive analytics solutions from hello Microsoft Azure Machine Learning library of algorithms.</span></span>
<span data-ttu-id="43397-113">Den här artikeln guidar dig igenom hur toouse den.</span><span class="sxs-lookup"><span data-stu-id="43397-113">This article walks you through how toouse it.</span></span>

> [!NOTE]
> <span data-ttu-id="43397-114">toodownload hello fusklapp och följ längs med den här artikeln går för[maskin learning algoritmen fusklapp för Microsoft Azure Machine Learning Studio](machine-learning-algorithm-cheat-sheet.md).</span><span class="sxs-lookup"><span data-stu-id="43397-114">toodownload hello cheat sheet and follow along with this article, go too[Machine learning algorithm cheat sheet for Microsoft Azure Machine Learning Studio](machine-learning-algorithm-cheat-sheet.md).</span></span>
> 
> 

<span data-ttu-id="43397-115">Den här fusklapp har en särskild målgrupp i åtanke: en början data forskare med undergraduate nivå machine learning som försöker toochoose en algoritm toostart med i Azure Machine Learning Studio.</span><span class="sxs-lookup"><span data-stu-id="43397-115">This cheat sheet has a very specific audience in mind: a beginning data scientist with undergraduate-level machine learning, trying toochoose an algorithm toostart with in Azure Machine Learning Studio.</span></span> <span data-ttu-id="43397-116">Det innebär att den gör vissa generaliseringar och oversimplifications, men den pekar du i en säker riktning.</span><span class="sxs-lookup"><span data-stu-id="43397-116">That means that it makes some generalizations and oversimplifications, but it points you in a safe direction.</span></span> <span data-ttu-id="43397-117">Det innebär också att det finns många av algoritmer som inte visas här.</span><span class="sxs-lookup"><span data-stu-id="43397-117">It also means that there are lots of algorithms not listed here.</span></span> <span data-ttu-id="43397-118">När Azure Machine Learning växer tooencompass en fullständig uppsättning tillgängliga metoder kan vi lägger till dem.</span><span class="sxs-lookup"><span data-stu-id="43397-118">As Azure Machine Learning grows tooencompass a more complete set of available methods, we'll add them.</span></span>

<span data-ttu-id="43397-119">De här rekommendationerna är kompilerade feedback och tips från många dataanalytiker och machine learning experter.</span><span class="sxs-lookup"><span data-stu-id="43397-119">These recommendations are compiled feedback and tips from many data scientists and machine learning experts.</span></span> <span data-ttu-id="43397-120">Vi har inte accepterar allt, men jag försökte tooharmonize våra åsikter i en grov konsensus.</span><span class="sxs-lookup"><span data-stu-id="43397-120">We didn't agree on everything, but I've tried tooharmonize our opinions into a rough consensus.</span></span> <span data-ttu-id="43397-121">De flesta av hello instruktioner avvikelser som börjar med ”det beror...”</span><span class="sxs-lookup"><span data-stu-id="43397-121">Most of hello statements of disagreement begin with "It depends…"</span></span>

### <a name="how-toouse-hello-cheat-sheet"></a><span data-ttu-id="43397-122">Hur toouse hello cheat blad</span><span class="sxs-lookup"><span data-stu-id="43397-122">How toouse hello cheat sheet</span></span>
<span data-ttu-id="43397-123">Läsa hello sökväg och algoritmen etiketter på hello diagram som ”för  *&lt;sökväg etikett&gt;*, använda  *&lt;algoritmen&gt;*”.</span><span class="sxs-lookup"><span data-stu-id="43397-123">Read hello path and algorithm labels on hello chart as "For *&lt;path label&gt;*, use *&lt;algorithm&gt;*."</span></span> <span data-ttu-id="43397-124">Till exempel ”för *hastighet*, använda *två klassen logistic regression*”.</span><span class="sxs-lookup"><span data-stu-id="43397-124">For example, "For *speed*, use *two class logistic regression*."</span></span> <span data-ttu-id="43397-125">Ibland mer än en gren gäller.</span><span class="sxs-lookup"><span data-stu-id="43397-125">Sometimes more than one branch applies.</span></span>
<span data-ttu-id="43397-126">Ibland är ingen av dem en perfekt passning.</span><span class="sxs-lookup"><span data-stu-id="43397-126">Sometimes none of them are a perfect fit.</span></span> <span data-ttu-id="43397-127">De är avsedda toobe regeln för USB rekommendationer, så oroa dig inte om det är exakt.</span><span class="sxs-lookup"><span data-stu-id="43397-127">They're intended toobe rule-of-thumb recommendations, so don't worry about it being exact.</span></span>
<span data-ttu-id="43397-128">Flera datavetare jag pratade med säger att bara till sätt att hitta hello mycket bästa algoritmen är tootry hello alla.</span><span class="sxs-lookup"><span data-stu-id="43397-128">Several data scientists I talked with said that hello only sure way to find hello very best algorithm is tootry all of them.</span></span>

<span data-ttu-id="43397-129">Här är ett exempel från hello [Cortana Intelligence Gallery](http://gallery.cortanaintelligence.com/) av ett experiment som används för flera algoritmer mot hello samma data och jämför hello resultat: [jämför flera klassen klassificerare: enhetsbokstaven igenkänning ](http://gallery.cortanaintelligence.com/Details/a635502fc98b402a890efe21cec65b92).</span><span class="sxs-lookup"><span data-stu-id="43397-129">Here's an example from hello [Cortana Intelligence Gallery](http://gallery.cortanaintelligence.com/) of an experiment that tries several algorithms against hello same data and compares hello results: [Compare Multi-class Classifiers: Letter recognition](http://gallery.cortanaintelligence.com/Details/a635502fc98b402a890efe21cec65b92).</span></span>

> [!TIP]
> <span data-ttu-id="43397-130">toodownload och skriva ut ett diagram som ger en översikt över hello funktioner i Machine Learning Studio finns [Översiktsdiagram över funktioner i Azure Machine Learning Studio i](machine-learning-studio-overview-diagram.md).</span><span class="sxs-lookup"><span data-stu-id="43397-130">toodownload and print a diagram that gives an overview of hello capabilities of Machine Learning Studio, see [Overview diagram of Azure Machine Learning Studio capabilities](machine-learning-studio-overview-diagram.md).</span></span>
> 
> 

## <a name="flavors-of-machine-learning"></a><span data-ttu-id="43397-131">Varianter av machine learning</span><span class="sxs-lookup"><span data-stu-id="43397-131">Flavors of machine learning</span></span>
### <a name="supervised"></a><span data-ttu-id="43397-132">Övervakad</span><span class="sxs-lookup"><span data-stu-id="43397-132">Supervised</span></span>
<span data-ttu-id="43397-133">Övervakad inlärning algoritmer göra förutsägelser baserat på en uppsättning exempel.</span><span class="sxs-lookup"><span data-stu-id="43397-133">Supervised learning algorithms make predictions based on a set of examples.</span></span> <span data-ttu-id="43397-134">Historiska lager priser kan exempelvis vara används toohazard gissningar i framtida priser.</span><span class="sxs-lookup"><span data-stu-id="43397-134">For instance, historical stock prices can be used toohazard guesses at future prices.</span></span> <span data-ttu-id="43397-135">Varje exempel som används för träning är märkt med hello värdet av intresse – i det här fallet hello lager pris.</span><span class="sxs-lookup"><span data-stu-id="43397-135">Each example used for training is labeled with hello value of interest—in this case hello stock price.</span></span> <span data-ttu-id="43397-136">En övervakad inlärningsalgoritm söker efter mönster i dessa värdeetiketter.</span><span class="sxs-lookup"><span data-stu-id="43397-136">A supervised learning algorithm looks for patterns in those value labels.</span></span> <span data-ttu-id="43397-137">Det kan använda all information som kan vara relevanta – hello dagen i veckan hello, hello säsongen, hello företagets ekonomiska data, hello typ av bransch, hello förekomst av störande geopolitiska händelser, och varje algoritm ser ut för olika typer av mönster.</span><span class="sxs-lookup"><span data-stu-id="43397-137">It can use any information that might be relevant—hello day of hello week, hello season, hello company's financial data, hello type of industry, hello presence of disruptive geopolitical events—and each algorithm looks for different types of patterns.</span></span> <span data-ttu-id="43397-138">När hello algoritm har hittat hello bästa mönstret den kan den använder att mönster toomake förutsägelser för namnlösa tester data – framtidens priser.</span><span class="sxs-lookup"><span data-stu-id="43397-138">After hello algorithm has found hello best pattern it can, it uses that pattern toomake predictions for unlabeled testing data—tomorrow's prices.</span></span>

<span data-ttu-id="43397-139">Övervakad inlärning är ett populärt och praktiskt typ av maskininlärning.</span><span class="sxs-lookup"><span data-stu-id="43397-139">Supervised learning is a popular and useful type of machine learning.</span></span> <span data-ttu-id="43397-140">Med ett undantag är alla hello moduler i Azure Machine Learning övervakad inlärning algoritmer.</span><span class="sxs-lookup"><span data-stu-id="43397-140">With one exception, all hello modules in Azure Machine Learning are supervised learning algorithms.</span></span> <span data-ttu-id="43397-141">Det finns flera specifika typer av övervakad inlärning som representeras i Azure Machine Learning: klassificering, regression och avvikelseidentifiering identifiering.</span><span class="sxs-lookup"><span data-stu-id="43397-141">There are several specific types of supervised learning that are represented within Azure Machine Learning: classification, regression, and anomaly detection.</span></span>

* <span data-ttu-id="43397-142">**Klassificering**.</span><span class="sxs-lookup"><span data-stu-id="43397-142">**Classification**.</span></span> <span data-ttu-id="43397-143">När hello data som ska använda toopredict en kategori, kallas även övervakad inlärning klassificering.</span><span class="sxs-lookup"><span data-stu-id="43397-143">When hello data are being used toopredict a category, supervised learning is also called classification.</span></span> <span data-ttu-id="43397-144">Detta är hello fallet när du tilldelar en avbildning som en bild av en katt eller en hund.</span><span class="sxs-lookup"><span data-stu-id="43397-144">This is hello case when assigning an image as a picture of either a 'cat' or a 'dog'.</span></span> <span data-ttu-id="43397-145">När det finns två alternativ, kallas **tvåklass** eller **binomial klassificering**.</span><span class="sxs-lookup"><span data-stu-id="43397-145">When there are only two choices, it's called **two-class** or **binomial classification**.</span></span> <span data-ttu-id="43397-146">När det finns flera kategorier som när förutsäga hello vinnaren av hello NCAA mars Madness turnering, problemet kallas **flera klassen klassificering**.</span><span class="sxs-lookup"><span data-stu-id="43397-146">When there are more categories, as when predicting hello winner of hello NCAA March Madness tournament, this problem is known as **multi-class classification**.</span></span>
* <span data-ttu-id="43397-147">**Regression**.</span><span class="sxs-lookup"><span data-stu-id="43397-147">**Regression**.</span></span> <span data-ttu-id="43397-148">När ett värde är att förutsade, precis som med lagrets priser, kallas övervakad inlärning regression.</span><span class="sxs-lookup"><span data-stu-id="43397-148">When a value is being predicted, as with stock prices, supervised learning is called regression.</span></span>
* <span data-ttu-id="43397-149">**Avvikelseidentifiering**.</span><span class="sxs-lookup"><span data-stu-id="43397-149">**Anomaly detection**.</span></span> <span data-ttu-id="43397-150">Ibland är hello målet tooidentify datapunkter som är helt enkelt ovanliga.</span><span class="sxs-lookup"><span data-stu-id="43397-150">Sometimes hello goal is tooidentify data points that are simply unusual.</span></span> <span data-ttu-id="43397-151">Att upptäcka bedrägerier, till exempel alla sällsynt kreditkort utgiftsgränsen mönstren är tveksam.</span><span class="sxs-lookup"><span data-stu-id="43397-151">In fraud detection, for example, any highly unusual credit card spending patterns are suspect.</span></span> <span data-ttu-id="43397-152">hello möjliga varianter är så många och hello utbildning exempel så några att det är inte möjligt toolearn vilken bedrägliga aktivitet ser ut.</span><span class="sxs-lookup"><span data-stu-id="43397-152">hello possible variations are so numerous and hello training examples so few, that it's not feasible toolearn what fraudulent activity looks like.</span></span> <span data-ttu-id="43397-153">Den metod som tar avvikelseidentifiering är toosimply veta vilken normal aktivitet ser ut som (med en tidigare icke-olagliga transaktioner) och identifiera något som skiljer sig avsevärt.</span><span class="sxs-lookup"><span data-stu-id="43397-153">The approach that anomaly detection takes is toosimply learn what normal activity looks like (using a history non-fraudulent transactions) and identify anything that is significantly different.</span></span>

### <a name="unsupervised"></a><span data-ttu-id="43397-154">Oövervakad</span><span class="sxs-lookup"><span data-stu-id="43397-154">Unsupervised</span></span>
<span data-ttu-id="43397-155">I oövervakade learning har datapunkterna inga etiketter.</span><span class="sxs-lookup"><span data-stu-id="43397-155">In unsupervised learning, data points have no labels associated with them.</span></span> <span data-ttu-id="43397-156">I stället inlärning hello målet för en oövervakad algoritmen är att ordna hello data på vissa sätt toodescribe dess struktur.</span><span class="sxs-lookup"><span data-stu-id="43397-156">Instead, hello goal of an unsupervised learning algorithm is to organize hello data in some way or toodescribe its structure.</span></span> <span data-ttu-id="43397-157">Detta kan innebära att gruppera i kluster eller för att hitta olika sätt att granska komplexa data så att den visas enklare och mer organiserad.</span><span class="sxs-lookup"><span data-stu-id="43397-157">This can mean grouping it into clusters or finding different ways of looking at complex data so that it appears simpler or more organized.</span></span>

### <a name="reinforcement-learning"></a><span data-ttu-id="43397-158">Förstärkning learning</span><span class="sxs-lookup"><span data-stu-id="43397-158">Reinforcement learning</span></span>
<span data-ttu-id="43397-159">I förstärkning learning hämtar hello algoritmen toochoose en åtgärd i svaret tooeach datapunkt.</span><span class="sxs-lookup"><span data-stu-id="43397-159">In reinforcement learning, hello algorithm gets toochoose an action in response tooeach data point.</span></span> <span data-ttu-id="43397-160">Hej Inlärningsalgoritmen får också en ersättning signal som har en kort stund senare, som anger hur bra hello beslut.</span><span class="sxs-lookup"><span data-stu-id="43397-160">hello learning algorithm also receives a reward signal a short time later, indicating how good hello decision was.</span></span>
<span data-ttu-id="43397-161">Utifrån detta ändrar hello-algoritmen sin strategi i ordning tooachieve hello högsta ersättning.</span><span class="sxs-lookup"><span data-stu-id="43397-161">Based on this, hello algorithm modifies its strategy in order tooachieve hello highest reward.</span></span> <span data-ttu-id="43397-162">Det finns inga förstärkning learning algoritmen moduler i Azure Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="43397-162">Currently there are no reinforcement learning algorithm modules in Azure Machine Learning.</span></span> <span data-ttu-id="43397-163">Förstärkning learning är vanligt i robotics där hello uppsättning sensoravläsningar vid en punkt i tiden är en datapunkt och hello algoritmen måste välja hello robot nästa åtgärd.</span><span class="sxs-lookup"><span data-stu-id="43397-163">Reinforcement learning is common in robotics, where hello set of sensor readings at one point in time is a data point, and hello algorithm must choose hello robot's next action.</span></span> <span data-ttu-id="43397-164">Det är också en fysisk plats för sakernas Internet program.</span><span class="sxs-lookup"><span data-stu-id="43397-164">It is also a natural fit for Internet of Things applications.</span></span>

## <a name="considerations-when-choosing-an-algorithm"></a><span data-ttu-id="43397-165">Att tänka på när du väljer en algoritm</span><span class="sxs-lookup"><span data-stu-id="43397-165">Considerations when choosing an algorithm</span></span>
### <a name="accuracy"></a><span data-ttu-id="43397-166">Noggrannhet</span><span class="sxs-lookup"><span data-stu-id="43397-166">Accuracy</span></span>
<span data-ttu-id="43397-167">Hämta hello mest exakta svaret möjliga är inte alltid nödvändigt.</span><span class="sxs-lookup"><span data-stu-id="43397-167">Getting hello most accurate answer possible isn't always necessary.</span></span>
<span data-ttu-id="43397-168">Ibland är en uppskattning lämplig, beroende på vad du vill använda den för.</span><span class="sxs-lookup"><span data-stu-id="43397-168">Sometimes an approximation is adequate, depending on what you want to use it for.</span></span> <span data-ttu-id="43397-169">Om så är fallet hello kan du kanske kan toocut din bearbetningstid kraftigt av skulle fastna för fler ungefärliga metoder.</span><span class="sxs-lookup"><span data-stu-id="43397-169">If that's hello case, you may be able toocut your processing time dramatically by sticking with more approximate methods.</span></span> <span data-ttu-id="43397-170">En annan fördel med flera ungefärliga metoder är att de naturligt tenderar att undvika [overfitting](https://youtu.be/DQWI1kvmwRg).</span><span class="sxs-lookup"><span data-stu-id="43397-170">Another advantage of more approximate methods is that they naturally tend to avoid [overfitting](https://youtu.be/DQWI1kvmwRg).</span></span>

### <a name="training-time"></a><span data-ttu-id="43397-171">Utbildning</span><span class="sxs-lookup"><span data-stu-id="43397-171">Training time</span></span>
<span data-ttu-id="43397-172">Hej antal minuter eller timmar nödvändiga tootrain en modell varierar mycket mellan algoritmer.</span><span class="sxs-lookup"><span data-stu-id="43397-172">hello number of minutes or hours necessary tootrain a model varies a great deal between algorithms.</span></span> <span data-ttu-id="43397-173">Utbildning tid är ofta beroende av noggrannhet – en vanligtvis medföljer hello andra.</span><span class="sxs-lookup"><span data-stu-id="43397-173">Training time is often closely tied to accuracy—one typically accompanies hello other.</span></span> <span data-ttu-id="43397-174">Dessutom kan är vissa algoritmer mer känslig toohello antalet datapunkter än andra.</span><span class="sxs-lookup"><span data-stu-id="43397-174">In addition, some algorithms are more sensitive toohello number of data points than others.</span></span>
<span data-ttu-id="43397-175">När tiden begränsas hinner hello valet av algoritmen, särskilt när hello datauppsättning är stor.</span><span class="sxs-lookup"><span data-stu-id="43397-175">When time is limited it can drive hello choice of algorithm, especially when hello data set is large.</span></span>

### <a name="linearity"></a><span data-ttu-id="43397-176">Linearitet</span><span class="sxs-lookup"><span data-stu-id="43397-176">Linearity</span></span>
<span data-ttu-id="43397-177">Många maskininlärningsalgoritmer Se användning av linearitet.</span><span class="sxs-lookup"><span data-stu-id="43397-177">Lots of machine learning algorithms make use of linearity.</span></span> <span data-ttu-id="43397-178">Linjär klassificering algoritmer förutsätter att klasser kan avgränsas med rakt (eller dess högre dimension analoga).</span><span class="sxs-lookup"><span data-stu-id="43397-178">Linear classification algorithms assume that classes can be separated by a straight line (or its higher-dimensional analog).</span></span> <span data-ttu-id="43397-179">Dessa inkluderar logistic regression och stöd för vector datorer (som implementeras i Azure Machine Learning).</span><span class="sxs-lookup"><span data-stu-id="43397-179">These include logistic regression and support vector machines (as implemented in Azure Machine Learning).</span></span>
<span data-ttu-id="43397-180">Linjär regression algoritmer förutsätter att datatrender följer rakt.</span><span class="sxs-lookup"><span data-stu-id="43397-180">Linear regression algorithms assume that data trends follow a straight line.</span></span> <span data-ttu-id="43397-181">Dessa förutsättningar är inte bra för vissa problem, men på andra de avslutar noggrannhet.</span><span class="sxs-lookup"><span data-stu-id="43397-181">These assumptions aren't bad for some problems, but on others they bring accuracy down.</span></span>

![Icke-linjära klassen gräns][1]

<span data-ttu-id="43397-183">***Icke-linjära klassen gräns*** *-förlita dig på en linjär klassificeringsalgoritm skulle resultera i sämre Precision*</span><span class="sxs-lookup"><span data-stu-id="43397-183">***Non-linear class boundary*** *- relying on a linear classification algorithm would result in low accuracy*</span></span>

![Data med en icke-linjär trend][2]

<span data-ttu-id="43397-185">***Data med en icke-linjär trend*** *-metoden linjär regression skulle generera mycket större fel än nödvändigt*</span><span class="sxs-lookup"><span data-stu-id="43397-185">***Data with a nonlinear trend*** *- using a linear regression method would generate much larger errors than necessary*</span></span>

<span data-ttu-id="43397-186">Trots sina farorna är linjär algoritmer mycket populär första raden för angrepp.</span><span class="sxs-lookup"><span data-stu-id="43397-186">Despite their dangers, linear algorithms are very popular as a first line of attack.</span></span> <span data-ttu-id="43397-187">De tenderar toobe algoritmiskt snabbt och enkelt att träna.</span><span class="sxs-lookup"><span data-stu-id="43397-187">They tend toobe algorithmically simple and fast to train.</span></span>

### <a name="number-of-parameters"></a><span data-ttu-id="43397-188">Antalet parametrar</span><span class="sxs-lookup"><span data-stu-id="43397-188">Number of parameters</span></span>
<span data-ttu-id="43397-189">Parametrarna är hello rattar en data-forskare hämtar tooturn när du ställer in en algoritm.</span><span class="sxs-lookup"><span data-stu-id="43397-189">Parameters are hello knobs a data scientist gets tooturn when setting up an algorithm.</span></span> <span data-ttu-id="43397-190">De är siffror som påverkar hello algoritmen beteende, till exempel feltolerans eller antal iterationer eller alternativ mellan varianter av hur hello algoritmen fungerar.</span><span class="sxs-lookup"><span data-stu-id="43397-190">They are numbers that affect hello algorithm's behavior, such as error tolerance or number of iterations, or options between variants of how hello algorithm behaves.</span></span> <span data-ttu-id="43397-191">hello utbildningstid och korrektheten i hello algoritmen kan ibland vara ganska känsliga toogetting bara hello rätt inställningar.</span><span class="sxs-lookup"><span data-stu-id="43397-191">hello training time and accuracy of hello algorithm can sometimes be quite sensitive toogetting just hello right settings.</span></span> <span data-ttu-id="43397-192">Vanligtvis krävs algoritmer med många parametrar hello mest utvärderingsversion och fel toofind en bra kombination.</span><span class="sxs-lookup"><span data-stu-id="43397-192">Typically, algorithms with large numbers parameters require hello most trial and error toofind a good combination.</span></span>

<span data-ttu-id="43397-193">Du kan också finns en [parametern omfattande](machine-learning-algorithm-parameters-optimize.md) modulen block i Azure Machine Learning som försöker automatiskt alla parameterkombinationer på oavsett granularitet som du väljer.</span><span class="sxs-lookup"><span data-stu-id="43397-193">Alternatively, there is a [parameter sweeping](machine-learning-algorithm-parameters-optimize.md) module block in Azure Machine Learning that automatically tries all parameter combinations at whatever granularity you choose.</span></span> <span data-ttu-id="43397-194">Även om detta är ett bra sätt toomake att omfattas av hello parametern utrymme, hello tid som krävs för tootrain en modell ökar exponentiellt med hello antal parametrar.</span><span class="sxs-lookup"><span data-stu-id="43397-194">While this is a great way toomake sure you've spanned hello parameter space, hello time required tootrain a model increases exponentially with hello number of parameters.</span></span>

<span data-ttu-id="43397-195">hello är upp och att med många parametrar vanligtvis anger att en algoritm har större flexibilitet.</span><span class="sxs-lookup"><span data-stu-id="43397-195">hello upside is that having many parameters typically indicates that an algorithm has greater flexibility.</span></span> <span data-ttu-id="43397-196">Det kan ofta uppnå mycket bra precision.</span><span class="sxs-lookup"><span data-stu-id="43397-196">It can often achieve very good accuracy.</span></span> <span data-ttu-id="43397-197">Du kan hitta hello rätt kombination av parameterinställningar för har angetts.</span><span class="sxs-lookup"><span data-stu-id="43397-197">Provided you can find hello right combination of parameter settings.</span></span>

### <a name="number-of-features"></a><span data-ttu-id="43397-198">Antal funktioner</span><span class="sxs-lookup"><span data-stu-id="43397-198">Number of features</span></span>
<span data-ttu-id="43397-199">För vissa typer av data kan hello antal funktioner vara mycket stora jämfört med toohello antal datapunkter.</span><span class="sxs-lookup"><span data-stu-id="43397-199">For certain types of data, hello number of features can be very large compared toohello number of data points.</span></span> <span data-ttu-id="43397-200">Detta är ofta hello fallet med genetics eller textdata.</span><span class="sxs-lookup"><span data-stu-id="43397-200">This is often hello case with genetics or textual data.</span></span> <span data-ttu-id="43397-201">hello stort antal funktioner kan bog ned vissa algoritmer för maskininlärning gör utbildning tid unfeasibly lång.</span><span class="sxs-lookup"><span data-stu-id="43397-201">hello large number of features can bog down some learning algorithms, making training time unfeasibly long.</span></span> <span data-ttu-id="43397-202">Support Vector datorer är särskilt väl lämpade toothis fallet (se nedan).</span><span class="sxs-lookup"><span data-stu-id="43397-202">Support Vector Machines are particularly well suited toothis case (see below).</span></span>

### <a name="special-cases"></a><span data-ttu-id="43397-203">Särskilda fall</span><span class="sxs-lookup"><span data-stu-id="43397-203">Special cases</span></span>
<span data-ttu-id="43397-204">Vissa algoritmer för maskininlärning göra viss antaganden om hello struktur hello data eller hello önskat resultat.</span><span class="sxs-lookup"><span data-stu-id="43397-204">Some learning algorithms make particular assumptions about hello structure of hello data or hello desired results.</span></span> <span data-ttu-id="43397-205">Om du hittar en som passar dina behov, får den du bättre resultat, mer korrekta förutsägelser eller snabbare utbildning.</span><span class="sxs-lookup"><span data-stu-id="43397-205">If you can find one that fits your needs, it can give you more useful results, more accurate predictions, or faster training times.</span></span>

| <span data-ttu-id="43397-206">**Algoritmen**</span><span class="sxs-lookup"><span data-stu-id="43397-206">**Algorithm**</span></span> | <span data-ttu-id="43397-207">**Noggrannhet**</span><span class="sxs-lookup"><span data-stu-id="43397-207">**Accuracy**</span></span> | <span data-ttu-id="43397-208">**Utbildning**</span><span class="sxs-lookup"><span data-stu-id="43397-208">**Training time**</span></span> | <span data-ttu-id="43397-209">**Linearitet**</span><span class="sxs-lookup"><span data-stu-id="43397-209">**Linearity**</span></span> | <span data-ttu-id="43397-210">**Parametrar**</span><span class="sxs-lookup"><span data-stu-id="43397-210">**Parameters**</span></span> | <span data-ttu-id="43397-211">**Anteckningar**</span><span class="sxs-lookup"><span data-stu-id="43397-211">**Notes**</span></span> |
| --- |:---:|:---:|:---:|:---:| --- |
| <span data-ttu-id="43397-212">**Tvåklass klassificering**</span><span class="sxs-lookup"><span data-stu-id="43397-212">**Two-class classification**</span></span> | | | | | |
| [<span data-ttu-id="43397-213">logistic regression</span><span class="sxs-lookup"><span data-stu-id="43397-213">logistic regression</span></span>](https://msdn.microsoft.com/library/azure/dn905994.aspx) | |<span data-ttu-id="43397-214">●</span><span class="sxs-lookup"><span data-stu-id="43397-214">●</span></span> |<span data-ttu-id="43397-215">●</span><span class="sxs-lookup"><span data-stu-id="43397-215">●</span></span> |<span data-ttu-id="43397-216">5</span><span class="sxs-lookup"><span data-stu-id="43397-216">5</span></span> | |
| [<span data-ttu-id="43397-217">beslut skog</span><span class="sxs-lookup"><span data-stu-id="43397-217">decision forest</span></span>](https://msdn.microsoft.com/library/azure/dn906008.aspx) |<span data-ttu-id="43397-218">●</span><span class="sxs-lookup"><span data-stu-id="43397-218">●</span></span> |<span data-ttu-id="43397-219">○</span><span class="sxs-lookup"><span data-stu-id="43397-219">○</span></span> | |<span data-ttu-id="43397-220">6</span><span class="sxs-lookup"><span data-stu-id="43397-220">6</span></span> | |
| [<span data-ttu-id="43397-221">beslut Djungel</span><span class="sxs-lookup"><span data-stu-id="43397-221">decision jungle</span></span>](https://msdn.microsoft.com/library/azure/dn905976.aspx) |<span data-ttu-id="43397-222">●</span><span class="sxs-lookup"><span data-stu-id="43397-222">●</span></span> |<span data-ttu-id="43397-223">○</span><span class="sxs-lookup"><span data-stu-id="43397-223">○</span></span> | |<span data-ttu-id="43397-224">6</span><span class="sxs-lookup"><span data-stu-id="43397-224">6</span></span> |<span data-ttu-id="43397-225">Låg minneskrav</span><span class="sxs-lookup"><span data-stu-id="43397-225">Low memory footprint</span></span> |
| [<span data-ttu-id="43397-226">tvåklassförhöjda beslutsträdet</span><span class="sxs-lookup"><span data-stu-id="43397-226">boosted decision tree</span></span>](https://msdn.microsoft.com/library/azure/dn906025.aspx) |<span data-ttu-id="43397-227">●</span><span class="sxs-lookup"><span data-stu-id="43397-227">●</span></span> |<span data-ttu-id="43397-228">○</span><span class="sxs-lookup"><span data-stu-id="43397-228">○</span></span> | |<span data-ttu-id="43397-229">6</span><span class="sxs-lookup"><span data-stu-id="43397-229">6</span></span> |<span data-ttu-id="43397-230">Stora minneskrav</span><span class="sxs-lookup"><span data-stu-id="43397-230">Large memory footprint</span></span> |
| [<span data-ttu-id="43397-231">neurala nätverket</span><span class="sxs-lookup"><span data-stu-id="43397-231">neural network</span></span>](https://msdn.microsoft.com/library/azure/dn905947.aspx) |<span data-ttu-id="43397-232">●</span><span class="sxs-lookup"><span data-stu-id="43397-232">●</span></span> | | |<span data-ttu-id="43397-233">9</span><span class="sxs-lookup"><span data-stu-id="43397-233">9</span></span> |[<span data-ttu-id="43397-234">Ytterligare anpassning är möjligt</span><span class="sxs-lookup"><span data-stu-id="43397-234">Additional customization is possible</span></span>](http://go.microsoft.com/fwlink/?LinkId=402867) |
| [<span data-ttu-id="43397-235">Genomsnittlig perceptron</span><span class="sxs-lookup"><span data-stu-id="43397-235">averaged perceptron</span></span>](https://msdn.microsoft.com/library/azure/dn906036.aspx) |<span data-ttu-id="43397-236">○</span><span class="sxs-lookup"><span data-stu-id="43397-236">○</span></span> |<span data-ttu-id="43397-237">○</span><span class="sxs-lookup"><span data-stu-id="43397-237">○</span></span> |<span data-ttu-id="43397-238">●</span><span class="sxs-lookup"><span data-stu-id="43397-238">●</span></span> |<span data-ttu-id="43397-239">4</span><span class="sxs-lookup"><span data-stu-id="43397-239">4</span></span> | |
| [<span data-ttu-id="43397-240">support vector machine</span><span class="sxs-lookup"><span data-stu-id="43397-240">support vector machine</span></span>](https://msdn.microsoft.com/library/azure/dn905835.aspx) | |<span data-ttu-id="43397-241">○</span><span class="sxs-lookup"><span data-stu-id="43397-241">○</span></span> |<span data-ttu-id="43397-242">●</span><span class="sxs-lookup"><span data-stu-id="43397-242">●</span></span> |<span data-ttu-id="43397-243">5</span><span class="sxs-lookup"><span data-stu-id="43397-243">5</span></span> |<span data-ttu-id="43397-244">Bra för stora funktionsuppsättningar</span><span class="sxs-lookup"><span data-stu-id="43397-244">Good for large feature sets</span></span> |
| [<span data-ttu-id="43397-245">lokalt djup support vector machine</span><span class="sxs-lookup"><span data-stu-id="43397-245">locally deep support vector machine</span></span>](https://msdn.microsoft.com/library/azure/dn913070.aspx) |<span data-ttu-id="43397-246">○</span><span class="sxs-lookup"><span data-stu-id="43397-246">○</span></span> | | |<span data-ttu-id="43397-247">8</span><span class="sxs-lookup"><span data-stu-id="43397-247">8</span></span> |<span data-ttu-id="43397-248">Bra för stora funktionsuppsättningar</span><span class="sxs-lookup"><span data-stu-id="43397-248">Good for large feature sets</span></span> |
| [<span data-ttu-id="43397-249">'Bayes point-dator</span><span class="sxs-lookup"><span data-stu-id="43397-249">Bayes’ point machine</span></span>](https://msdn.microsoft.com/library/azure/dn905930.aspx) | |<span data-ttu-id="43397-250">○</span><span class="sxs-lookup"><span data-stu-id="43397-250">○</span></span> |<span data-ttu-id="43397-251">●</span><span class="sxs-lookup"><span data-stu-id="43397-251">●</span></span> |<span data-ttu-id="43397-252">3</span><span class="sxs-lookup"><span data-stu-id="43397-252">3</span></span> | |
| <span data-ttu-id="43397-253">**Flera klassen klassificering**</span><span class="sxs-lookup"><span data-stu-id="43397-253">**Multi-class classification**</span></span> | | | | | |
| [<span data-ttu-id="43397-254">logistic regression</span><span class="sxs-lookup"><span data-stu-id="43397-254">logistic regression</span></span>](https://msdn.microsoft.com/library/azure/dn905853.aspx) | |<span data-ttu-id="43397-255">●</span><span class="sxs-lookup"><span data-stu-id="43397-255">●</span></span> |<span data-ttu-id="43397-256">●</span><span class="sxs-lookup"><span data-stu-id="43397-256">●</span></span> |<span data-ttu-id="43397-257">5</span><span class="sxs-lookup"><span data-stu-id="43397-257">5</span></span> | |
| [<span data-ttu-id="43397-258">beslut skog</span><span class="sxs-lookup"><span data-stu-id="43397-258">decision forest</span></span>](https://msdn.microsoft.com/library/azure/dn906015.aspx) |<span data-ttu-id="43397-259">●</span><span class="sxs-lookup"><span data-stu-id="43397-259">●</span></span> |<span data-ttu-id="43397-260">○</span><span class="sxs-lookup"><span data-stu-id="43397-260">○</span></span> | |<span data-ttu-id="43397-261">6</span><span class="sxs-lookup"><span data-stu-id="43397-261">6</span></span> | |
| [<span data-ttu-id="43397-262">beslut Djungel</span><span class="sxs-lookup"><span data-stu-id="43397-262">decision jungle </span></span>](https://msdn.microsoft.com/library/azure/dn905963.aspx) |<span data-ttu-id="43397-263">●</span><span class="sxs-lookup"><span data-stu-id="43397-263">●</span></span> |<span data-ttu-id="43397-264">○</span><span class="sxs-lookup"><span data-stu-id="43397-264">○</span></span> | |<span data-ttu-id="43397-265">6</span><span class="sxs-lookup"><span data-stu-id="43397-265">6</span></span> |<span data-ttu-id="43397-266">Låg minneskrav</span><span class="sxs-lookup"><span data-stu-id="43397-266">Low memory footprint</span></span> |
| [<span data-ttu-id="43397-267">neurala nätverket</span><span class="sxs-lookup"><span data-stu-id="43397-267">neural network</span></span>](https://msdn.microsoft.com/library/azure/dn906030.aspx) |<span data-ttu-id="43397-268">●</span><span class="sxs-lookup"><span data-stu-id="43397-268">●</span></span> | | |<span data-ttu-id="43397-269">9</span><span class="sxs-lookup"><span data-stu-id="43397-269">9</span></span> |[<span data-ttu-id="43397-270">Ytterligare anpassning är möjligt</span><span class="sxs-lookup"><span data-stu-id="43397-270">Additional customization is possible</span></span>](http://go.microsoft.com/fwlink/?LinkId=402867) |
| [<span data-ttu-id="43397-271">ett-v-all</span><span class="sxs-lookup"><span data-stu-id="43397-271">one-v-all</span></span>](https://msdn.microsoft.com/library/azure/dn905887.aspx) |- |- |- |- |<span data-ttu-id="43397-272">Se egenskaperna för vald hello tvåklass metod</span><span class="sxs-lookup"><span data-stu-id="43397-272">See properties of hello two-class method selected</span></span> |
| <span data-ttu-id="43397-273">**Regression**</span><span class="sxs-lookup"><span data-stu-id="43397-273">**Regression**</span></span> | | | | | |
| [<span data-ttu-id="43397-274">linjär</span><span class="sxs-lookup"><span data-stu-id="43397-274">linear</span></span>](https://msdn.microsoft.com/library/azure/dn905978.aspx) | |<span data-ttu-id="43397-275">●</span><span class="sxs-lookup"><span data-stu-id="43397-275">●</span></span> |<span data-ttu-id="43397-276">●</span><span class="sxs-lookup"><span data-stu-id="43397-276">●</span></span> |<span data-ttu-id="43397-277">4</span><span class="sxs-lookup"><span data-stu-id="43397-277">4</span></span> | |
| [<span data-ttu-id="43397-278">Linjär Bayesian</span><span class="sxs-lookup"><span data-stu-id="43397-278">Bayesian linear</span></span>](https://msdn.microsoft.com/library/azure/dn906022.aspx) | |<span data-ttu-id="43397-279">○</span><span class="sxs-lookup"><span data-stu-id="43397-279">○</span></span> |<span data-ttu-id="43397-280">●</span><span class="sxs-lookup"><span data-stu-id="43397-280">●</span></span> |<span data-ttu-id="43397-281">2</span><span class="sxs-lookup"><span data-stu-id="43397-281">2</span></span> | |
| [<span data-ttu-id="43397-282">beslut skog</span><span class="sxs-lookup"><span data-stu-id="43397-282">decision forest</span></span>](https://msdn.microsoft.com/library/azure/dn905862.aspx) |<span data-ttu-id="43397-283">●</span><span class="sxs-lookup"><span data-stu-id="43397-283">●</span></span> |<span data-ttu-id="43397-284">○</span><span class="sxs-lookup"><span data-stu-id="43397-284">○</span></span> | |<span data-ttu-id="43397-285">6</span><span class="sxs-lookup"><span data-stu-id="43397-285">6</span></span> | |
| [<span data-ttu-id="43397-286">tvåklassförhöjda beslutsträdet</span><span class="sxs-lookup"><span data-stu-id="43397-286">boosted decision tree</span></span>](https://msdn.microsoft.com/library/azure/dn905801.aspx) |<span data-ttu-id="43397-287">●</span><span class="sxs-lookup"><span data-stu-id="43397-287">●</span></span> |<span data-ttu-id="43397-288">○</span><span class="sxs-lookup"><span data-stu-id="43397-288">○</span></span> | |<span data-ttu-id="43397-289">5</span><span class="sxs-lookup"><span data-stu-id="43397-289">5</span></span> |<span data-ttu-id="43397-290">Stora minneskrav</span><span class="sxs-lookup"><span data-stu-id="43397-290">Large memory footprint</span></span> |
| [<span data-ttu-id="43397-291">snabb skog quantile</span><span class="sxs-lookup"><span data-stu-id="43397-291">fast forest quantile</span></span>](https://msdn.microsoft.com/library/azure/dn913093.aspx) |<span data-ttu-id="43397-292">●</span><span class="sxs-lookup"><span data-stu-id="43397-292">●</span></span> |<span data-ttu-id="43397-293">○</span><span class="sxs-lookup"><span data-stu-id="43397-293">○</span></span> | |<span data-ttu-id="43397-294">9</span><span class="sxs-lookup"><span data-stu-id="43397-294">9</span></span> |<span data-ttu-id="43397-295">Distributioner i stället för punkt förutsägelser</span><span class="sxs-lookup"><span data-stu-id="43397-295">Distributions rather than point predictions</span></span> |
| [<span data-ttu-id="43397-296">neurala nätverket</span><span class="sxs-lookup"><span data-stu-id="43397-296">neural network</span></span>](https://msdn.microsoft.com/library/azure/dn905924.aspx) |<span data-ttu-id="43397-297">●</span><span class="sxs-lookup"><span data-stu-id="43397-297">●</span></span> | | |<span data-ttu-id="43397-298">9</span><span class="sxs-lookup"><span data-stu-id="43397-298">9</span></span> |[<span data-ttu-id="43397-299">Ytterligare anpassning är möjligt</span><span class="sxs-lookup"><span data-stu-id="43397-299">Additional customization is possible</span></span>](http://go.microsoft.com/fwlink/?LinkId=402867) |
| [<span data-ttu-id="43397-300">Poisson</span><span class="sxs-lookup"><span data-stu-id="43397-300">Poisson</span></span>](https://msdn.microsoft.com/library/azure/dn905988.aspx) | | |<span data-ttu-id="43397-301">●</span><span class="sxs-lookup"><span data-stu-id="43397-301">●</span></span> |<span data-ttu-id="43397-302">5</span><span class="sxs-lookup"><span data-stu-id="43397-302">5</span></span> |<span data-ttu-id="43397-303">Tekniskt sett log-linjär.</span><span class="sxs-lookup"><span data-stu-id="43397-303">Technically log-linear.</span></span> <span data-ttu-id="43397-304">För att förutsäga antalet</span><span class="sxs-lookup"><span data-stu-id="43397-304">For predicting counts</span></span> |
| [<span data-ttu-id="43397-305">ordningstalet</span><span class="sxs-lookup"><span data-stu-id="43397-305">ordinal</span></span>](https://msdn.microsoft.com/library/azure/dn906029.aspx) | | | |<span data-ttu-id="43397-306">0</span><span class="sxs-lookup"><span data-stu-id="43397-306">0</span></span> |<span data-ttu-id="43397-307">För att förutsäga rang ordning</span><span class="sxs-lookup"><span data-stu-id="43397-307">For predicting rank-ordering</span></span> |
| <span data-ttu-id="43397-308">**Avvikelseidentifiering**</span><span class="sxs-lookup"><span data-stu-id="43397-308">**Anomaly detection**</span></span> | | | | | |
| [<span data-ttu-id="43397-309">support vector machine</span><span class="sxs-lookup"><span data-stu-id="43397-309">support vector machine</span></span>](https://msdn.microsoft.com/library/azure/dn913103.aspx) |<span data-ttu-id="43397-310">○</span><span class="sxs-lookup"><span data-stu-id="43397-310">○</span></span> |<span data-ttu-id="43397-311">○</span><span class="sxs-lookup"><span data-stu-id="43397-311">○</span></span> | |<span data-ttu-id="43397-312">2</span><span class="sxs-lookup"><span data-stu-id="43397-312">2</span></span> |<span data-ttu-id="43397-313">Särskilt bra för stora funktionsuppsättningar</span><span class="sxs-lookup"><span data-stu-id="43397-313">Especially good for large feature sets</span></span> |
| [<span data-ttu-id="43397-314">PCA-baserad avvikelseidentifiering</span><span class="sxs-lookup"><span data-stu-id="43397-314">PCA-based anomaly detection</span></span>](https://msdn.microsoft.com/library/azure/dn913102.aspx) | |<span data-ttu-id="43397-315">○</span><span class="sxs-lookup"><span data-stu-id="43397-315">○</span></span> |<span data-ttu-id="43397-316">●</span><span class="sxs-lookup"><span data-stu-id="43397-316">●</span></span> |<span data-ttu-id="43397-317">3</span><span class="sxs-lookup"><span data-stu-id="43397-317">3</span></span> | |
| [<span data-ttu-id="43397-318">K-means</span><span class="sxs-lookup"><span data-stu-id="43397-318">K-means</span></span>](https://msdn.microsoft.com/library/azure/5049a09b-bd90-4c4e-9b46-7c87e3a36810/) | |<span data-ttu-id="43397-319">○</span><span class="sxs-lookup"><span data-stu-id="43397-319">○</span></span> |<span data-ttu-id="43397-320">●</span><span class="sxs-lookup"><span data-stu-id="43397-320">●</span></span> |<span data-ttu-id="43397-321">4</span><span class="sxs-lookup"><span data-stu-id="43397-321">4</span></span> |<span data-ttu-id="43397-322">En algoritm för kluster</span><span class="sxs-lookup"><span data-stu-id="43397-322">A clustering algorithm</span></span> |

<span data-ttu-id="43397-323">**Algoritmen egenskaper:**</span><span class="sxs-lookup"><span data-stu-id="43397-323">**Algorithm properties:**</span></span>

<span data-ttu-id="43397-324">**●** -visar hög precision och snabb utbildning gånger hello användning av linearitet</span><span class="sxs-lookup"><span data-stu-id="43397-324">**●** - shows excellent accuracy, fast training times, and hello use of linearity</span></span>

<span data-ttu-id="43397-325">**○** -visar bra Precision och måttlig utbildning gånger</span><span class="sxs-lookup"><span data-stu-id="43397-325">**○** - shows good accuracy and moderate training times</span></span>

## <a name="algorithm-notes"></a><span data-ttu-id="43397-326">Algoritmen anteckningar</span><span class="sxs-lookup"><span data-stu-id="43397-326">Algorithm notes</span></span>
### <a name="linear-regression"></a><span data-ttu-id="43397-327">Linjär regression</span><span class="sxs-lookup"><span data-stu-id="43397-327">Linear regression</span></span>
<span data-ttu-id="43397-328">Som nämnts tidigare [linjär regression](https://msdn.microsoft.com/library/azure/dn905978.aspx) passar en rad (eller plan eller hyperplane) toohello datauppsättning.</span><span class="sxs-lookup"><span data-stu-id="43397-328">As mentioned previously, [linear regression](https://msdn.microsoft.com/library/azure/dn905978.aspx) fits a line (or plane, or hyperplane) toohello data set.</span></span> <span data-ttu-id="43397-329">Det är en bestämmer hög grad, snabbt och enkelt, men det kan vara alltför simplistic för vissa problem.</span><span class="sxs-lookup"><span data-stu-id="43397-329">It's a workhorse, simple and fast, but it may be overly simplistic for some problems.</span></span>
<span data-ttu-id="43397-330">Här en [linjär regression kursen](machine-learning-linear-regression-in-azure.md).</span><span class="sxs-lookup"><span data-stu-id="43397-330">Check here for a [linear regression tutorial](machine-learning-linear-regression-in-azure.md).</span></span>

![Data med en linjär trend][3]

<span data-ttu-id="43397-332">***Data med en linjär trend***</span><span class="sxs-lookup"><span data-stu-id="43397-332">***Data with a linear trend***</span></span>

### <a name="logistic-regression"></a><span data-ttu-id="43397-333">Logistic regression</span><span class="sxs-lookup"><span data-stu-id="43397-333">Logistic regression</span></span>
<span data-ttu-id="43397-334">Även om den innehåller förvirrande 'regression' hello namn, logistic regression är faktiskt ett kraftfullt verktyg för [tvåklass](https://msdn.microsoft.com/library/azure/dn905994.aspx) och [multiclass](https://msdn.microsoft.com/library/azure/dn905853.aspx) klassificering.</span><span class="sxs-lookup"><span data-stu-id="43397-334">Although it confusingly includes 'regression' in hello name, logistic regression is actually a powerful tool for [two-class](https://msdn.microsoft.com/library/azure/dn905994.aspx) and [multiclass](https://msdn.microsoft.com/library/azure/dn905853.aspx) classification.</span></span> <span data-ttu-id="43397-335">Det går snabbt och enkelt.</span><span class="sxs-lookup"><span data-stu-id="43397-335">It's fast and simple.</span></span> <span data-ttu-id="43397-336">Hej faktum att den använder en '-formad kurva i stället för rakt är det en naturlig anpassning för att dela data i grupper.</span><span class="sxs-lookup"><span data-stu-id="43397-336">hello fact that it uses an 'S'-shaped curve instead of a straight line makes it a natural fit for dividing data into groups.</span></span> <span data-ttu-id="43397-337">Logistic regression ger linjär klassgränser, så se när du använder den, till en linjär uppskattning är något som du kan live med.</span><span class="sxs-lookup"><span data-stu-id="43397-337">Logistic regression gives linear class boundaries, so when you use it, make sure a linear approximation is something you can live with.</span></span>

![Logistic regression tootwo klassen data med just en funktion][4]

<span data-ttu-id="43397-339">***En logistic regression tootwo klassen data med ett enda funktionen*** *-klassen gräns är hello punkt vid vilken hello logistic kurvan är precis så nära tooboth klasser*</span><span class="sxs-lookup"><span data-stu-id="43397-339">***A logistic regression tootwo-class data with just one feature*** *- the class boundary is hello point at which hello logistic curve is just as close tooboth classes*</span></span>

### <a name="trees-forests-and-jungles"></a><span data-ttu-id="43397-340">Träd och skogar jungles</span><span class="sxs-lookup"><span data-stu-id="43397-340">Trees, forests, and jungles</span></span>
<span data-ttu-id="43397-341">Decision skogar ([regression](https://msdn.microsoft.com/library/azure/dn905862.aspx), [tvåklass](https://msdn.microsoft.com/library/azure/dn906008.aspx), och [multiclass](https://msdn.microsoft.com/library/azure/dn906015.aspx)), beslut jungles ([tvåklass](https://msdn.microsoft.com/library/azure/dn905976.aspx) och [ multiclass](https://msdn.microsoft.com/library/azure/dn905963.aspx)), och förstärkta beslutsträd ([regression](https://msdn.microsoft.com/library/azure/dn905801.aspx) och [tvåklass](https://msdn.microsoft.com/library/azure/dn906025.aspx)) baseras på beslutsträd, en grundläggande koncept för maskininlärning.</span><span class="sxs-lookup"><span data-stu-id="43397-341">Decision forests ([regression](https://msdn.microsoft.com/library/azure/dn905862.aspx), [two-class](https://msdn.microsoft.com/library/azure/dn906008.aspx), and [multiclass](https://msdn.microsoft.com/library/azure/dn906015.aspx)), decision jungles ([two-class](https://msdn.microsoft.com/library/azure/dn905976.aspx) and [multiclass](https://msdn.microsoft.com/library/azure/dn905963.aspx)), and boosted decision trees ([regression](https://msdn.microsoft.com/library/azure/dn905801.aspx) and [two-class](https://msdn.microsoft.com/library/azure/dn906025.aspx)) are all based on decision trees, a foundational machine learning concept.</span></span> <span data-ttu-id="43397-342">Det finns många varianter av beslutsträd, men alla gör samma sak, dela in hello funktionen utrymme i regioner med mestadels hello samma etikett.</span><span class="sxs-lookup"><span data-stu-id="43397-342">There are many variants of decision trees, but they all do the same thing—subdivide hello feature space into regions with mostly hello same label.</span></span> <span data-ttu-id="43397-343">Dessa kan vara områden av konsekvent kategori eller konstant värde, beroende på om du gör klassificerings- eller regressionsmodell.</span><span class="sxs-lookup"><span data-stu-id="43397-343">These can be regions of consistent category or of constant value, depending on whether you are doing classification or regression.</span></span>

![Beslutsträdet delar upp en funktion utrymme][5]

<span data-ttu-id="43397-345">***Ett beslutsträd delar upp kan funktionen i områden av ungefär uniform värden***</span><span class="sxs-lookup"><span data-stu-id="43397-345">***A decision tree subdivides a feature space into regions of roughly uniform values***</span></span>

<span data-ttu-id="43397-346">Eftersom funktionen kan kan delas in i godtyckligt små områden, är det enkelt tooimagine att dela den buffertstorleken tillräckligt med toohave en datapunkt per region.</span><span class="sxs-lookup"><span data-stu-id="43397-346">Because a feature space can be subdivided into arbitrarily small regions, it's easy tooimagine dividing it finely enough toohave one data point per region.</span></span> <span data-ttu-id="43397-347">Detta är ett ytterst exempel på overfitting.</span><span class="sxs-lookup"><span data-stu-id="43397-347">This is an extreme example of overfitting.</span></span> <span data-ttu-id="43397-348">I ordning tooavoid detta en stor mängd träd är konstruerade med matematiska vidtas att hello träd inte korrelerade.</span><span class="sxs-lookup"><span data-stu-id="43397-348">In order tooavoid this, a large set of trees are constructed with special mathematical care taken that hello trees are not correlated.</span></span> <span data-ttu-id="43397-349">hello genomsnittet av den här ”beslut skogen” är ett träd som undviker overfitting.</span><span class="sxs-lookup"><span data-stu-id="43397-349">hello average of this "decision forest" is a tree that avoids overfitting.</span></span> <span data-ttu-id="43397-350">Beslut skogar kan använda mycket minne.</span><span class="sxs-lookup"><span data-stu-id="43397-350">Decision forests can use a lot of memory.</span></span> <span data-ttu-id="43397-351">Beslutsdjungler är en variant som förbrukar mindre minne på hello bekostnad av en längre utbildningstid.</span><span class="sxs-lookup"><span data-stu-id="43397-351">Decision jungles are a variant that consumes less memory at hello expense of a slightly longer training time.</span></span>

<span data-ttu-id="43397-352">Förstärkta beslutsträd undvika overfitting genom att begränsa hur många gånger som de kan du dela upp och hur många datapunkter är tillåtna i varje region.</span><span class="sxs-lookup"><span data-stu-id="43397-352">Boosted decision trees avoid overfitting by limiting how many times they can subdivide and how few data points are allowed in each region.</span></span> <span data-ttu-id="43397-353">Algoritmen skapar en sekvens med träd, där varje lär sig att kompensera för hello-fel som har lämnat hello trädet innan.</span><span class="sxs-lookup"><span data-stu-id="43397-353">The algorithm constructs a sequence of trees, each of which learns to compensate for hello error left by hello tree before.</span></span> <span data-ttu-id="43397-354">hello resultatet är en mycket noggrann deltagaren som tenderar toouse mycket minne.</span><span class="sxs-lookup"><span data-stu-id="43397-354">hello result is a very accurate learner that tends toouse a lot of memory.</span></span> <span data-ttu-id="43397-355">Hello fullständiga tekniska beskrivning, kolla [Friedmans ursprungliga dokumentet](http://www-stat.stanford.edu/~jhf/ftp/trebst.pdf).</span><span class="sxs-lookup"><span data-stu-id="43397-355">For hello full technical description, check out [Friedman's original paper](http://www-stat.stanford.edu/~jhf/ftp/trebst.pdf).</span></span>

<span data-ttu-id="43397-356">[Snabb skog quantile regression](https://msdn.microsoft.com/library/azure/dn913093.aspx) är en variation av beslutsträd för hello specialfall där du vill veta inte bara hello vanliga () medianvärdet för hello data i en region men motsvarande distribution i hello form av quantiles.</span><span class="sxs-lookup"><span data-stu-id="43397-356">[Fast forest quantile regression](https://msdn.microsoft.com/library/azure/dn913093.aspx) is a variation of decision trees for hello special case where you want to know not only hello typical (median) value of hello data within a region, but also its distribution in hello form of quantiles.</span></span>

### <a name="neural-networks-and-perceptrons"></a><span data-ttu-id="43397-357">Neurala nätverk och perceptrons</span><span class="sxs-lookup"><span data-stu-id="43397-357">Neural networks and perceptrons</span></span>
<span data-ttu-id="43397-358">Neurala nätverk är hjärna-inspirerat learning algoritmer som täcker [multiclass](https://msdn.microsoft.com/library/azure/dn906030.aspx), [tvåklass](https://msdn.microsoft.com/library/azure/dn905947.aspx), och [regression](https://msdn.microsoft.com/library/azure/dn905924.aspx) problem.</span><span class="sxs-lookup"><span data-stu-id="43397-358">Neural networks are brain-inspired learning algorithms covering [multiclass](https://msdn.microsoft.com/library/azure/dn906030.aspx), [two-class](https://msdn.microsoft.com/library/azure/dn905947.aspx), and [regression](https://msdn.microsoft.com/library/azure/dn905924.aspx) problems.</span></span> <span data-ttu-id="43397-359">De kommer i en rad, men hello neurala nätverk i Azure Machine Learning är alla hello form av riktat acykliskt diagram.</span><span class="sxs-lookup"><span data-stu-id="43397-359">They come in an infinite variety, but hello neural networks within Azure Machine Learning are all of hello form of directed acyclic graphs.</span></span> <span data-ttu-id="43397-360">Det innebär att inkommande funktioner skickas framåt (aldrig bakåt) via en sekvens av lager innan aktiveras i utdata.</span><span class="sxs-lookup"><span data-stu-id="43397-360">That means that input features are passed forward (never backward) through a sequence of layers before being turned into outputs.</span></span> <span data-ttu-id="43397-361">I varje lager viktas indata i olika kombinationer summeras och skickas till hello nästa lager.</span><span class="sxs-lookup"><span data-stu-id="43397-361">In each layer, inputs are weighted in various combinations, summed, and passed on to hello next layer.</span></span> <span data-ttu-id="43397-362">Den här kombinationen av enkla beräkningar resulterar i möjlighet toolearn sofistikerade klassen gränser och data trender till synes av Magiskt tal.</span><span class="sxs-lookup"><span data-stu-id="43397-362">This combination of simple calculations results in the ability toolearn sophisticated class boundaries and data trends, seemingly by magic.</span></span> <span data-ttu-id="43397-363">Många lager nätverk för den här typen utföra hello ”djup learning” som bränslen så mycket rapportering av teknisk och vetenskaplig fiktion.</span><span class="sxs-lookup"><span data-stu-id="43397-363">Many-layered networks of this sort perform hello "deep learning" that fuels so much tech reporting and science fiction.</span></span>

<span data-ttu-id="43397-364">Den här högpresterande finns inte gratis men.</span><span class="sxs-lookup"><span data-stu-id="43397-364">This high performance doesn't come for free, though.</span></span> <span data-ttu-id="43397-365">Neurala nätverk kan ta en lång tid tootrain, särskilt för stora datamängder med många funktioner.</span><span class="sxs-lookup"><span data-stu-id="43397-365">Neural networks can take a long time tootrain, particularly for large data sets with lots of features.</span></span> <span data-ttu-id="43397-366">De kan också ha fler parametrar än de flesta algoritmer, vilket innebär att parametern omfattande expanderar hello utbildningstid en hel del.</span><span class="sxs-lookup"><span data-stu-id="43397-366">They also have more parameters than most algorithms, which means that parameter sweeping expands hello training time a great deal.</span></span>
<span data-ttu-id="43397-367">Och för de overachievers som önskar för[ange sina egna nätverksstrukturen](http://go.microsoft.com/fwlink/?LinkId=402867), du kan använda inexhaustible.</span><span class="sxs-lookup"><span data-stu-id="43397-367">And for those overachievers who wish too[specify their own network structure](http://go.microsoft.com/fwlink/?LinkId=402867), the possibilities are inexhaustible.</span></span>

<span data-ttu-id="43397-368">![Gränser som upptäckts av neurala nätverk][6]
***hello gränser som upptäckts av neurala nätverk kan vara komplicerat och oregelbundna***</span><span class="sxs-lookup"><span data-stu-id="43397-368">![Boundaries learned by neural networks][6]
***hello boundaries learned by neural networks can be complex and irregular***</span></span>

<span data-ttu-id="43397-369">Hej [tvåklass var i genomsnitt perceptron](https://msdn.microsoft.com/library/azure/dn906036.aspx) neurala nätverk svaret tooskyrocketing utbildning gånger.</span><span class="sxs-lookup"><span data-stu-id="43397-369">hello [two-class averaged perceptron](https://msdn.microsoft.com/library/azure/dn906036.aspx) is neural networks' answer tooskyrocketing training times.</span></span> <span data-ttu-id="43397-370">Den använder en nätverksinfrastruktur som ger linjär klassgränser.</span><span class="sxs-lookup"><span data-stu-id="43397-370">It uses a network structure that gives linear class boundaries.</span></span> <span data-ttu-id="43397-371">Det är nästan primitiva dagens standarder, men den har en lång historik över robustly fungerar och är tillräckligt små toolearn snabbt.</span><span class="sxs-lookup"><span data-stu-id="43397-371">It is almost primitive by today's standards, but it has a long history of working robustly and is small enough toolearn quickly.</span></span>

### <a name="svms"></a><span data-ttu-id="43397-372">SVMs</span><span class="sxs-lookup"><span data-stu-id="43397-372">SVMs</span></span>
<span data-ttu-id="43397-373">Support vector datorer (SVMs) hitta hello gräns som avgränsar klasser av som bred en marginal som möjligt.</span><span class="sxs-lookup"><span data-stu-id="43397-373">Support vector machines (SVMs) find hello boundary that separates classes by as wide a margin as possible.</span></span> <span data-ttu-id="43397-374">När hello två klasser inte kan vara klart åtskilda, hitta hello algoritmer hello bästa gräns som de kan.</span><span class="sxs-lookup"><span data-stu-id="43397-374">When hello two classes can't be clearly separated, hello algorithms find hello best boundary they can.</span></span> <span data-ttu-id="43397-375">Som skrivits i Azure Machine Learning hello [tvåklass SVM](https://msdn.microsoft.com/library/azure/dn905835.aspx) gör detta med en rak linje.</span><span class="sxs-lookup"><span data-stu-id="43397-375">As written in Azure Machine Learning, hello [two-class SVM](https://msdn.microsoft.com/library/azure/dn905835.aspx) does this with a straight line only.</span></span> <span data-ttu-id="43397-376">(I SVM tala används en linjär kernel.) Eftersom det gör det här linjär uppskattning är kan toorun ganska snabbt.</span><span class="sxs-lookup"><span data-stu-id="43397-376">(In SVM-speak, it uses a linear kernel.) Because it makes this linear approximation, it is able toorun fairly quickly.</span></span> <span data-ttu-id="43397-377">Där det sin verkliga styrka är med funktionen intensiva data, t.ex. text eller genom.</span><span class="sxs-lookup"><span data-stu-id="43397-377">Where it really shines is with feature-intense data, like text or genomic.</span></span> <span data-ttu-id="43397-378">I dessa fall är SVMs kan tooseparate klasser snabbare och med mindre overfitting än de flesta andra algoritmer dessutom toorequiring bara en liten mängd minne.</span><span class="sxs-lookup"><span data-stu-id="43397-378">In these cases SVMs are able tooseparate classes more quickly and with less overfitting than most other algorithms, in addition toorequiring only a modest amount of memory.</span></span>

![Support vector machine klassen gräns][7]

<span data-ttu-id="43397-380">***En typisk support vector machine klass gräns maximerar hello marginal avgränsa två klasser***</span><span class="sxs-lookup"><span data-stu-id="43397-380">***A typical support vector machine class boundary maximizes hello margin separating two classes***</span></span>

<span data-ttu-id="43397-381">En annan produkt av Microsoft Research hello [tvåklass lokalt djup SVM](https://msdn.microsoft.com/library/azure/dn913070.aspx) är en icke-linjär variant av SVM som behåller de flesta av hello hastighet och minne effektivitet hello linjär version.</span><span class="sxs-lookup"><span data-stu-id="43397-381">Another product of Microsoft Research, hello [two-class locally deep SVM](https://msdn.microsoft.com/library/azure/dn913070.aspx) is a non-linear variant of SVM that retains most of hello speed and memory efficiency of hello linear version.</span></span> <span data-ttu-id="43397-382">Det är perfekt för fall där hello linjär metod inte får tillräckligt aktuell svar.</span><span class="sxs-lookup"><span data-stu-id="43397-382">It is ideal for cases where hello linear approach doesn't give accurate enough answers.</span></span> <span data-ttu-id="43397-383">hello utvecklare sparas det snabbt genom att bryta ned hello problem i flera mindre linjär SVM problem.</span><span class="sxs-lookup"><span data-stu-id="43397-383">hello developers kept it fast by breaking down hello problem into a bunch of small linear SVM problems.</span></span> <span data-ttu-id="43397-384">Läs hello [fullständig beskrivning](http://research.microsoft.com/um/people/manik/pubs/Jose13.pdf) hello information om hur de hämtas av den här lura.</span><span class="sxs-lookup"><span data-stu-id="43397-384">Read hello [full description](http://research.microsoft.com/um/people/manik/pubs/Jose13.pdf) for hello details on how they pulled off this trick.</span></span>

<span data-ttu-id="43397-385">Använder ett smarta tillägg av linjära SVMs hello [en klass SVM](https://msdn.microsoft.com/library/azure/dn913103.aspx) ritar en gräns som nära visar hello hela datauppsättningen.</span><span class="sxs-lookup"><span data-stu-id="43397-385">Using a clever extension of nonlinear SVMs, hello [one-class SVM](https://msdn.microsoft.com/library/azure/dn913103.aspx) draws a boundary that tightly outlines hello entire data set.</span></span> <span data-ttu-id="43397-386">Det är användbart för identifiering av avvikelse.</span><span class="sxs-lookup"><span data-stu-id="43397-386">It is useful for anomaly detection.</span></span> <span data-ttu-id="43397-387">Alla nya datapunkter som långt hamnar utanför gränsen är tillräckligt ovanliga toobe anmärkningsvärda.</span><span class="sxs-lookup"><span data-stu-id="43397-387">Any new data points that fall far outside that boundary are unusual enough toobe noteworthy.</span></span>

### <a name="bayesian-methods"></a><span data-ttu-id="43397-388">Bayesian metoder</span><span class="sxs-lookup"><span data-stu-id="43397-388">Bayesian methods</span></span>
<span data-ttu-id="43397-389">Bayesian metoder har en hög önskvärt kvalitet: de undvika overfitting.</span><span class="sxs-lookup"><span data-stu-id="43397-389">Bayesian methods have a highly desirable quality: they avoid overfitting.</span></span> <span data-ttu-id="43397-390">De kan göra detta genom att göra några antaganden i förväg om hello sannolikt distribution hello svar.</span><span class="sxs-lookup"><span data-stu-id="43397-390">They do this by making some assumptions beforehand about hello likely distribution of hello answer.</span></span> <span data-ttu-id="43397-391">En annan byproduct med den här metoden är att de har mycket några parametrar.</span><span class="sxs-lookup"><span data-stu-id="43397-391">Another byproduct of this approach is that they have very few parameters.</span></span> <span data-ttu-id="43397-392">Azure Machine Learning har båda Bayesian algoritmer för båda klassificering ([Two-class Bayes point-dator](https://msdn.microsoft.com/library/azure/dn905930.aspx)) och regression ([Bayesian linjär regression](https://msdn.microsoft.com/library/azure/dn906022.aspx)).</span><span class="sxs-lookup"><span data-stu-id="43397-392">Azure Machine Learning has both Bayesian algorithms for both classification ([Two-class Bayes' point machine](https://msdn.microsoft.com/library/azure/dn905930.aspx)) and regression ([Bayesian linear regression](https://msdn.microsoft.com/library/azure/dn906022.aspx)).</span></span>
<span data-ttu-id="43397-393">Observera att dessa förutsätter att hello data kan dela eller ryms inom rakt.</span><span class="sxs-lookup"><span data-stu-id="43397-393">Note that these assume that hello data can be split or fit with a straight line.</span></span>

<span data-ttu-id="43397-394">På en historisk anteckning utvecklades Bayes' point datorer Microsoft Research.</span><span class="sxs-lookup"><span data-stu-id="43397-394">On a historical note, Bayes' point machines were developed at Microsoft Research.</span></span> <span data-ttu-id="43397-395">De har vissa undantagsfall snygg teoretisk arbete bakomliggande.</span><span class="sxs-lookup"><span data-stu-id="43397-395">They have some exceptionally beautiful theoretical work behind them.</span></span> <span data-ttu-id="43397-396">hello berörda student är riktat toohello [ursprungliga artikeln i JMLR](http://jmlr.org/papers/volume1/herbrich01a/herbrich01a.pdf) och en [insiktsfulla blogg av Chris Bishop](http://blogs.technet.com/b/machinelearning/archive/2014/10/30/embracing-uncertainty-probabilistic-inference.aspx).</span><span class="sxs-lookup"><span data-stu-id="43397-396">hello interested student is directed toohello [original article in JMLR](http://jmlr.org/papers/volume1/herbrich01a/herbrich01a.pdf) and an [insightful blog by Chris Bishop](http://blogs.technet.com/b/machinelearning/archive/2014/10/30/embracing-uncertainty-probabilistic-inference.aspx).</span></span>

### <a name="specialized-algorithms"></a><span data-ttu-id="43397-397">Särskilda algoritmer</span><span class="sxs-lookup"><span data-stu-id="43397-397">Specialized algorithms</span></span>
<span data-ttu-id="43397-398">Om du har en särskild målet kanske tur.</span><span class="sxs-lookup"><span data-stu-id="43397-398">If you have a very specific goal you may be in luck.</span></span> <span data-ttu-id="43397-399">Hello Azure Machine Learning samlingen består av algoritmer som specialiserade på:</span><span class="sxs-lookup"><span data-stu-id="43397-399">Within hello Azure Machine Learning collection, there are algorithms that specialize in:</span></span>

- <span data-ttu-id="43397-400">rangordnas förutsägelse ([ordningstal regression](https://msdn.microsoft.com/library/azure/dn906029.aspx)),</span><span class="sxs-lookup"><span data-stu-id="43397-400">rank prediction ([ordinal regression](https://msdn.microsoft.com/library/azure/dn906029.aspx)),</span></span>
- <span data-ttu-id="43397-401">Räkna förutsägelse ([Poisson regression](https://msdn.microsoft.com/library/azure/dn905988.aspx)),</span><span class="sxs-lookup"><span data-stu-id="43397-401">count prediction ([Poisson regression](https://msdn.microsoft.com/library/azure/dn905988.aspx)),</span></span>
- <span data-ttu-id="43397-402">avvikelseidentifiering (en baserat på [huvudkomponenter analysis](https://msdn.microsoft.com/library/azure/dn913102.aspx) och baserat på ett [support vector machine](https://msdn.microsoft.com/library/azure/dn913103.aspx)s)</span><span class="sxs-lookup"><span data-stu-id="43397-402">anomaly detection (one based on [principal components analysis](https://msdn.microsoft.com/library/azure/dn913102.aspx) and one based on [support vector machine](https://msdn.microsoft.com/library/azure/dn913103.aspx)s)</span></span>
- <span data-ttu-id="43397-403">kluster ([K-means](https://msdn.microsoft.com/library/azure/5049a09b-bd90-4c4e-9b46-7c87e3a36810/))</span><span class="sxs-lookup"><span data-stu-id="43397-403">clustering ([K-means](https://msdn.microsoft.com/library/azure/5049a09b-bd90-4c4e-9b46-7c87e3a36810/))</span></span>

![PCA-baserad avvikelseidentifiering][8]

<span data-ttu-id="43397-405">***PCA-baserad avvikelseidentifiering*** *-hello majoriteten av hello data hamnar i en stereotypical distributionsplats; punkter kraftigt avviker från att distributionsplatsen är tveksam*</span><span class="sxs-lookup"><span data-stu-id="43397-405">***PCA-based anomaly detection*** *- hello vast majority of hello data falls into a stereotypical distribution; points deviating dramatically from that distribution are suspect*</span></span>

![Datauppsättning grupperas med K-means][9]

<span data-ttu-id="43397-407">***En datauppsättning är grupperade i fem kluster med hjälp av K-means***</span><span class="sxs-lookup"><span data-stu-id="43397-407">***A data set is grouped into five clusters using K-means***</span></span>

<span data-ttu-id="43397-408">Det finns också en ensemble [en v alla multiklass-baserad klassificerare](https://msdn.microsoft.com/library/azure/dn905887.aspx), vilka problem radbrytningar hello N-klass klassificering N-1 tvåklass klassificering problem.</span><span class="sxs-lookup"><span data-stu-id="43397-408">There is also an ensemble [one-v-all multiclass classifier](https://msdn.microsoft.com/library/azure/dn905887.aspx), which breaks hello N-class classification problem into N-1 two-class classification problems.</span></span> <span data-ttu-id="43397-409">hello noggrannhet, utbildning och linearitet egenskaper bestäms av hello tvåklass klassificerare används.</span><span class="sxs-lookup"><span data-stu-id="43397-409">hello accuracy, training time, and linearity properties are determined by hello two-class classifiers used.</span></span>

![Två-klass, klassificerare kombineras tooform en klassificerare tre-klass][10]

<span data-ttu-id="43397-411">***Ett par med två-klass, klassificerare kombinera tooform en klassificerare tre-klass***</span><span class="sxs-lookup"><span data-stu-id="43397-411">***A pair of two-class classifiers combine tooform a three-class classifier***</span></span>

<span data-ttu-id="43397-412">Azure Machine Learning har även åtkomst tooa kraftfulla maskininlärning framework under hello rubrik [Vowpal Wabbit](https://msdn.microsoft.com/library/azure/8383eb49-c0a3-45db-95c8-eb56a1fef5bf).</span><span class="sxs-lookup"><span data-stu-id="43397-412">Azure Machine Learning also includes access tooa powerful machine learning framework under hello title of [Vowpal Wabbit](https://msdn.microsoft.com/library/azure/8383eb49-c0a3-45db-95c8-eb56a1fef5bf).</span></span>
<span data-ttu-id="43397-413">VW lekfull kategorisering här, eftersom den kan lära dig klassificerings- och regression problem och kan även lära sig från delvis omärkta data.</span><span class="sxs-lookup"><span data-stu-id="43397-413">VW defies categorization here, since it can learn both classification and regression problems and can even learn from partially unlabeled data.</span></span> <span data-ttu-id="43397-414">Du kan konfigurera den toouse någon av ett antal learning, förlust funktioner och optimering algoritmer.</span><span class="sxs-lookup"><span data-stu-id="43397-414">You can configure it toouse any one of a number of learning algorithms, loss functions, and optimization algorithms.</span></span> <span data-ttu-id="43397-415">Den utformades från hello bakgrund in toobe effektivt parallellt och mycket snabbt.</span><span class="sxs-lookup"><span data-stu-id="43397-415">It was designed from hello ground up toobe efficient, parallel, and extremely fast.</span></span> <span data-ttu-id="43397-416">Den hanterar funktionen löjligt stora mängder med mycket tydligt ansträngning.</span><span class="sxs-lookup"><span data-stu-id="43397-416">It handles ridiculously large feature sets with little apparent effort.</span></span>
<span data-ttu-id="43397-417">Igång och lett av Microsoft Researchs egna John Langford är VW en formel en post i ett fält av börs bil algoritmer.</span><span class="sxs-lookup"><span data-stu-id="43397-417">Started and led by Microsoft Research's own John Langford, VW is a Formula One entry in a field of stock car algorithms.</span></span> <span data-ttu-id="43397-418">Inte alla problem som passar VW men om den det kan vara värt att din stund tooclimb inlärningskurvan på dess gränssnitt.</span><span class="sxs-lookup"><span data-stu-id="43397-418">Not every problem fits VW, but if yours does, it may be worth your while tooclimb the learning curve on its interface.</span></span> <span data-ttu-id="43397-419">Det är också tillgängliga som [fristående öppen källkod](https://github.com/JohnLangford/vowpal_wabbit) på flera språk.</span><span class="sxs-lookup"><span data-stu-id="43397-419">It's also available as [stand-alone open source code](https://github.com/JohnLangford/vowpal_wabbit) in several languages.</span></span>

## <a name="more-help-with-algorithms"></a><span data-ttu-id="43397-420">Mer hjälp med algoritmer</span><span class="sxs-lookup"><span data-stu-id="43397-420">More help with algorithms</span></span>
* <span data-ttu-id="43397-421">En nedladdningsbar infographic som beskriver algoritmer och exempel finns [nedladdningsbara Infographic: maskin lär du dig grunderna med algoritmen exempel](machine-learning-basics-infographic-with-algorithm-examples.md).</span><span class="sxs-lookup"><span data-stu-id="43397-421">For a downloadable infographic that describes algorithms and provides examples, see [Downloadable Infographic: Machine learning basics with algorithm examples](machine-learning-basics-infographic-with-algorithm-examples.md).</span></span>
* <span data-ttu-id="43397-422">En lista efter kategori av alla hello maskininlärningsalgoritmer tillgängliga i Azure Machine Learning Studio finns [initiera modell] [ initialize-model] i modulen hjälpen och hello Machine Learning Studio-algoritmen.</span><span class="sxs-lookup"><span data-stu-id="43397-422">For a list by category of all hello machine learning algorithms available in Azure Machine Learning Studio, see [Initialize Model][initialize-model] in hello Machine Learning Studio Algorithm and Module Help.</span></span>
* <span data-ttu-id="43397-423">En fullständig alfabetisk lista över algoritmer och moduler i Azure Machine Learning Studio finns [A-Ö-listan över Machine Learning Studio moduler] [ a-z-list] i Machine Learning Studio algoritmen och hjälpa till att modulen.</span><span class="sxs-lookup"><span data-stu-id="43397-423">For a complete alphabetical list of algorithms and modules in Azure Machine Learning Studio, see [A-Z list of Machine Learning Studio modules][a-z-list] in Machine Learning Studio Algorithm and Module Help.</span></span>
* <span data-ttu-id="43397-424">toodownload och skriva ut ett diagram som ger en översikt över hello funktioner i Azure Machine Learning Studio finns [Översiktsdiagram över funktioner i Azure Machine Learning Studio i](machine-learning-studio-overview-diagram.md).</span><span class="sxs-lookup"><span data-stu-id="43397-424">toodownload and print a diagram that gives an overview of hello capabilities of Azure Machine Learning Studio, see [Overview diagram of Azure Machine Learning Studio capabilities](machine-learning-studio-overview-diagram.md).</span></span>


<!-- Reference links -->
[initialize-model]: https://msdn.microsoft.com/library/azure/dn905812.aspx
[a-z-list]: https://msdn.microsoft.com/library/azure/dn906033.aspx

<!-- Media -->

[1]: ./media/machine-learning-algorithm-choice/image1.png
[2]: ./media/machine-learning-algorithm-choice/image2.png
[3]: ./media/machine-learning-algorithm-choice/image3.png
[4]: ./media/machine-learning-algorithm-choice/image4.png
[5]: ./media/machine-learning-algorithm-choice/image5.png
[6]: ./media/machine-learning-algorithm-choice/image6.png
[7]: ./media/machine-learning-algorithm-choice/image7.png
[8]: ./media/machine-learning-algorithm-choice/image8.png
[9]: ./media/machine-learning-algorithm-choice/image9.png
[10]: ./media/machine-learning-algorithm-choice/image10.png
