---
title: "Översikt över datavetenskap med Spark på Azure HDInsight | Microsoft Docs"
description: "Spark MLlib toolkit ger betydande maskininlärning integrera affärsmodelleringsfunktioner för distribuerade HDInsight-miljö."
services: machine-learning
documentationcenter: 
author: bradsev
manager: jhubbard
editor: cgronlun
ms.assetid: a4e1de99-a554-4240-9647-2c6d669593c8
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/15/2017
ms.author: deguhath;bradsev;gokuma
ms.openlocfilehash: 379b32f4e533f48f1593a97e73737a0c5bfb9135
ms.sourcegitcommit: f537befafb079256fba0529ee554c034d73f36b0
ms.translationtype: MT
ms.contentlocale: sv-SE
ms.lasthandoff: 07/11/2017
---
# <a name="overview-of-data-science-using-spark-on-azure-hdinsight"></a><span data-ttu-id="4f93b-103">Översikt över datavetenskap med Spark på Azure HDInsight</span><span class="sxs-lookup"><span data-stu-id="4f93b-103">Overview of data science using Spark on Azure HDInsight</span></span>
[!INCLUDE [machine-learning-spark-modeling](../../includes/machine-learning-spark-modeling.md)]

<span data-ttu-id="4f93b-104">Den här sviten avsnitt visar hur du använder HDInsight Spark slutföra vanliga datavetenskap åtgärder, till exempel datapåfyllning, funktionen tekniker, modellering och utvärdering av modellen.</span><span class="sxs-lookup"><span data-stu-id="4f93b-104">This suite of topics shows how to use HDInsight Spark to complete common data science tasks such as data ingestion, feature engineering, modeling, and model evaluation.</span></span> <span data-ttu-id="4f93b-105">De data som används är ett exempel på 2013 NYC taxi resa och avgiften dataset.</span><span class="sxs-lookup"><span data-stu-id="4f93b-105">The data used is a sample of the 2013 NYC taxi trip and fare dataset.</span></span> <span data-ttu-id="4f93b-106">Modeller som skapats är logistic och linjär regression, slumpmässiga skogar och toning ökat träd.</span><span class="sxs-lookup"><span data-stu-id="4f93b-106">The models built include logistic and linear regression, random forests, and gradient boosted trees.</span></span> <span data-ttu-id="4f93b-107">Avsnitten visar även hur du lagrar dessa modeller i Azure blob storage (WASB) och hur du poängsätta och utvärdera deras förutsägbar prestanda.</span><span class="sxs-lookup"><span data-stu-id="4f93b-107">The topics also show how to store these models in Azure blob storage (WASB) and how to score and evaluate their predictive performance.</span></span> <span data-ttu-id="4f93b-108">Mer avancerade avsnitt beskriver hur modeller kan vara tränas med omfattande korsvalidering och hyper-parametern.</span><span class="sxs-lookup"><span data-stu-id="4f93b-108">More advanced topics cover how models can be trained using cross-validation and hyper-parameter sweeping.</span></span> <span data-ttu-id="4f93b-109">Det här översiktsavsnittet refererar även till avsnitt som beskriver hur du ställer in Spark-klustret som du måste slutföra stegen i anvisningarna tillgängliga.</span><span class="sxs-lookup"><span data-stu-id="4f93b-109">This overview topic also references the topics that describe how to set up the Spark cluster that you need to complete the steps in the walkthroughs provided.</span></span> 

## <a name="spark-and-mllib"></a><span data-ttu-id="4f93b-110">Spark och MLlib</span><span class="sxs-lookup"><span data-stu-id="4f93b-110">Spark and MLlib</span></span>
<span data-ttu-id="4f93b-111">[Spark](http://spark.apache.org/) är ett ramverk för parallellbearbetning med öppen källkod som stöder minnesintern bearbetning för att höja prestandan för stora program för stordataanalys.</span><span class="sxs-lookup"><span data-stu-id="4f93b-111">[Spark](http://spark.apache.org/) is an open-source parallel processing framework that supports in-memory processing to boost the performance of big-data analytic applications.</span></span> <span data-ttu-id="4f93b-112">Bearbetningsmotorn i Spark är byggd för hastighet, enkel användning och avancerade analyser.</span><span class="sxs-lookup"><span data-stu-id="4f93b-112">The Spark processing engine is built for speed, ease of use, and sophisticated analytics.</span></span> <span data-ttu-id="4f93b-113">Sparks funktioner för beräkning för distribuerade i minnet gör det ett bra alternativ för iterativa algoritmer i machine learning och grafberäkningar.</span><span class="sxs-lookup"><span data-stu-id="4f93b-113">Spark's in-memory distributed computation capabilities make it a good choice for the iterative algorithms used in machine learning and graph computations.</span></span> <span data-ttu-id="4f93b-114">[MLlib](http://spark.apache.org/mllib/) är Sparks skalbara machine learning bibliotek som ger den algoritmbaserade modeling funktioner för den här distribuerad miljö.</span><span class="sxs-lookup"><span data-stu-id="4f93b-114">[MLlib](http://spark.apache.org/mllib/) is Spark's scalable machine learning library that brings the algorithmic modeling capabilities to this distributed environment.</span></span> 

## <a name="hdinsight-spark"></a><span data-ttu-id="4f93b-115">HDInsight Spark</span><span class="sxs-lookup"><span data-stu-id="4f93b-115">HDInsight Spark</span></span>
<span data-ttu-id="4f93b-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) är öppen källkod Spark Azure värdbaserade erbjuds.</span><span class="sxs-lookup"><span data-stu-id="4f93b-116">[HDInsight Spark](../hdinsight/hdinsight-apache-spark-overview.md) is the Azure hosted offering of open-source Spark.</span></span> <span data-ttu-id="4f93b-117">Den omfattar också stöd för **Jupyter PySpark-anteckningsböcker** i Spark-klustret som kan köra interaktiva Spark SQL-frågor för att omvandla, filtrering och visualisera data som lagras i Azure BLOB (WASB).</span><span class="sxs-lookup"><span data-stu-id="4f93b-117">It also includes support for **Jupyter PySpark notebooks** on the Spark cluster that can run Spark SQL interactive queries for transforming, filtering, and visualizing data stored in Azure Blobs (WASB).</span></span> <span data-ttu-id="4f93b-118">PySpark är Python-API för Spark.</span><span class="sxs-lookup"><span data-stu-id="4f93b-118">PySpark is the Python API for Spark.</span></span> <span data-ttu-id="4f93b-119">Kodstycken som tillhandahåller lösningarna och visa de relevanta områdena visualisera data här köras i Jupyter-anteckningsböcker som är installerad på Spark-kluster.</span><span class="sxs-lookup"><span data-stu-id="4f93b-119">The code snippets that provide the solutions and show the relevant plots to visualize the data here run in Jupyter notebooks installed on the Spark clusters.</span></span> <span data-ttu-id="4f93b-120">Modellering stegen i följande avsnitt innehåller kod som visar hur du träna, utvärdera, spara och använda varje typ av modellen.</span><span class="sxs-lookup"><span data-stu-id="4f93b-120">The modeling steps in these topics contain code that shows how to train, evaluate, save, and consume each type of model.</span></span> 

## <a name="setup-spark-clusters-and-jupyter-notebooks"></a><span data-ttu-id="4f93b-121">Installationsprogrammet: Spark-kluster och Jupyter-anteckningsböcker</span><span class="sxs-lookup"><span data-stu-id="4f93b-121">Setup: Spark clusters and Jupyter notebooks</span></span>
<span data-ttu-id="4f93b-122">Konfigurationsstegen och kod finns i den här genomgången för att använda ett HDInsight Spark 1.6.</span><span class="sxs-lookup"><span data-stu-id="4f93b-122">Setup steps and code are provided in this walkthrough for using an HDInsight Spark 1.6.</span></span> <span data-ttu-id="4f93b-123">Men Jupyter-anteckningsböcker som har angetts för både HDInsight Spark 1.6 och 2.0 Spark-kluster.</span><span class="sxs-lookup"><span data-stu-id="4f93b-123">But Jupyter notebooks are provided for both HDInsight Spark 1.6 and Spark 2.0 clusters.</span></span> <span data-ttu-id="4f93b-124">En beskrivning av bärbara datorer och länkar till dem finns i den [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) för GitHub-lagringsplats som innehåller dessa.</span><span class="sxs-lookup"><span data-stu-id="4f93b-124">A description of the notebooks and links to them are provided in the [Readme.md](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Readme.md) for the GitHub repository containing them.</span></span> <span data-ttu-id="4f93b-125">Dessutom koden här länkade anteckningsböcker är generisk och bör fungera på Spark-kluster.</span><span class="sxs-lookup"><span data-stu-id="4f93b-125">Moreover, the code here and in the linked notebooks is generic and should work on any Spark cluster.</span></span> <span data-ttu-id="4f93b-126">Om du inte använder HDInsight Spark kanske klustret installation och hantering av stegen skiljer sig från vad som anges här.</span><span class="sxs-lookup"><span data-stu-id="4f93b-126">If you are not using HDInsight Spark, the cluster setup and management steps may be slightly different from what is shown here.</span></span> <span data-ttu-id="4f93b-127">För enkelhetens skull är här länkar till Jupyter-anteckningsböcker för Spark 1.6 (för att köras i pySpark-kerneln Jupyter Notebook-Server) och Spark 2.0 (för att köras i kernelns pySpark3 Jupyter-anteckningsbok Server):</span><span class="sxs-lookup"><span data-stu-id="4f93b-127">For convenience, here are the links to the Jupyter notebooks for Spark 1.6 (to be run in the pySpark kernel of the Jupyter Notebook server) and  Spark 2.0 (to be run in the pySpark3 kernel of the Jupyter Notebook server):</span></span>

### <a name="spark-16-notebooks"></a><span data-ttu-id="4f93b-128">Spark 1.6 bärbara datorer</span><span class="sxs-lookup"><span data-stu-id="4f93b-128">Spark 1.6 notebooks</span></span>
<span data-ttu-id="4f93b-129">Dessa datorer är att köras i pySpark-kerneln Jupyter-anteckningsbok Server.</span><span class="sxs-lookup"><span data-stu-id="4f93b-129">These notebooks are to be run in the pySpark kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="4f93b-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): innehåller information om hur du utför datagranskning modellering och bedömningen med flera olika algoritmer.</span><span class="sxs-lookup"><span data-stu-id="4f93b-130">[pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-data-exploration-modeling.ipynb): Provides information on how to perform data exploration, modeling, and scoring with several different algorithms.</span></span>
- <span data-ttu-id="4f93b-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): innehåller avsnitt i anteckningsboken #1 och modellen utveckling med hjälp av hyperparameter justering och korsvalidering.</span><span class="sxs-lookup"><span data-stu-id="4f93b-131">[pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): Includes topics in notebook #1, and model development using hyperparameter tuning and cross-validation.</span></span>
- <span data-ttu-id="4f93b-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): Visar hur du operationalisera en sparad modell med Python på HDInsight-kluster.</span><span class="sxs-lookup"><span data-stu-id="4f93b-132">[pySpark-machine-learning-data-science-spark-model-consumption.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb): Shows how to operationalize a saved model using Python on HDInsight clusters.</span></span>

### <a name="spark-20-notebooks"></a><span data-ttu-id="4f93b-133">Spark 2.0 bärbara datorer</span><span class="sxs-lookup"><span data-stu-id="4f93b-133">Spark 2.0 notebooks</span></span>
<span data-ttu-id="4f93b-134">Dessa datorer är att köra i kernelns pySpark3 Jupyter-anteckningsbok Server.</span><span class="sxs-lookup"><span data-stu-id="4f93b-134">These notebooks are to be run in the pySpark3 kernel of Jupyter notebook server.</span></span>

- <span data-ttu-id="4f93b-135">[Spark2.0-pySpark3-Machine-Learning-data-Science-Spark-Advanced-data-exploration-Modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): den här filen innehåller information om hur du utför datagranskning modellering, och bedömningen i Spark 2.0-kluster med NYC Taxi resa och avgiften datauppsättning beskrivs [här](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="4f93b-135">[Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb): This file provides information on how to perform data exploration, modeling, and scoring in Spark 2.0 clusters using the NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span> <span data-ttu-id="4f93b-136">Den här anteckningsboken kan vara en bra utgångspunkt för att snabbt utforska koden som vi har angetts för Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="4f93b-136">This notebook may be a good starting point for quickly exploring the code we have provided for Spark 2.0.</span></span> <span data-ttu-id="4f93b-137">För en mer detaljerad anteckningsbok analyserar NYC Taxi data, finns i nästa anteckningsboken i den här listan.</span><span class="sxs-lookup"><span data-stu-id="4f93b-137">For a more detailed notebook analyzes the NYC Taxi data, see the next notebook in this list.</span></span> <span data-ttu-id="4f93b-138">Om du hittar information efter den här listan som jämför dessa datorer.</span><span class="sxs-lookup"><span data-stu-id="4f93b-138">See the notes following this list that compare these notebooks.</span></span> 
- <span data-ttu-id="4f93b-139">[Spark2.0 pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): den här filen visar hur du utför data wrangling (Spark SQL och dataframe operations), utforskning modellering och bedömningen med NYC Taxi resa och avgiften datauppsättning beskrivs [här](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span><span class="sxs-lookup"><span data-stu-id="4f93b-139">[Spark2.0-pySpark3_NYC_Taxi_Tip_Regression.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_NYC_Taxi_Tip_Regression.ipynb): This file shows how to perform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using the NYC Taxi trip and fare data-set described [here](https://docs.microsoft.com/en-us/azure/machine-learning/machine-learning-data-science-spark-overview#the-nyc-2013-taxi-data).</span></span>
- <span data-ttu-id="4f93b-140">[Spark2.0 pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): den här filen visar hur du utför data wrangling (Spark SQL och dataframe operations), utforskning modellering och bedömningen med välkända flygbolag i tid avvikelse datauppsättningen från 2011 och 2012.</span><span class="sxs-lookup"><span data-stu-id="4f93b-140">[Spark2.0-pySpark3_Airline_Departure_Delay_Classification.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0_pySpark3_Airline_Departure_Delay_Classification.ipynb): This file shows how to perform data wrangling (Spark SQL and dataframe operations), exploration, modeling and scoring using the well-known Airline On-time departure dataset from 2011 and 2012.</span></span> <span data-ttu-id="4f93b-141">Vi integrerad flygbolag dataset med flygplats väder data (t.ex. vindhastigheten temperatur, höjd etc.) innan du modellera, så att funktionerna väder kan ingå i modellen.</span><span class="sxs-lookup"><span data-stu-id="4f93b-141">We integrated the airline dataset with the airport weather data (e.g. windspeed, temperature, altitude etc.) prior to modeling, so these weather features can be included in the model.</span></span>

<!-- -->

> [!NOTE]
> <span data-ttu-id="4f93b-142">Flygbolag datamängden har lagts till Spark 2.0 bärbara datorer att illustrera bättre användning av algoritmer för klassificering.</span><span class="sxs-lookup"><span data-stu-id="4f93b-142">The airline dataset was added to the Spark 2.0 notebooks to better illustrate the use of classification algorithms.</span></span> <span data-ttu-id="4f93b-143">Se följande länkar för information om flygbolag i tid avvikelse dataset och väder datamängd:</span><span class="sxs-lookup"><span data-stu-id="4f93b-143">See the following links for information about airline on-time departure dataset and weather dataset:</span></span>

>- <span data-ttu-id="4f93b-144">Flygbolag i tid avvikelse data: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span><span class="sxs-lookup"><span data-stu-id="4f93b-144">Airline on-time departure data: [http://www.transtats.bts.gov/ONTIME/](http://www.transtats.bts.gov/ONTIME/)</span></span>

>- <span data-ttu-id="4f93b-145">Flygplats väder data: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span><span class="sxs-lookup"><span data-stu-id="4f93b-145">Airport weather data: [https://www.ncdc.noaa.gov/](https://www.ncdc.noaa.gov/)</span></span> 
> 
> 

<!-- -->

<!-- -->

> [!NOTE]
<span data-ttu-id="4f93b-146">Spark 2.0 anteckningsböcker på NYC taxi och flygbolag svarta fördröjning-datauppsättningar kan ta 10 minuter eller mer att köra (beroende på storleken på HDI-kluster).</span><span class="sxs-lookup"><span data-stu-id="4f93b-146">The Spark 2.0 notebooks on the NYC taxi and airline flight delay data-sets can take 10 mins or more to run (depending on the size of your HDI cluster).</span></span> <span data-ttu-id="4f93b-147">Första anteckningsboken i listan ovan visas många aspekter av datagranskning, visualisering och ML-modell utbildning i en bärbar dator som det tar mindre tid att köra med ned provtagning NYC datamängd, där taxi och avgiften filer har redan anslutits: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) anteckningsboken tar mycket kortare tid att slutföra (2-3 minuter) och kan vara en bra utgångspunkt för snabbt utforska koden som vi har angetts för Spark 2.0.</span><span class="sxs-lookup"><span data-stu-id="4f93b-147">The first notebook in the above list shows many aspects of the data exploration, visualization and ML model training in a notebook that takes less time to run with down-sampled NYC data set, in which the taxi and fare files have been pre-joined: [Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark2.0/Spark2.0-pySpark3-machine-learning-data-science-spark-advanced-data-exploration-modeling.ipynb) This notebook takes a much shorter time to finish (2-3 mins) and may be a good starting point for quickly exploring the code we have provided for Spark 2.0.</span></span> 

<!-- -->

<span data-ttu-id="4f93b-148">Vägledning om operationalization av en Spark 2.0 och modellen förbrukningen för resultatfunktioner finns i [Spark 1.6 dokumentet på förbrukningen](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) ett exempel som beskriver de steg som krävs.</span><span class="sxs-lookup"><span data-stu-id="4f93b-148">For guidance on the operationalization of a Spark 2.0 model and model consumption for scoring, see the [Spark 1.6 document on consumption](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/pySpark/Spark1.6/pySpark-machine-learning-data-science-spark-model-consumption.ipynb) for an example outlining the steps required.</span></span> <span data-ttu-id="4f93b-149">Om du vill använda detta på Spark 2.0, ersätter filen Python-kod med [filen](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span><span class="sxs-lookup"><span data-stu-id="4f93b-149">To use this on Spark 2.0, replace the Python code file with [this file](https://github.com/Azure/Azure-MachineLearning-DataScience/blob/master/Misc/Spark/Python/Spark2.0_ConsumeRFCV_NYCReg.py).</span></span>

### <a name="prerequisites"></a><span data-ttu-id="4f93b-150">Krav</span><span class="sxs-lookup"><span data-stu-id="4f93b-150">Prerequisites</span></span>
<span data-ttu-id="4f93b-151">Följande procedurer relaterade till Spark 1.6.</span><span class="sxs-lookup"><span data-stu-id="4f93b-151">The following procedures are related to Spark 1.6.</span></span> <span data-ttu-id="4f93b-152">Använd anteckningsböcker beskrivs och länka till tidigare Spark 2.0-versionen.</span><span class="sxs-lookup"><span data-stu-id="4f93b-152">For  the Spark 2.0 version, use the notebooks described and linked to previously.</span></span> 

<span data-ttu-id="4f93b-153">1. Du måste ha en Azure-prenumeration.</span><span class="sxs-lookup"><span data-stu-id="4f93b-153">1.You must have an Azure subscription.</span></span> <span data-ttu-id="4f93b-154">Om du inte redan har en, se [hämta kostnadsfri utvärderingsversion av Azure](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span><span class="sxs-lookup"><span data-stu-id="4f93b-154">If you do not already have one, see [Get Azure free trial](https://azure.microsoft.com/documentation/videos/get-azure-free-trial-for-testing-hadoop-in-hdinsight/).</span></span>

<span data-ttu-id="4f93b-155">2. måste en 1.6 Spark-klustret för att slutföra den här genomgången.</span><span class="sxs-lookup"><span data-stu-id="4f93b-155">2.You need a Spark 1.6 cluster to complete this walkthrough.</span></span> <span data-ttu-id="4f93b-156">Om du vill skapa en finns i [komma igång: skapa Apache Spark på Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span><span class="sxs-lookup"><span data-stu-id="4f93b-156">To create one, see the instructions provided in [Get started: create Apache Spark on Azure HDInsight](../hdinsight/hdinsight-apache-spark-jupyter-spark-sql.md).</span></span> <span data-ttu-id="4f93b-157">Typ av kluster och version har angetts från den **Välj typ av kluster** menyn.</span><span class="sxs-lookup"><span data-stu-id="4f93b-157">The cluster type and version is specified from the **Select Cluster Type** menu.</span></span> 

![Konfigurera klustret](./media/machine-learning-data-science-spark-overview/spark-cluster-on-portal.png)

<!-- -->

> [!NOTE]
> <span data-ttu-id="4f93b-159">Ett avsnitt som visar hur du utföra uppgifter för vetenskap en slutpunkt till slutpunkt av data med hjälp av Scala i stället för Python, finns det [datavetenskap med hjälp av Scala med Spark på Azure](machine-learning-data-science-process-scala-walkthrough.md).</span><span class="sxs-lookup"><span data-stu-id="4f93b-159">For a topic that shows how to use Scala rather than Python to complete tasks for an end-to-end data science process, see the [Data Science using Scala with Spark on Azure](machine-learning-data-science-process-scala-walkthrough.md).</span></span>
> 
> 

<!-- -->

> [!INCLUDE [delete-cluster-warning](../../includes/hdinsight-delete-cluster-warning.md)]
> 
> 

## <a name="the-nyc-2013-taxi-data"></a><span data-ttu-id="4f93b-160">NYC 2013 Taxi data</span><span class="sxs-lookup"><span data-stu-id="4f93b-160">The NYC 2013 Taxi data</span></span>
<span data-ttu-id="4f93b-161">NYC Taxi resa data är cirka 20 GB komprimerad fil med kommaavgränsade värden (CSV)-filer (~ 48 GB okomprimerade), som består av fler än 173 miljoner enskilda resor och priser betalat för varje resa.</span><span class="sxs-lookup"><span data-stu-id="4f93b-161">The NYC Taxi Trip data is about 20 GB of compressed comma-separated values (CSV) files (~48 GB uncompressed), comprising more than 173 million individual trips and the fares paid for each trip.</span></span> <span data-ttu-id="4f93b-162">Varje post resa innehåller plocka upp och Samlingsbibliotek plats och tid, anonymiserade hackare (drivrutin) licensnummer och medallion (taxi's unikt id) nummer.</span><span class="sxs-lookup"><span data-stu-id="4f93b-162">Each trip record includes the pick up and drop-off location and time, anonymized hack (driver's) license number and medallion (taxi’s unique id) number.</span></span> <span data-ttu-id="4f93b-163">Data omfattar alla resor år 2013 och finns i följande två datauppsättningar för varje månad:</span><span class="sxs-lookup"><span data-stu-id="4f93b-163">The data covers all trips in the year 2013 and is provided in the following two datasets for each month:</span></span>

1. <span data-ttu-id="4f93b-164">'Trip_data' CSV-filer innehåller resa information, till exempel antalet passagerare, hämta och dropoff pekar utlösas varaktighet och resa längd.</span><span class="sxs-lookup"><span data-stu-id="4f93b-164">The 'trip_data' CSV files contain trip details, such as number of passengers, pick up and dropoff points, trip duration, and trip length.</span></span> <span data-ttu-id="4f93b-165">Här följer några Exempelposter:</span><span class="sxs-lookup"><span data-stu-id="4f93b-165">Here are a few sample records:</span></span>
   
        medallion,hack_license,vendor_id,rate_code,store_and_fwd_flag,pickup_datetime,dropoff_datetime,passenger_count,trip_time_in_secs,trip_distance,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,1,N,2013-01-01 15:11:48,2013-01-01 15:18:10,4,382,1.00,-73.978165,40.757977,-73.989838,40.751171
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-06 00:18:35,2013-01-06 00:22:54,1,259,1.50,-74.006683,40.731781,-73.994499,40.75066
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,1,N,2013-01-05 18:49:41,2013-01-05 18:54:23,1,282,1.10,-74.004707,40.73777,-74.009834,40.726002
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:54:15,2013-01-07 23:58:20,2,244,.70,-73.974602,40.759945,-73.984734,40.759388
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,1,N,2013-01-07 23:25:03,2013-01-07 23:34:24,1,560,2.10,-73.97625,40.748528,-74.002586,40.747868
2. <span data-ttu-id="4f93b-166">'Trip_fare' CSV-filer innehåller information om avgiften betalat för varje förflyttning, till exempel betalningssätt, avgiften belopp, tillägg och skatter, tips och vägtullar, och det totala betald.</span><span class="sxs-lookup"><span data-stu-id="4f93b-166">The 'trip_fare' CSV files contain details of the fare paid for each trip, such as payment type, fare amount, surcharge and taxes, tips and tolls, and the total amount paid.</span></span> <span data-ttu-id="4f93b-167">Här följer några Exempelposter:</span><span class="sxs-lookup"><span data-stu-id="4f93b-167">Here are a few sample records:</span></span>
   
        medallion, hack_license, vendor_id, pickup_datetime, payment_type, fare_amount, surcharge, mta_tax, tip_amount, tolls_amount, total_amount
        89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT,2013-01-01 15:11:48,CSH,6.5,0,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-06 00:18:35,CSH,6,0.5,0.5,0,0,7
        0BD7C8F5BA12B88E0B67BED28BEA73D8,9FD8F69F0804BDB5549F40E9DA1BE472,CMT,2013-01-05 18:49:41,CSH,5.5,1,0.5,0,0,7
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:54:15,CSH,5,0.5,0.5,0,0,6
        DFD2202EE08F7A8DC9A57B02ACB81FE2,51EE87E3205C985EF8431D850C786310,CMT,2013-01-07 23:25:03,CSH,9.5,0.5,0.5,0,0,10.5

<span data-ttu-id="4f93b-168">Vi har tagit en 0,1% exempel på dessa filer och ansluten resan\_data och resa\_färdavgiften CSV-filer i en enda datamängd som används som indata datamängden för den här genomgången.</span><span class="sxs-lookup"><span data-stu-id="4f93b-168">We have taken a 0.1% sample of these files and joined the trip\_data and trip\_fare CVS files into a single dataset to use as the input dataset for this walkthrough.</span></span> <span data-ttu-id="4f93b-169">Unik nyckel för att ansluta till resa\_data och resa\_avgiften består av fälten: medallion hackare\_licensen och hämtning\_datetime.</span><span class="sxs-lookup"><span data-stu-id="4f93b-169">The unique key to join trip\_data and trip\_fare is composed of the fields: medallion, hack\_licence and pickup\_datetime.</span></span> <span data-ttu-id="4f93b-170">Varje post i datauppsättningen innehåller följande attribut som representerar en NYC Taxi resa:</span><span class="sxs-lookup"><span data-stu-id="4f93b-170">Each record of the dataset contains the following attributes representing a NYC Taxi trip:</span></span>

| <span data-ttu-id="4f93b-171">Fält</span><span class="sxs-lookup"><span data-stu-id="4f93b-171">Field</span></span> | <span data-ttu-id="4f93b-172">Kort beskrivning</span><span class="sxs-lookup"><span data-stu-id="4f93b-172">Brief Description</span></span> |
| --- | --- |
| <span data-ttu-id="4f93b-173">medallion</span><span class="sxs-lookup"><span data-stu-id="4f93b-173">medallion</span></span> |<span data-ttu-id="4f93b-174">Anonymiserade taxi medallion (taxi unikt id)</span><span class="sxs-lookup"><span data-stu-id="4f93b-174">Anonymized taxi medallion (unique taxi id)</span></span> |
| <span data-ttu-id="4f93b-175">hack_license</span><span class="sxs-lookup"><span data-stu-id="4f93b-175">hack_license</span></span> |<span data-ttu-id="4f93b-176">Anonymiserade Hackney transport licensnummer</span><span class="sxs-lookup"><span data-stu-id="4f93b-176">Anonymized Hackney Carriage License number</span></span> |
| <span data-ttu-id="4f93b-177">vendor_id</span><span class="sxs-lookup"><span data-stu-id="4f93b-177">vendor_id</span></span> |<span data-ttu-id="4f93b-178">Taxi leverantörs-id</span><span class="sxs-lookup"><span data-stu-id="4f93b-178">Taxi vendor id</span></span> |
| <span data-ttu-id="4f93b-179">rate_code</span><span class="sxs-lookup"><span data-stu-id="4f93b-179">rate_code</span></span> |<span data-ttu-id="4f93b-180">NYC taxi frekvensen avgiften</span><span class="sxs-lookup"><span data-stu-id="4f93b-180">NYC taxi rate of fare</span></span> |
| <span data-ttu-id="4f93b-181">store_and_fwd_flag</span><span class="sxs-lookup"><span data-stu-id="4f93b-181">store_and_fwd_flag</span></span> |<span data-ttu-id="4f93b-182">Lagra och vidarebefordra flaggan</span><span class="sxs-lookup"><span data-stu-id="4f93b-182">Store and forward flag</span></span> |
| <span data-ttu-id="4f93b-183">pickup_datetime</span><span class="sxs-lookup"><span data-stu-id="4f93b-183">pickup_datetime</span></span> |<span data-ttu-id="4f93b-184">Hämta datum och tid</span><span class="sxs-lookup"><span data-stu-id="4f93b-184">Pick up date & time</span></span> |
| <span data-ttu-id="4f93b-185">dropoff_datetime</span><span class="sxs-lookup"><span data-stu-id="4f93b-185">dropoff_datetime</span></span> |<span data-ttu-id="4f93b-186">Dropoff datum och tid</span><span class="sxs-lookup"><span data-stu-id="4f93b-186">Dropoff date & time</span></span> |
| <span data-ttu-id="4f93b-187">pickup_hour</span><span class="sxs-lookup"><span data-stu-id="4f93b-187">pickup_hour</span></span> |<span data-ttu-id="4f93b-188">Hämta timme</span><span class="sxs-lookup"><span data-stu-id="4f93b-188">Pick up hour</span></span> |
| <span data-ttu-id="4f93b-189">pickup_week</span><span class="sxs-lookup"><span data-stu-id="4f93b-189">pickup_week</span></span> |<span data-ttu-id="4f93b-190">Hämta veckan på året</span><span class="sxs-lookup"><span data-stu-id="4f93b-190">Pick up week of the year</span></span> |
| <span data-ttu-id="4f93b-191">veckodag</span><span class="sxs-lookup"><span data-stu-id="4f93b-191">weekday</span></span> |<span data-ttu-id="4f93b-192">Veckodag (mellan 1-7)</span><span class="sxs-lookup"><span data-stu-id="4f93b-192">Weekday (range 1-7)</span></span> |
| <span data-ttu-id="4f93b-193">passenger_count</span><span class="sxs-lookup"><span data-stu-id="4f93b-193">passenger_count</span></span> |<span data-ttu-id="4f93b-194">Passagerare i en taxi resa</span><span class="sxs-lookup"><span data-stu-id="4f93b-194">Number of passengers in a taxi trip</span></span> |
| <span data-ttu-id="4f93b-195">trip_time_in_secs</span><span class="sxs-lookup"><span data-stu-id="4f93b-195">trip_time_in_secs</span></span> |<span data-ttu-id="4f93b-196">Resa tiden i sekunder</span><span class="sxs-lookup"><span data-stu-id="4f93b-196">Trip time in seconds</span></span> |
| <span data-ttu-id="4f93b-197">trip_distance</span><span class="sxs-lookup"><span data-stu-id="4f93b-197">trip_distance</span></span> |<span data-ttu-id="4f93b-198">Resa avstånd som obligatoriska i mil</span><span class="sxs-lookup"><span data-stu-id="4f93b-198">Trip distance traveled in miles</span></span> |
| <span data-ttu-id="4f93b-199">pickup_longitude</span><span class="sxs-lookup"><span data-stu-id="4f93b-199">pickup_longitude</span></span> |<span data-ttu-id="4f93b-200">Hämta longitud</span><span class="sxs-lookup"><span data-stu-id="4f93b-200">Pick up longitude</span></span> |
| <span data-ttu-id="4f93b-201">pickup_latitude</span><span class="sxs-lookup"><span data-stu-id="4f93b-201">pickup_latitude</span></span> |<span data-ttu-id="4f93b-202">Hämta latitud</span><span class="sxs-lookup"><span data-stu-id="4f93b-202">Pick up latitude</span></span> |
| <span data-ttu-id="4f93b-203">dropoff_longitude</span><span class="sxs-lookup"><span data-stu-id="4f93b-203">dropoff_longitude</span></span> |<span data-ttu-id="4f93b-204">Dropoff longitud</span><span class="sxs-lookup"><span data-stu-id="4f93b-204">Dropoff longitude</span></span> |
| <span data-ttu-id="4f93b-205">dropoff_latitude</span><span class="sxs-lookup"><span data-stu-id="4f93b-205">dropoff_latitude</span></span> |<span data-ttu-id="4f93b-206">Dropoff latitud</span><span class="sxs-lookup"><span data-stu-id="4f93b-206">Dropoff latitude</span></span> |
| <span data-ttu-id="4f93b-207">direct_distance</span><span class="sxs-lookup"><span data-stu-id="4f93b-207">direct_distance</span></span> |<span data-ttu-id="4f93b-208">Dirigera avståndet mellan plocka upp och dropoff platser</span><span class="sxs-lookup"><span data-stu-id="4f93b-208">Direct distance between pick up and dropoff locations</span></span> |
| <span data-ttu-id="4f93b-209">payment_type</span><span class="sxs-lookup"><span data-stu-id="4f93b-209">payment_type</span></span> |<span data-ttu-id="4f93b-210">Betalningssätt (CA: er, kreditkortsnummer osv.)</span><span class="sxs-lookup"><span data-stu-id="4f93b-210">Payment type (cas, credit-card etc.)</span></span> |
| <span data-ttu-id="4f93b-211">fare_amount</span><span class="sxs-lookup"><span data-stu-id="4f93b-211">fare_amount</span></span> |<span data-ttu-id="4f93b-212">Avgiften beloppet i</span><span class="sxs-lookup"><span data-stu-id="4f93b-212">Fare amount in</span></span> |
| <span data-ttu-id="4f93b-213">Tillägg</span><span class="sxs-lookup"><span data-stu-id="4f93b-213">surcharge</span></span> |<span data-ttu-id="4f93b-214">Tillägg</span><span class="sxs-lookup"><span data-stu-id="4f93b-214">Surcharge</span></span> |
| <span data-ttu-id="4f93b-215">mta_tax</span><span class="sxs-lookup"><span data-stu-id="4f93b-215">mta_tax</span></span> |<span data-ttu-id="4f93b-216">MTA skatt</span><span class="sxs-lookup"><span data-stu-id="4f93b-216">Mta tax</span></span> |
| <span data-ttu-id="4f93b-217">tip_amount</span><span class="sxs-lookup"><span data-stu-id="4f93b-217">tip_amount</span></span> |<span data-ttu-id="4f93b-218">Tips belopp</span><span class="sxs-lookup"><span data-stu-id="4f93b-218">Tip amount</span></span> |
| <span data-ttu-id="4f93b-219">tolls_amount</span><span class="sxs-lookup"><span data-stu-id="4f93b-219">tolls_amount</span></span> |<span data-ttu-id="4f93b-220">Vägtullar belopp</span><span class="sxs-lookup"><span data-stu-id="4f93b-220">Tolls amount</span></span> |
| <span data-ttu-id="4f93b-221">total_amount</span><span class="sxs-lookup"><span data-stu-id="4f93b-221">total_amount</span></span> |<span data-ttu-id="4f93b-222">Totalmängd</span><span class="sxs-lookup"><span data-stu-id="4f93b-222">Total amount</span></span> |
| <span data-ttu-id="4f93b-223">lutad</span><span class="sxs-lookup"><span data-stu-id="4f93b-223">tipped</span></span> |<span data-ttu-id="4f93b-224">Lutad (0-1 för Nej eller Ja)</span><span class="sxs-lookup"><span data-stu-id="4f93b-224">Tipped (0/1 for no or yes)</span></span> |
| <span data-ttu-id="4f93b-225">tip_class</span><span class="sxs-lookup"><span data-stu-id="4f93b-225">tip_class</span></span> |<span data-ttu-id="4f93b-226">Tips klass (0: 0, 1: $0-5, 2: $6 – 10, 3: $11-20, 4: > 20)</span><span class="sxs-lookup"><span data-stu-id="4f93b-226">Tip class (0: $0, 1: $0-5, 2: $6-10, 3: $11-20, 4: > $20)</span></span> |

## <a name="execute-code-from-a-jupyter-notebook-on-the-spark-cluster"></a><span data-ttu-id="4f93b-227">Köra kod från en Jupyter notebook i Spark-klustret</span><span class="sxs-lookup"><span data-stu-id="4f93b-227">Execute code from a Jupyter notebook on the Spark cluster</span></span>
<span data-ttu-id="4f93b-228">Du kan starta Jupyter-anteckningsbok från Azure-portalen.</span><span class="sxs-lookup"><span data-stu-id="4f93b-228">You can launch the Jupyter Notebook from the Azure portal.</span></span> <span data-ttu-id="4f93b-229">Spark-kluster på instrumentpanelen och klicka på den för att ange hanteringssidan för klustret.</span><span class="sxs-lookup"><span data-stu-id="4f93b-229">Find your Spark cluster on your dashboard and click it to enter management page for your cluster.</span></span> <span data-ttu-id="4f93b-230">Klicka för att öppna den bärbara datorn som är associerade med Spark-klustret **Klusterinstrumentpaneler** -> **Jupyter-anteckningsbok** .</span><span class="sxs-lookup"><span data-stu-id="4f93b-230">To open the notebook associated with the Spark cluster, click **Cluster Dashboards** -> **Jupyter Notebook** .</span></span>

![Klustret instrumentpaneler](./media/machine-learning-data-science-spark-overview/spark-jupyter-on-portal.png)

<span data-ttu-id="4f93b-232">Du kan även bläddra till ***https://CLUSTERNAME.azurehdinsight.net/jupyter*** till Jupyter-anteckningsböcker.</span><span class="sxs-lookup"><span data-stu-id="4f93b-232">You can also browse to ***https://CLUSTERNAME.azurehdinsight.net/jupyter*** to access the Jupyter Notebooks.</span></span> <span data-ttu-id="4f93b-233">Ersätt det KLUSTERNAMN som en del av denna URL med namnet på ditt eget kluster.</span><span class="sxs-lookup"><span data-stu-id="4f93b-233">Replace the CLUSTERNAME part of this URL with the name of your own cluster.</span></span> <span data-ttu-id="4f93b-234">Du behöver lösenordet för ditt administratörskonto att få åtkomst till de bärbara datorerna.</span><span class="sxs-lookup"><span data-stu-id="4f93b-234">You need the password for your admin account to access the notebooks.</span></span>

![Bläddra Jupyter-anteckningsböcker](./media/machine-learning-data-science-spark-overview/spark-jupyter-notebook.png)

<span data-ttu-id="4f93b-236">Välj PySpark att se en katalog som innehåller några exempel på förhand packade bärbara datorer som använder PySpark-API. Datorer som innehåller kodexempel för den här serien Spark-avsnittet finns på [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span><span class="sxs-lookup"><span data-stu-id="4f93b-236">Select PySpark to see a directory that contains a few examples of pre-packaged notebooks that use the PySpark API.The notebooks that contain the code samples for this suite of Spark topic are available at [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark)</span></span>

<span data-ttu-id="4f93b-237">Du kan ladda upp bärbara datorer direkt från [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) till Jupyter-anteckningsbok servern på Spark-kluster.</span><span class="sxs-lookup"><span data-stu-id="4f93b-237">You can upload the notebooks directly from [GitHub](https://github.com/Azure/Azure-MachineLearning-DataScience/tree/master/Misc/Spark/pySpark) to the Jupyter notebook server on your Spark cluster.</span></span> <span data-ttu-id="4f93b-238">På startsidan för din Jupyter klickar du på den **överför** knappen i den högra delen av skärmen.</span><span class="sxs-lookup"><span data-stu-id="4f93b-238">On the home page of your Jupyter, click the **Upload** button on the right part of the screen.</span></span> <span data-ttu-id="4f93b-239">En Utforskaren öppnas.</span><span class="sxs-lookup"><span data-stu-id="4f93b-239">It opens a file explorer.</span></span> <span data-ttu-id="4f93b-240">Här kan du klistra in GitHub (rådata innehåll) URL: en för bärbara datorer och klicka på **öppna**.</span><span class="sxs-lookup"><span data-stu-id="4f93b-240">Here you can paste the GitHub (raw content) URL of the Notebook and click **Open**.</span></span> 

<span data-ttu-id="4f93b-241">Du ser filnamnet i listan Jupyter-fil med en **överför** igen.</span><span class="sxs-lookup"><span data-stu-id="4f93b-241">You see the file name on your Jupyter file list with an **Upload** button again.</span></span> <span data-ttu-id="4f93b-242">Klicka här **överför** knappen.</span><span class="sxs-lookup"><span data-stu-id="4f93b-242">Click this **Upload** button.</span></span> <span data-ttu-id="4f93b-243">Nu har du importerat den bärbara datorn.</span><span class="sxs-lookup"><span data-stu-id="4f93b-243">Now you have imported the notebook.</span></span> <span data-ttu-id="4f93b-244">Upprepa dessa steg för att ladda upp andra datorer från den här genomgången.</span><span class="sxs-lookup"><span data-stu-id="4f93b-244">Repeat these steps to upload the other notebooks from this walkthrough.</span></span>

> [!TIP]
> <span data-ttu-id="4f93b-245">Du kan högerklicka på länkarna i webbläsaren och välj **Kopiera länk** att hämta github raw innehåll Webbadress.</span><span class="sxs-lookup"><span data-stu-id="4f93b-245">You can right-click the links on your browser and select **Copy Link** to get the github raw content URL.</span></span> <span data-ttu-id="4f93b-246">Du kan klistra in URL: en i dialogrutan Jupyter överför filen explorer.</span><span class="sxs-lookup"><span data-stu-id="4f93b-246">You can paste this URL into the Jupyter Upload file explorer dialog box.</span></span>
> 
> 

<span data-ttu-id="4f93b-247">Nu kan du:</span><span class="sxs-lookup"><span data-stu-id="4f93b-247">Now you can:</span></span>

* <span data-ttu-id="4f93b-248">Visa koden genom att klicka på den bärbara datorn.</span><span class="sxs-lookup"><span data-stu-id="4f93b-248">See the code by clicking the notebook.</span></span>
* <span data-ttu-id="4f93b-249">Köra varje cell genom att trycka på **SKIFT-ange**.</span><span class="sxs-lookup"><span data-stu-id="4f93b-249">Execute each cell by pressing **SHIFT-ENTER**.</span></span>
* <span data-ttu-id="4f93b-250">Kör anteckningsboken genom att klicka på **Cell** -> **kör**.</span><span class="sxs-lookup"><span data-stu-id="4f93b-250">Run the entire notebook by clicking on **Cell** -> **Run**.</span></span>
* <span data-ttu-id="4f93b-251">Använda automatisk visualisering av frågor.</span><span class="sxs-lookup"><span data-stu-id="4f93b-251">Use the automatic visualization of queries.</span></span>

> [!TIP]
> <span data-ttu-id="4f93b-252">PySpark-kerneln visualizes automatiskt utdata för SQL (HiveQL)-frågor.</span><span class="sxs-lookup"><span data-stu-id="4f93b-252">The PySpark kernel automatically visualizes the output of SQL (HiveQL) queries.</span></span> <span data-ttu-id="4f93b-253">Du har möjlighet att välja mellan flera olika typer av grafik (register, cirkeldiagram, rad, område eller fältet) med hjälp av den **typen** menyn knapparna i anteckningsboken:</span><span class="sxs-lookup"><span data-stu-id="4f93b-253">You are given the option to select among several different types of visualizations (Table, Pie, Line, Area, or Bar) by using the **Type** menu buttons in the notebook:</span></span>
> 
> 

![Logistic regression ROC-kurvan generisk metod](./media/machine-learning-data-science-spark-overview/pyspark-jupyter-autovisualization.png)

## <a name="whats-next"></a><span data-ttu-id="4f93b-255">Nästa steg</span><span class="sxs-lookup"><span data-stu-id="4f93b-255">What's next?</span></span>
<span data-ttu-id="4f93b-256">Nu när du har konfigurerat ett HDInsight Spark-kluster och har överfört Jupyter-anteckningsböcker är du redo att gå igenom de avsnitt som motsvarar tre PySpark bärbara datorer.</span><span class="sxs-lookup"><span data-stu-id="4f93b-256">Now that you are set up with an HDInsight Spark cluster and have uploaded the Jupyter notebooks, you are ready to work through the topics that correspond to the three PySpark notebooks.</span></span> <span data-ttu-id="4f93b-257">De visar hur du utforska dina data och hur du skapar och använda modeller.</span><span class="sxs-lookup"><span data-stu-id="4f93b-257">They show how to explore your data and then how to create and consume models.</span></span> <span data-ttu-id="4f93b-258">Avancerade undersökning och modellering bärbar dator visar hur du inkludera korsvalidering, hyper-parametern omfattande, och modellerar utvärdering.</span><span class="sxs-lookup"><span data-stu-id="4f93b-258">The advanced data exploration and modeling notebook shows how to include cross-validation, hyper-parameter sweeping, and model evaluation.</span></span> 

<span data-ttu-id="4f93b-259">**Datagranskning och modellering med Spark:** utforska datauppsättningen och skapa poängsätta och utvärdera modeller för maskininlärning genom att utföra den [skapa binär klassificering och regression modeller för data med Spark MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) avsnittet.</span><span class="sxs-lookup"><span data-stu-id="4f93b-259">**Data Exploration and modeling with Spark:** Explore the dataset and create, score, and evaluate the machine learning models by working through the [Create binary classification and regression models for data with the Spark MLlib toolkit](machine-learning-data-science-spark-data-exploration-modeling.md) topic.</span></span>

<span data-ttu-id="4f93b-260">**Modellen förbrukning:** information om hur du poängsätta klassificering och regression modeller som skapats i det här avsnittet finns [poängsätta och utvärdera Spark-inbyggda machine learning-modeller](machine-learning-data-science-spark-model-consumption.md).</span><span class="sxs-lookup"><span data-stu-id="4f93b-260">**Model consumption:** To learn how to score the classification and regression models created in this topic, see [Score and evaluate Spark-built machine learning models](machine-learning-data-science-spark-model-consumption.md).</span></span>

<span data-ttu-id="4f93b-261">**Korsvalidering och hyperparameter omfattande**: se [avancerade datagranskning och modellering med Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) på hur modeller kan vara tränas med omfattande korsvalidering och hyper-parameter</span><span class="sxs-lookup"><span data-stu-id="4f93b-261">**Cross-validation and hyperparameter sweeping**: See [Advanced data exploration and modeling with Spark](machine-learning-data-science-spark-advanced-data-exploration-modeling.md) on how models can be trained using cross-validation and hyper-parameter sweeping</span></span>

