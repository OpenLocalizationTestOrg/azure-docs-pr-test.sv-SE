---
title: "aaaGuide toohello Net # Neurala nätverk specifikationsspråk | Microsoft Docs"
description: "Syntaxen för hello Net # neurala nätverk specifikationsspråk, tillsammans med exempel på hur toocreate ett anpassat neurala nätverk modellen i Microsoft Azure ML med hjälp av Net #"
services: machine-learning
documentationcenter: 
author: jeannt
manager: jhubbard
editor: cgronlun
ms.assetid: cfd1454b-47df-4745-b064-ce5f9b3be303
ms.service: machine-learning
ms.workload: data-services
ms.tgt_pltfrm: na
ms.devlang: na
ms.topic: article
ms.date: 03/31/2017
ms.author: jeannt
ms.openlocfilehash: 3493247ecc39ca3a1382510ad520d7017159ff62
ms.sourcegitcommit: 523283cc1b3c37c428e77850964dc1c33742c5f0
ms.translationtype: MT
ms.contentlocale: sv-SE
ms.lasthandoff: 10/06/2017
---
# <a name="guide-toonet-neural-network-specification-language-for-azure-machine-learning"></a><span data-ttu-id="16c35-103">Guiden tooNet # neurala nätverket specifikationsspråk för Azure Machine Learning</span><span class="sxs-lookup"><span data-stu-id="16c35-103">Guide tooNet# neural network specification language for Azure Machine Learning</span></span>
## <a name="overview"></a><span data-ttu-id="16c35-104">Översikt</span><span class="sxs-lookup"><span data-stu-id="16c35-104">Overview</span></span>
<span data-ttu-id="16c35-105">NET # är ett språk som har utvecklats av Microsoft som används toodefine neural nätverksarkitekturer.</span><span class="sxs-lookup"><span data-stu-id="16c35-105">Net# is a language developed by Microsoft that is used toodefine neural network architectures.</span></span> <span data-ttu-id="16c35-106">Du kan använda Net # i neurala nätverket moduler i Microsoft Azure Machine Learning.</span><span class="sxs-lookup"><span data-stu-id="16c35-106">You can use Net# in neural network modules in Microsoft Azure Machine Learning.</span></span>

<!-- This function doesn't currentlyappear in hello MicrosoftML documentation. If it is added in a future update, we can uncomment this text.

, or in hello `rxNeuralNetwork()` function in [MicrosoftML](https://msdn.microsoft.com/microsoft-r/microsoftml/microsoftml). 

-->

<span data-ttu-id="16c35-107">I den här artikeln får du lära dig grundläggande koncept behövs toodevelop en anpassad neurala nätverket:</span><span class="sxs-lookup"><span data-stu-id="16c35-107">In this article, you will learn basic concepts needed toodevelop a custom neural network:</span></span> 

* <span data-ttu-id="16c35-108">Neural nätverkskrav och hur toodefine hello huvudkomponenter</span><span class="sxs-lookup"><span data-stu-id="16c35-108">Neural network requirements and how toodefine hello primary components</span></span>
* <span data-ttu-id="16c35-109">hello syntax och nyckelord för hello Net #-specifikationsspråk</span><span class="sxs-lookup"><span data-stu-id="16c35-109">hello syntax and keywords of hello Net# specification language</span></span>
* <span data-ttu-id="16c35-110">Exempel på anpassade neurala nätverk som skapats med hjälp av Net #</span><span class="sxs-lookup"><span data-stu-id="16c35-110">Examples of custom neural networks created using Net#</span></span> 

[!INCLUDE [machine-learning-free-trial](../../includes/machine-learning-free-trial.md)]

## <a name="neural-network-basics"></a><span data-ttu-id="16c35-111">Grunderna i neurala nätverket</span><span class="sxs-lookup"><span data-stu-id="16c35-111">Neural network basics</span></span>
<span data-ttu-id="16c35-112">En neurala nätverk som består av ***noder*** som är ordnade i ***lager***, och det vägda ***anslutningar*** (eller ***kanter***) mellan hello-noder.</span><span class="sxs-lookup"><span data-stu-id="16c35-112">A neural network structure consists of ***nodes*** that are organized in ***layers***, and weighted ***connections*** (or ***edges***) between hello nodes.</span></span> <span data-ttu-id="16c35-113">hello anslutningar är riktat och varje anslutning har en ***källa*** nod och en ***mål*** nod.</span><span class="sxs-lookup"><span data-stu-id="16c35-113">hello connections are directional, and each connection has a ***source*** node and a ***destination*** node.</span></span>  

<span data-ttu-id="16c35-114">Varje ***trainable layer*** (en dold eller ett lager för utdata) har en eller flera ***anslutning paket***.</span><span class="sxs-lookup"><span data-stu-id="16c35-114">Each ***trainable layer*** (a hidden or an output layer) has one or more ***connection bundles***.</span></span> <span data-ttu-id="16c35-115">En anslutning bunt består av ett lager för källa och en specifikation av hello anslutningar från källan lagret.</span><span class="sxs-lookup"><span data-stu-id="16c35-115">A connection bundle consists of a source layer and a specification of hello connections from that source layer.</span></span> <span data-ttu-id="16c35-116">Alla hello-anslutningar i en viss paket-resurs hello samma ***källa layer*** och hello samma ***mållagret***.</span><span class="sxs-lookup"><span data-stu-id="16c35-116">All hello connections in a given bundle share hello same ***source layer*** and hello same ***destination layer***.</span></span> <span data-ttu-id="16c35-117">Ett paket med anslutning betraktas som tillhör toohello paket mållagret i Net #.</span><span class="sxs-lookup"><span data-stu-id="16c35-117">In Net#, a connection bundle is considered as belonging toohello bundle's destination layer.</span></span>  

<span data-ttu-id="16c35-118">NET # stöder olika typer av paket för anslutningen, vilket gör att du anpassar hello sätt indata är mappade toohidden lager och mappade toohello matar ut.</span><span class="sxs-lookup"><span data-stu-id="16c35-118">Net# supports various kinds of connection bundles, which lets you customize hello way inputs are mapped toohidden layers and mapped toohello outputs.</span></span>   

<span data-ttu-id="16c35-119">hello standard eller standard paket är en **fullständig paket**, vilken varje nod i hello källa skiktet är anslutna tooevery nod i hello mållagret.</span><span class="sxs-lookup"><span data-stu-id="16c35-119">hello default or standard bundle is a **full bundle**, in which each node in hello source layer is connected tooevery node in hello destination layer.</span></span>  

<span data-ttu-id="16c35-120">Dessutom stöder Net # hello följande fyra typer av avancerad anslutning paket:</span><span class="sxs-lookup"><span data-stu-id="16c35-120">Additionally, Net# supports hello following four kinds of advanced connection bundles:</span></span>  

* <span data-ttu-id="16c35-121">**Filtrerade paket**.</span><span class="sxs-lookup"><span data-stu-id="16c35-121">**Filtered bundles**.</span></span> <span data-ttu-id="16c35-122">hello användare kan definiera ett predikat hello platser för hello Källnoden lager och hello layer målnoden.</span><span class="sxs-lookup"><span data-stu-id="16c35-122">hello user can define a predicate by using hello locations of hello source layer node and hello destination layer node.</span></span> <span data-ttu-id="16c35-123">Noder är anslutna när hello är True.</span><span class="sxs-lookup"><span data-stu-id="16c35-123">Nodes are connected whenever hello predicate is True.</span></span>
* <span data-ttu-id="16c35-124">**Convolutional paket**.</span><span class="sxs-lookup"><span data-stu-id="16c35-124">**Convolutional bundles**.</span></span> <span data-ttu-id="16c35-125">hello användare kan definiera små neighborhoods av noder i hello källa lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-125">hello user can define small neighborhoods of nodes in hello source layer.</span></span> <span data-ttu-id="16c35-126">Varje nod i hello mållagret är anslutna tooone nätverket av noder i hello källa lagret.</span><span class="sxs-lookup"><span data-stu-id="16c35-126">Each node in hello destination layer is connected tooone neighborhood of nodes in hello source layer.</span></span>
* <span data-ttu-id="16c35-127">**Poolning paket** och **svar normalisering paket**.</span><span class="sxs-lookup"><span data-stu-id="16c35-127">**Pooling bundles** and **Response normalization bundles**.</span></span> <span data-ttu-id="16c35-128">Dessa är liknande tooconvolutional paket i den hello användaren definierar små neighborhoods av noder i hello källa lagret.</span><span class="sxs-lookup"><span data-stu-id="16c35-128">These are similar tooconvolutional bundles in that hello user defines small neighborhoods of nodes in hello source layer.</span></span> <span data-ttu-id="16c35-129">hello skillnaden är att hello vikten av hello kanter i dessa paket inte är trainable.</span><span class="sxs-lookup"><span data-stu-id="16c35-129">hello difference is that hello weights of hello edges in these bundles are not trainable.</span></span> <span data-ttu-id="16c35-130">I stället en fördefinierad funktion används toohello Källnoden värden toodetermine hello mål nodvärde.</span><span class="sxs-lookup"><span data-stu-id="16c35-130">Instead, a predefined function is applied toohello source node values toodetermine hello destination node value.</span></span>  

<span data-ttu-id="16c35-131">Med hjälp av Net # gör toodefine hello struktur för ett neurala nätverk det möjligt toodefine komplexa strukturer som djupa neurala nätverk eller faltningar av godtycklig dimensioner, som är kända tooimprove inlärning på data, till exempel bild, ljud och video.</span><span class="sxs-lookup"><span data-stu-id="16c35-131">Using Net# toodefine hello structure of a neural network makes it possible toodefine complex structures such as deep neural networks or convolutions of arbitrary dimensions, which are known tooimprove learning on data such as image, audio, or video.</span></span>  

## <a name="supported-customizations"></a><span data-ttu-id="16c35-132">Anpassningar som stöds</span><span class="sxs-lookup"><span data-stu-id="16c35-132">Supported customizations</span></span>
<span data-ttu-id="16c35-133">hello-arkitekturen för neurala nätverket modeller som du skapar i Azure Machine Learning kan stor utsträckning anpassas med hjälp av Net #.</span><span class="sxs-lookup"><span data-stu-id="16c35-133">hello architecture of neural network models that you create in Azure Machine Learning can be extensively customized by using Net#.</span></span> <span data-ttu-id="16c35-134">Du kan:</span><span class="sxs-lookup"><span data-stu-id="16c35-134">You can:</span></span>  

* <span data-ttu-id="16c35-135">Skapa dolda lager och kontroll hello antalet noder i varje lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-135">Create hidden layers and control hello number of nodes in each layer.</span></span>
* <span data-ttu-id="16c35-136">Ange hur lager toobe anslutna tooeach andra.</span><span class="sxs-lookup"><span data-stu-id="16c35-136">Specify how layers are toobe connected tooeach other.</span></span>
* <span data-ttu-id="16c35-137">Definiera särskilda anslutningar, till exempel faltningar och vikt delning paket.</span><span class="sxs-lookup"><span data-stu-id="16c35-137">Define special connectivity structures, such as convolutions and weight sharing bundles.</span></span>
* <span data-ttu-id="16c35-138">Ange olika aktivering funktioner.</span><span class="sxs-lookup"><span data-stu-id="16c35-138">Specify different activation functions.</span></span>  

<span data-ttu-id="16c35-139">Mer information om syntaxen för anspråksregelspråket hello-specifikationen finns [struktur specifikationen](#Structure-specifications).</span><span class="sxs-lookup"><span data-stu-id="16c35-139">For details of hello specification language syntax, see [Structure Specification](#Structure-specifications).</span></span>  

<span data-ttu-id="16c35-140">Exempel på definierar neurala nätverk för några vanliga uppgifter från simplex toocomplex för maskininlärning finns [exempel](#Examples-of-Net#-usage).</span><span class="sxs-lookup"><span data-stu-id="16c35-140">For examples of defining neural networks for some common machine learning tasks, from simplex toocomplex, see [Examples](#Examples-of-Net#-usage).</span></span>  

## <a name="general-requirements"></a><span data-ttu-id="16c35-141">Allmänna krav</span><span class="sxs-lookup"><span data-stu-id="16c35-141">General requirements</span></span>
* <span data-ttu-id="16c35-142">Det måste finnas exakt en utgående lager, minst ett indata lager och noll eller flera dolda lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-142">There must be exactly one output layer, at least one input layer, and zero or more hidden layers.</span></span> 
* <span data-ttu-id="16c35-143">Varje lager har ett fast antal noder, begreppsmässigt ordnade i en rektangulär matris av godtycklig dimensioner.</span><span class="sxs-lookup"><span data-stu-id="16c35-143">Each layer has a fixed number of nodes, conceptually arranged in a rectangular array of arbitrary dimensions.</span></span> 
* <span data-ttu-id="16c35-144">Inkommande lager saknar associerade utbildade parametrar som representerar hello punkt där instansdata anger hello nätverk.</span><span class="sxs-lookup"><span data-stu-id="16c35-144">Input layers have no associated trained parameters and represent hello point where instance data enters hello network.</span></span> 
* <span data-ttu-id="16c35-145">Trainable lager (hello dolda och utdata lager) har associerade utbildade parametrar, kallas även eventuella fördomar och vikt.</span><span class="sxs-lookup"><span data-stu-id="16c35-145">Trainable layers (hello hidden and output layers) have associated trained parameters, known as weights and biases.</span></span> 
* <span data-ttu-id="16c35-146">hello käll- och noder måste vara i separata lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-146">hello source and destination nodes must be in separate layers.</span></span> 
* <span data-ttu-id="16c35-147">Anslutningar måste vara acykliska; med andra ord, får inte det vara en kedja av anslutningar som leder tillbaka toohello inledande Källnoden.</span><span class="sxs-lookup"><span data-stu-id="16c35-147">Connections must be acyclic; in other words, there cannot be a chain of connections leading back toohello initial source node.</span></span>
* <span data-ttu-id="16c35-148">hello utdata layer får inte vara ett källa lager för ett paket för anslutningen.</span><span class="sxs-lookup"><span data-stu-id="16c35-148">hello output layer cannot be a source layer of a connection bundle.</span></span>  

## <a name="structure-specifications"></a><span data-ttu-id="16c35-149">Specifikationer för struktur</span><span class="sxs-lookup"><span data-stu-id="16c35-149">Structure specifications</span></span>
<span data-ttu-id="16c35-150">En neurala nätverket struktur specifikation består av tre delar: hello **konstantdeklaration**, hello **layer deklaration**, hello **anslutning deklaration**.</span><span class="sxs-lookup"><span data-stu-id="16c35-150">A neural network structure specification is composed of three sections: hello **constant declaration**, hello **layer declaration**, hello **connection declaration**.</span></span> <span data-ttu-id="16c35-151">Det finns även en valfri **dela deklaration** avsnitt.</span><span class="sxs-lookup"><span data-stu-id="16c35-151">There is also an optional **share declaration** section.</span></span> <span data-ttu-id="16c35-152">hello avsnitt kan anges i valfri ordning.</span><span class="sxs-lookup"><span data-stu-id="16c35-152">hello sections can be specified in any order.</span></span>  

## <a name="constant-declaration"></a><span data-ttu-id="16c35-153">Konstantdeklaration</span><span class="sxs-lookup"><span data-stu-id="16c35-153">Constant declaration</span></span>
<span data-ttu-id="16c35-154">En konstantdeklaration är valfritt.</span><span class="sxs-lookup"><span data-stu-id="16c35-154">A constant declaration is optional.</span></span> <span data-ttu-id="16c35-155">Det ger ett sätt toodefine värden används någon annanstans i definition av hello neurala nätverk.</span><span class="sxs-lookup"><span data-stu-id="16c35-155">It provides a means toodefine values used elsewhere in hello neural network definition.</span></span> <span data-ttu-id="16c35-156">hello deklaration instruktion består av en identifierare som följt av ett likhetstecken och ett värdeuttryck.</span><span class="sxs-lookup"><span data-stu-id="16c35-156">hello declaration statement consists of an identifier followed by an equal sign and a value expression.</span></span>   

<span data-ttu-id="16c35-157">Till exempel hello efter uttrycket definierar en konstant **x**:</span><span class="sxs-lookup"><span data-stu-id="16c35-157">For example, hello following statement defines a constant **x**:</span></span>  

    Const X = 28;  

<span data-ttu-id="16c35-158">toodefine två eller flera konstanter samtidigt, omges klammerparenteser hello identifierarnamn och värden och avgränsa dem med semikolon.</span><span class="sxs-lookup"><span data-stu-id="16c35-158">toodefine two or more constants simultaneously, enclose hello identifier names and values in braces, and separate them by using semicolons.</span></span> <span data-ttu-id="16c35-159">Exempel:</span><span class="sxs-lookup"><span data-stu-id="16c35-159">For example:</span></span>  

    Const { X = 28; Y = 4; }  

<span data-ttu-id="16c35-160">hello till höger på varje tilldelning uttrycket kan vara ett heltal, ett verkligt tal, ett booleskt värde (True eller False) eller ett matematiska uttryck.</span><span class="sxs-lookup"><span data-stu-id="16c35-160">hello right-hand side of each assignment expression can be an integer, a real number, a Boolean value (True or False), or a mathematical expression.</span></span> <span data-ttu-id="16c35-161">Exempel:</span><span class="sxs-lookup"><span data-stu-id="16c35-161">For example:</span></span>  

    Const { X = 17 * 2; Y = true; }  

## <a name="layer-declaration"></a><span data-ttu-id="16c35-162">Deklarationen för lager</span><span class="sxs-lookup"><span data-stu-id="16c35-162">Layer declaration</span></span>
<span data-ttu-id="16c35-163">hello layer deklaration krävs.</span><span class="sxs-lookup"><span data-stu-id="16c35-163">hello layer declaration is required.</span></span> <span data-ttu-id="16c35-164">Den definierar hello storlek och källa för hello-lagret, inklusive dess anslutning paket och attribut.</span><span class="sxs-lookup"><span data-stu-id="16c35-164">It defines hello size and source of hello layer, including its connection bundles and attributes.</span></span> <span data-ttu-id="16c35-165">Hej deklaration instruktionen börjar med hello namnet på hello lager (indata, dolda eller utdata), följt av hello dimensioner för hello layer (en tuppel positiva heltal).</span><span class="sxs-lookup"><span data-stu-id="16c35-165">hello declaration statement starts with hello name of hello layer (input, hidden, or output), followed by hello dimensions of hello layer (a tuple of positive integers).</span></span> <span data-ttu-id="16c35-166">Exempel:</span><span class="sxs-lookup"><span data-stu-id="16c35-166">For example:</span></span>  

    input Data auto;
    hidden Hidden[5,20] from Data all;
    output Result[2] from Hidden all;  

* <span data-ttu-id="16c35-167">hello produkten av hello dimensioner är hello antalet noder i hello lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-167">hello product of hello dimensions is hello number of nodes in hello layer.</span></span> <span data-ttu-id="16c35-168">I det här exemplet finns det två dimensioner [5,20], vilket innebär att det finns 100 noder i hello lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-168">In this example, there are two dimensions [5,20], which means there are  100 nodes in hello layer.</span></span>
* <span data-ttu-id="16c35-169">hello lager kan deklareras i vilken ordning som helst, med ett undantag: om fler än ett inkommande lager definieras hello ordning de deklareras måste matcha hello ordningen på funktioner i hello indata.</span><span class="sxs-lookup"><span data-stu-id="16c35-169">hello layers can be declared in any order, with one exception: If more than one input layer is defined, hello order in which they are declared must match hello order of features in hello input data.</span></span>  

<span data-ttu-id="16c35-170">toospecify hello antalet noder i ett lager att fastställa automatiskt, Använd hello **automatisk** nyckelord.</span><span class="sxs-lookup"><span data-stu-id="16c35-170">toospecify that hello number of nodes in a layer be determined automatically, use hello **auto** keyword.</span></span> <span data-ttu-id="16c35-171">Hej **automatisk** nyckelordet har olika effekter, beroende på hello lager:</span><span class="sxs-lookup"><span data-stu-id="16c35-171">hello **auto** keyword has different effects, depending on hello layer:</span></span>  

* <span data-ttu-id="16c35-172">I en inkommande layer-deklaration är hello antalet noder hello antal funktioner i hello indata.</span><span class="sxs-lookup"><span data-stu-id="16c35-172">In an input layer declaration, hello number of nodes is hello number of features in hello input data.</span></span>
* <span data-ttu-id="16c35-173">I en deklaration som dolda lagret hello antalet noder är hello-nummer som anges av hello parametervärdet för **antalet dolda noder**.</span><span class="sxs-lookup"><span data-stu-id="16c35-173">In a hidden layer declaration, hello number of nodes is hello number that is specified by hello parameter value for **Number of hidden nodes**.</span></span> 
* <span data-ttu-id="16c35-174">I en layer deklaration utdata är hello antalet noder 2 för tvåklass klassificering, 1 för regression och lika toohello antalet noder som utdata för multiklass-baserad klassificering.</span><span class="sxs-lookup"><span data-stu-id="16c35-174">In an output layer declaration, hello number of nodes is 2 for two-class classification, 1 for regression, and equal toohello number of output nodes for multiclass classification.</span></span>   

<span data-ttu-id="16c35-175">Kan till exempel hello följande nätverksdefinitionen hello storleken på alla lager toobe automatiskt:</span><span class="sxs-lookup"><span data-stu-id="16c35-175">For example, hello following network definition allows hello size of all layers toobe automatically determined:</span></span>  

    input Data auto;
    hidden Hidden auto from Data all;
    output Result auto from Hidden all;  


<span data-ttu-id="16c35-176">En layer-deklaration för en trainable lager (hello dolda eller utdata lager) kan du också inkludera hello utdata funktionen (kallas också en funktion för aktivering), där standardinställningen för**sigmoid** för klassificering modeller och **linjär** för regression modeller.</span><span class="sxs-lookup"><span data-stu-id="16c35-176">A layer declaration for a trainable layer (hello hidden or output layers) can optionally include hello output function (also called an activation function), which defaults too**sigmoid** for classification models, and **linear** for regression models.</span></span> <span data-ttu-id="16c35-177">(Även om du använder hello standard du uttryckligen uppge hello aktivering funktion, om så önskas för tydlighetens skull.)</span><span class="sxs-lookup"><span data-stu-id="16c35-177">(Even if you use hello default, you can explicitly state hello activation function, if desired for clarity.)</span></span>

<span data-ttu-id="16c35-178">hello stöder utdata följande funktioner:</span><span class="sxs-lookup"><span data-stu-id="16c35-178">hello following output functions are supported:</span></span>  

* <span data-ttu-id="16c35-179">sigmoid</span><span class="sxs-lookup"><span data-stu-id="16c35-179">sigmoid</span></span>
* <span data-ttu-id="16c35-180">linjär</span><span class="sxs-lookup"><span data-stu-id="16c35-180">linear</span></span>
* <span data-ttu-id="16c35-181">softmax</span><span class="sxs-lookup"><span data-stu-id="16c35-181">softmax</span></span>
* <span data-ttu-id="16c35-182">rlinear</span><span class="sxs-lookup"><span data-stu-id="16c35-182">rlinear</span></span>
* <span data-ttu-id="16c35-183">Ruta</span><span class="sxs-lookup"><span data-stu-id="16c35-183">square</span></span>
* <span data-ttu-id="16c35-184">rot</span><span class="sxs-lookup"><span data-stu-id="16c35-184">sqrt</span></span>
* <span data-ttu-id="16c35-185">srlinear</span><span class="sxs-lookup"><span data-stu-id="16c35-185">srlinear</span></span>
* <span data-ttu-id="16c35-186">ABS</span><span class="sxs-lookup"><span data-stu-id="16c35-186">abs</span></span>
* <span data-ttu-id="16c35-187">TANH</span><span class="sxs-lookup"><span data-stu-id="16c35-187">tanh</span></span> 
* <span data-ttu-id="16c35-188">brlinear</span><span class="sxs-lookup"><span data-stu-id="16c35-188">brlinear</span></span>  

<span data-ttu-id="16c35-189">Hello följande deklaration använder exempelvis hello **softmax** funktionen:</span><span class="sxs-lookup"><span data-stu-id="16c35-189">For example, hello following declaration uses hello **softmax** function:</span></span>  

    output Result [100] softmax from Hidden all;  

## <a name="connection-declaration"></a><span data-ttu-id="16c35-190">Deklarationen för anslutning</span><span class="sxs-lookup"><span data-stu-id="16c35-190">Connection declaration</span></span>
<span data-ttu-id="16c35-191">Du måste deklarera anslutningar mellan hello lager som du har definierat omedelbart när du har definierat hello trainable lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-191">Immediately after defining hello trainable layer, you must declare connections among hello layers you have defined.</span></span> <span data-ttu-id="16c35-192">hello anslutning paket deklaration börjar med nyckelordet hello **från**, följt av hello paket lager och hello datakälltypen av anslutningen paket toocreate hello namn.</span><span class="sxs-lookup"><span data-stu-id="16c35-192">hello connection bundle declaration starts with hello keyword **from**, followed by hello name of hello bundle's source layer and hello kind of connection bundle toocreate.</span></span>   

<span data-ttu-id="16c35-193">För närvarande stöds fem typer av paket för anslutningen:</span><span class="sxs-lookup"><span data-stu-id="16c35-193">Currently, five kinds of connection bundles are supported:</span></span>  

* <span data-ttu-id="16c35-194">**Fullständig** paket som anges av hello nyckelordet **alla**</span><span class="sxs-lookup"><span data-stu-id="16c35-194">**Full** bundles, indicated by hello keyword **all**</span></span>
* <span data-ttu-id="16c35-195">**Filtrerade** paket som anges av hello nyckelordet **där**, följt av ett predikat uttryck</span><span class="sxs-lookup"><span data-stu-id="16c35-195">**Filtered** bundles, indicated by hello keyword **where**, followed by a predicate expression</span></span>
* <span data-ttu-id="16c35-196">**Convolutional** paket som anges av hello nyckelordet **convolve**, följt av hello Faltning attribut</span><span class="sxs-lookup"><span data-stu-id="16c35-196">**Convolutional** bundles, indicated by hello keyword **convolve**, followed by hello convolution attributes</span></span>
* <span data-ttu-id="16c35-197">**Poolning** paket som anges av hello nyckelord **max poolen** eller **innebär pool**</span><span class="sxs-lookup"><span data-stu-id="16c35-197">**Pooling** bundles, indicated by hello keywords **max pool** or **mean pool**</span></span>
* <span data-ttu-id="16c35-198">**Svaret normalisering** paket som anges av hello nyckelordet **svar normen**</span><span class="sxs-lookup"><span data-stu-id="16c35-198">**Response normalization** bundles, indicated by hello keyword **response norm**</span></span>      

## <a name="full-bundles"></a><span data-ttu-id="16c35-199">Fullständig paket</span><span class="sxs-lookup"><span data-stu-id="16c35-199">Full bundles</span></span>
<span data-ttu-id="16c35-200">En fullständig anslutning bunt innehåller en anslutning från varje nod i hello layer tooeach Källnoden i hello mållagret.</span><span class="sxs-lookup"><span data-stu-id="16c35-200">A full connection bundle includes a connection from each node in hello source layer tooeach node in hello destination layer.</span></span> <span data-ttu-id="16c35-201">Detta är hello standardanslutningstyp av nätverksanslutning.</span><span class="sxs-lookup"><span data-stu-id="16c35-201">This is hello default network connection type.</span></span>  

## <a name="filtered-bundles"></a><span data-ttu-id="16c35-202">Filtrerade paket</span><span class="sxs-lookup"><span data-stu-id="16c35-202">Filtered bundles</span></span>
<span data-ttu-id="16c35-203">En filtrerad anslutning paket specifikation innehåller ett predikat, uttryckt syntaktiskt, mycket som ett C# lambda-uttryck.</span><span class="sxs-lookup"><span data-stu-id="16c35-203">A filtered connection bundle specification includes a predicate, expressed syntactically, much like a C# lambda expression.</span></span> <span data-ttu-id="16c35-204">hello definierar följande exempel två filtrerade paket:</span><span class="sxs-lookup"><span data-stu-id="16c35-204">hello following example defines two filtered bundles:</span></span>  

    input Pixels [10, 20];
    hidden ByRow[10, 12] from Pixels where (s,d) => s[0] == d[0];
    hidden ByCol[5, 20] from Pixels where (s,d) => abs(s[1] - d[1]) <= 1;  

* <span data-ttu-id="16c35-205">I hello predikatet för *ByRow*, **s** är en parameter som representerar ett index i hello rektangulär matris av noder av hello inkommande lagret, *bildpunkter*, och **d**  är en parameter som representerar ett index i hello array noder i hello dolda lagret, *ByRow*.</span><span class="sxs-lookup"><span data-stu-id="16c35-205">In hello predicate for *ByRow*, **s** is a parameter representing an index into hello rectangular array of nodes of hello input layer, *Pixels*, and **d** is a parameter representing an index into hello array of nodes of hello hidden layer, *ByRow*.</span></span> <span data-ttu-id="16c35-206">Hej typ av både **s** och **d** är en tuppel med heltal med längden två.</span><span class="sxs-lookup"><span data-stu-id="16c35-206">hello type of both **s** and **d** is a tuple of integers of length two.</span></span> <span data-ttu-id="16c35-207">Begreppsmässigt **s** sträcker sig över alla par med heltal med *0 < = s [0] < 10* och *0 < = s[1] < 20*, och **d**  sträcker sig över alla par med heltal, med *0 < = d [0] < 10* och *0 < = d[1] < 12*.</span><span class="sxs-lookup"><span data-stu-id="16c35-207">Conceptually, **s** ranges over all pairs of integers with *0 <= s[0] < 10* and *0 <= s[1] < 20*, and **d** ranges over all pairs of integers, with *0 <= d[0] < 10* and *0 <= d[1] < 12*.</span></span> 
* <span data-ttu-id="16c35-208">På hello höger i hello predikatuttryck finns det ett villkor.</span><span class="sxs-lookup"><span data-stu-id="16c35-208">On hello right-hand side of hello predicate expression, there is a condition.</span></span> <span data-ttu-id="16c35-209">I det här exemplet för varje värde i **s** och **d** så att hello villkoret är sant, det finns en gräns från hello källa layer nod toohello layer målnoden.</span><span class="sxs-lookup"><span data-stu-id="16c35-209">In this example, for every value of **s** and **d** such that hello condition is True, there is an edge from hello source layer node toohello destination layer node.</span></span> <span data-ttu-id="16c35-210">Därför det här filteruttrycket anger att hello-paket innehåller en anslutning från hello-noden som definieras av **s** toohello nod som definieras av **d** i samtliga fall där s [0] är lika tood [0].</span><span class="sxs-lookup"><span data-stu-id="16c35-210">Thus, this filter expression indicates that hello bundle includes a connection from hello node defined by **s** toohello node defined by **d** in all cases where s[0] is equal tood[0].</span></span>  

<span data-ttu-id="16c35-211">Du kan också kan du ange en uppsättning vikterna för ett filtrerade paket.</span><span class="sxs-lookup"><span data-stu-id="16c35-211">Optionally, you can specify a set of weights for a filtered bundle.</span></span> <span data-ttu-id="16c35-212">Hej värde för hello **vikterna** attributet måste vara en tuppel av flytande punktvärden med en längd som matchar hello antalet anslutningar som definieras av hello-paket.</span><span class="sxs-lookup"><span data-stu-id="16c35-212">hello value for hello **Weights** attribute must be a tuple of floating point values with a length that matches hello number of connections defined by hello bundle.</span></span> <span data-ttu-id="16c35-213">Som standard genereras slumpmässigt vikter.</span><span class="sxs-lookup"><span data-stu-id="16c35-213">By default, weights are randomly generated.</span></span>  

<span data-ttu-id="16c35-214">Värde som är grupperade efter hello index för noden.</span><span class="sxs-lookup"><span data-stu-id="16c35-214">Weight values are grouped by hello destination node index.</span></span> <span data-ttu-id="16c35-215">Det vill säga om hello första Målnoden är ansluten tog källa noder hello först *K* element i hello **vikterna** tuppel är hello vikterna för hello första målnoden i källan index ordning.</span><span class="sxs-lookup"><span data-stu-id="16c35-215">That is, if hello first destination node is connected tooK source nodes, hello first *K* elements of hello **Weights** tuple are hello weights for hello first destination node, in source index order.</span></span> <span data-ttu-id="16c35-216">hello samma gäller för hello återstående mål noder.</span><span class="sxs-lookup"><span data-stu-id="16c35-216">hello same applies for hello remaining destination nodes.</span></span>  

<span data-ttu-id="16c35-217">Det är möjligt toospecify vikterna direkt som konstanta värden.</span><span class="sxs-lookup"><span data-stu-id="16c35-217">It's possible toospecify weights directly as constant values.</span></span> <span data-ttu-id="16c35-218">Om du har lärt dig hello vikterna tidigare kan du exempelvis ange dem som konstanter med följande syntax:</span><span class="sxs-lookup"><span data-stu-id="16c35-218">For example, if you learned hello weights previously, you can specify them as constants using this syntax:</span></span>

    const Weights_1 = [0.0188045055, 0.130500451, ...]


## <a name="convolutional-bundles"></a><span data-ttu-id="16c35-219">Convolutional paket</span><span class="sxs-lookup"><span data-stu-id="16c35-219">Convolutional bundles</span></span>
<span data-ttu-id="16c35-220">När hello träningsdata har en homogen struktur, är convolutional anslutningar används ofta toolearn avancerade funktioner hello data.</span><span class="sxs-lookup"><span data-stu-id="16c35-220">When hello training data has a homogeneous structure, convolutional connections are commonly used toolearn high-level features of hello data.</span></span> <span data-ttu-id="16c35-221">Till exempel i bild, ljud- och data, spatial eller temporal dimensionalitet kan vara ganska enhetlig.</span><span class="sxs-lookup"><span data-stu-id="16c35-221">For example, in image, audio, or video data, spatial or temporal dimensionality can be fairly uniform.</span></span>  

<span data-ttu-id="16c35-222">Convolutional paket använder rektangulär **kärnor** som slid via hello dimensioner.</span><span class="sxs-lookup"><span data-stu-id="16c35-222">Convolutional bundles employ rectangular **kernels** that are slid through hello dimensions.</span></span> <span data-ttu-id="16c35-223">I princip varje kernel definierar en uppsättning vikten som används i lokala neighborhoods, enligt tooas **kernel-program**.</span><span class="sxs-lookup"><span data-stu-id="16c35-223">Essentially, each kernel defines a set of weights applied in local neighborhoods, referred tooas **kernel applications**.</span></span> <span data-ttu-id="16c35-224">Varje kernel-program motsvarar tooa nod i hello källa lager som är refererad tooas hello **centrala nod**.</span><span class="sxs-lookup"><span data-stu-id="16c35-224">Each kernel application corresponds tooa node in hello source layer, which is referred tooas hello **central node**.</span></span> <span data-ttu-id="16c35-225">hello vikten av en kernel delas av många anslutningar.</span><span class="sxs-lookup"><span data-stu-id="16c35-225">hello weights of a kernel are shared among many connections.</span></span> <span data-ttu-id="16c35-226">I en convolutional bundle varje kernel är rektangulär och alla kernel-program är hello samma storlek.</span><span class="sxs-lookup"><span data-stu-id="16c35-226">In a convolutional bundle, each kernel is rectangular and all kernel applications are hello same size.</span></span>  

<span data-ttu-id="16c35-227">Convolutional paket stöder hello följande attribut:</span><span class="sxs-lookup"><span data-stu-id="16c35-227">Convolutional bundles support hello following attributes:</span></span>

<span data-ttu-id="16c35-228">**InputShape** definierar hello dimensionalitet för hello källa lager för hello convolutional paketet.</span><span class="sxs-lookup"><span data-stu-id="16c35-228">**InputShape** defines hello dimensionality of hello source layer for hello purposes of this convolutional bundle.</span></span> <span data-ttu-id="16c35-229">hello-värdet måste vara en tuppel med positivt heltal.</span><span class="sxs-lookup"><span data-stu-id="16c35-229">hello value must be a tuple of positive integers.</span></span> <span data-ttu-id="16c35-230">hello produkten av hello heltal måste vara lika med hello antalet noder i hello källa lagret, men i annat fall det behöver inte toomatch hello dimensionalitet har deklarerats för hello källa lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-230">hello product of hello integers must equal hello number of nodes in hello source layer, but otherwise, it does not need toomatch hello dimensionality declared for hello source layer.</span></span> <span data-ttu-id="16c35-231">hello längden på den här tuppeln blir hello **aritet** värde för hello convolutional paket.</span><span class="sxs-lookup"><span data-stu-id="16c35-231">hello length of this tuple becomes hello **arity** value for hello convolutional bundle.</span></span> <span data-ttu-id="16c35-232">(Normalt aritet refererar toohello antal argument eller operander som en funktion kan ta)</span><span class="sxs-lookup"><span data-stu-id="16c35-232">(Typically arity refers toohello number of arguments or operands that a function can take.)</span></span>  

<span data-ttu-id="16c35-233">toodefine hello form och platserna för hello kärnor använda hello attribut **KernelShape**, **Stride**, **utfyllnad**, **LowerPad**, och **UpperPad**:</span><span class="sxs-lookup"><span data-stu-id="16c35-233">toodefine hello shape and locations of hello kernels, use hello attributes **KernelShape**, **Stride**, **Padding**, **LowerPad**, and **UpperPad**:</span></span>   

* <span data-ttu-id="16c35-234">**KernelShape**: (obligatoriskt) anger hello dimensionaliteten för varje kernel för hello convolutional paket.</span><span class="sxs-lookup"><span data-stu-id="16c35-234">**KernelShape**: (required) Defines hello dimensionality of each kernel for hello convolutional bundle.</span></span> <span data-ttu-id="16c35-235">hello-värdet måste vara en tuppel med positiva heltal med en längd som är lika med hello aritet för hello-paket.</span><span class="sxs-lookup"><span data-stu-id="16c35-235">hello value must be a tuple of positive integers with a length that equals hello arity of hello bundle.</span></span> <span data-ttu-id="16c35-236">Varje komponent i den här tuppeln får inte vara större än motsvarande hello-komponenten i **InputShape**.</span><span class="sxs-lookup"><span data-stu-id="16c35-236">Each component of this tuple must be no greater than hello corresponding component of **InputShape**.</span></span> 
* <span data-ttu-id="16c35-237">**STRIDE**: (valfritt) anger hello glidande steg storlekar på hello Faltning (ett Stegstorlek för varje dimension), som är hello avståndet mellan hello centrala noder.</span><span class="sxs-lookup"><span data-stu-id="16c35-237">**Stride**: (optional) Defines hello sliding step sizes of hello convolution (one step size for each dimension), that is hello distance between hello central nodes.</span></span> <span data-ttu-id="16c35-238">hello-värdet måste vara en tuppel med positiva heltal med en längd som är hello aritet för hello-paket.</span><span class="sxs-lookup"><span data-stu-id="16c35-238">hello value must be a tuple of positive integers with a length that is hello arity of hello bundle.</span></span> <span data-ttu-id="16c35-239">Varje komponent i den här tuppeln får inte vara större än motsvarande hello-komponenten i **KernelShape**.</span><span class="sxs-lookup"><span data-stu-id="16c35-239">Each component of this tuple must be no greater than hello corresponding component of **KernelShape**.</span></span> <span data-ttu-id="16c35-240">hello standardvärdet är en tuppel med alla komponenter lika tooone.</span><span class="sxs-lookup"><span data-stu-id="16c35-240">hello default value is a tuple with all components equal tooone.</span></span> 
* <span data-ttu-id="16c35-241">**Dela**: (valfritt) anger hello vikt för varje dimension hello Faltning.</span><span class="sxs-lookup"><span data-stu-id="16c35-241">**Sharing**: (optional) Defines hello weight sharing for each dimension of hello convolution.</span></span> <span data-ttu-id="16c35-242">hello-värdet kan vara ett booleskt värde eller en tuppel med booleska värden med en längd som är hello aritet för hello-paket.</span><span class="sxs-lookup"><span data-stu-id="16c35-242">hello value can be a single Boolean value or a tuple of Boolean values with a length that is hello arity of hello bundle.</span></span> <span data-ttu-id="16c35-243">Ett booleskt värde som är utökad toobe en tuppel hello rätt längd med alla komponenter lika toohello angivet värde.</span><span class="sxs-lookup"><span data-stu-id="16c35-243">A single Boolean value is extended toobe a tuple of hello correct length with all components equal toohello specified value.</span></span> <span data-ttu-id="16c35-244">hello standardvärdet är en tuppel som består av alla värden som True.</span><span class="sxs-lookup"><span data-stu-id="16c35-244">hello default value is a tuple that consists of all True values.</span></span> 
* <span data-ttu-id="16c35-245">**MapCount**: (valfritt) anger hello antalet funktionen mappar för hello convolutional paket.</span><span class="sxs-lookup"><span data-stu-id="16c35-245">**MapCount**: (optional) Defines hello number of feature maps for hello convolutional bundle.</span></span> <span data-ttu-id="16c35-246">hello-värdet kan vara ett enda positivt heltal eller en tuppel med positiva heltal med en längd som är hello aritet för hello-paket.</span><span class="sxs-lookup"><span data-stu-id="16c35-246">hello value can be a single positive integer or a tuple of positive integers with a length that is hello arity of hello bundle.</span></span> <span data-ttu-id="16c35-247">Ett enda heltal utökas toobe en tuppel hello rätt längd med hello första komponenter lika toohello anges värdet och alla hello återstående komponenter lika tooone.</span><span class="sxs-lookup"><span data-stu-id="16c35-247">A single integer value is extended toobe a tuple of hello correct length with hello first components equal toohello specified value and all hello remaining components equal tooone.</span></span> <span data-ttu-id="16c35-248">hello standardvärdet är en.</span><span class="sxs-lookup"><span data-stu-id="16c35-248">hello default value is one.</span></span> <span data-ttu-id="16c35-249">hello Totalt antal funktionen maps är hello produkt hello komponenter i hello tuppel.</span><span class="sxs-lookup"><span data-stu-id="16c35-249">hello total number of feature maps is hello product of hello components of hello tuple.</span></span> <span data-ttu-id="16c35-250">hello factoring för detta totala antal för hello komponenter bestämmer hur hello funktionen mappa värden grupperas i hello mål noder.</span><span class="sxs-lookup"><span data-stu-id="16c35-250">hello factoring of this total number across hello components determines how hello feature map values are grouped in hello destination nodes.</span></span> 
* <span data-ttu-id="16c35-251">**Vikterna**: (valfritt) anger hello inledande vikterna för hello-paket.</span><span class="sxs-lookup"><span data-stu-id="16c35-251">**Weights**: (optional) Defines hello initial weights for hello bundle.</span></span> <span data-ttu-id="16c35-252">hello-värdet måste vara en tuppel av flytande punktvärden med en längd som är hello antalet kärnor gånger hello vikterna per kernel, enligt nedan.</span><span class="sxs-lookup"><span data-stu-id="16c35-252">hello value must be a tuple of floating point values with a length that is hello number of kernels times hello number of weights per kernel, as defined later in this article.</span></span> <span data-ttu-id="16c35-253">Hej Standardvikterna genereras slumpmässigt.</span><span class="sxs-lookup"><span data-stu-id="16c35-253">hello default weights are randomly generated.</span></span>  

<span data-ttu-id="16c35-254">Det finns två uppsättningar med egenskaper som styr utfyllnad, hello egenskaper som inte anges samtidigt:</span><span class="sxs-lookup"><span data-stu-id="16c35-254">There are two sets of properties that control padding, hello properties being mutually exclusive:</span></span>

* <span data-ttu-id="16c35-255">**Utfyllnad**: (valfritt) avgör om hello indata ska bli utfyllt med hjälp av en **utfyllnad standardschema**.</span><span class="sxs-lookup"><span data-stu-id="16c35-255">**Padding**: (optional) Determines whether hello input should be padded by using a **default padding scheme**.</span></span> <span data-ttu-id="16c35-256">hello-värdet kan vara ett booleskt värde eller det kan vara en tuppel med booleska värden med en längd som är hello aritet för hello-paket.</span><span class="sxs-lookup"><span data-stu-id="16c35-256">hello value can be a single Boolean value, or it can be a tuple of Boolean values with a length that is hello arity of hello bundle.</span></span> <span data-ttu-id="16c35-257">Ett booleskt värde som är utökad toobe en tuppel hello rätt längd med alla komponenter lika toohello angivet värde.</span><span class="sxs-lookup"><span data-stu-id="16c35-257">A single Boolean value is extended toobe a tuple of hello correct length with all components equal toohello specified value.</span></span> <span data-ttu-id="16c35-258">Om hello värde för en dimension är True utfyllnad hello källa logiskt i dimensionen med cellerna noll-värden toosupport ytterligare kernel-program så att hello centrala noder i hello första och sista kernlar som är i den aktuella dimensionen är hello första och sista noder i den dimensionen i hello källa lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-258">If hello value for a dimension is True, hello source is logically padded in that dimension with zero-valued cells toosupport additional kernel applications, such that hello central nodes of hello first and last kernels in that dimension are hello first and last nodes in that dimension in hello source layer.</span></span> <span data-ttu-id="16c35-259">Därför hello antalet ”falska” noder i varje dimension är fastställt automatiskt toofit exakt *(InputShape [d] - 1) / Stride [d] + 1* kärnor till hello utfyllnad källa lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-259">Thus, hello number of "dummy" nodes in each dimension is determined automatically, toofit exactly *(InputShape[d] - 1) / Stride[d] + 1* kernels into hello padded source layer.</span></span> <span data-ttu-id="16c35-260">Om hello-värdet för en dimension är False, hello hello kernlar som är definierade så att hello antalet noder på varje sida som lämnas ut är samma (upp tooa skillnaden mellan 1).</span><span class="sxs-lookup"><span data-stu-id="16c35-260">If hello value for a dimension is False, hello kernels are defined so that hello number of nodes on each side that are left out is hello same (up tooa difference of 1).</span></span> <span data-ttu-id="16c35-261">hello standardvärdet för det här attributet är en tuppel med alla komponenter lika tooFalse.</span><span class="sxs-lookup"><span data-stu-id="16c35-261">hello default value of this attribute is a tuple with all components equal tooFalse.</span></span>
* <span data-ttu-id="16c35-262">**UpperPad** och **LowerPad**: (valfritt) Ange större kontroll över hello mängden utfyllnad toouse.</span><span class="sxs-lookup"><span data-stu-id="16c35-262">**UpperPad** and **LowerPad**: (optional) Provide greater control over hello amount of padding toouse.</span></span> <span data-ttu-id="16c35-263">**Viktigt:** attributen kan definieras om och bara om hello **utfyllnad** egenskapen ovan är ***inte*** definieras.</span><span class="sxs-lookup"><span data-stu-id="16c35-263">**Important:** These attributes can be defined if and only if hello **Padding** property above is ***not*** defined.</span></span> <span data-ttu-id="16c35-264">hello-värden måste vara heltal enkelvärdesattribut tupplar med längd som är hello aritet för hello-paket.</span><span class="sxs-lookup"><span data-stu-id="16c35-264">hello values should be integer-valued tuples with lengths that are hello arity of hello bundle.</span></span> <span data-ttu-id="16c35-265">När dessa attribut har angetts ”falska” noder läggs toohello lägre och övre ändar av varje dimension hello ingående lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-265">When these attributes are specified, "dummy" nodes are added toohello lower and upper ends of each dimension of hello input layer.</span></span> <span data-ttu-id="16c35-266">hello antalet noder som lagts till toohello lägre och övre ends i varje dimension bestäms av **LowerPad**[i] och **UpperPad**[i] respektive.</span><span class="sxs-lookup"><span data-stu-id="16c35-266">hello number of nodes added toohello lower and upper ends in each dimension is determined by **LowerPad**[i] and **UpperPad**[i] respectively.</span></span> <span data-ttu-id="16c35-267">tooensure att kärnor överensstämmer endast för ”verkliga” noderna och inte för ”falska” noder hello följande villkor uppfyllas:</span><span class="sxs-lookup"><span data-stu-id="16c35-267">tooensure that kernels correspond only too"real" nodes and not too"dummy" nodes, hello following conditions must be met:</span></span>
  * <span data-ttu-id="16c35-268">Varje komponent i **LowerPad** måste vara absolut mindre än KernelShape [d] / 2.</span><span class="sxs-lookup"><span data-stu-id="16c35-268">Each component of **LowerPad** must be strictly less than KernelShape[d]/2.</span></span> 
  * <span data-ttu-id="16c35-269">Varje komponent i **UpperPad** får inte vara större än KernelShape [d] / 2.</span><span class="sxs-lookup"><span data-stu-id="16c35-269">Each component of **UpperPad** must be no greater than KernelShape[d]/2.</span></span> 
  * <span data-ttu-id="16c35-270">hello standardvärdet av dessa attribut är en tuppel med alla komponenter lika too0.</span><span class="sxs-lookup"><span data-stu-id="16c35-270">hello default value of these attributes is a tuple with all components equal too0.</span></span> 

<span data-ttu-id="16c35-271">hello inställningen **utfyllnad** = true gör det mycket utfyllnad som behövs tookeep hello ”mittpunkt” hello kernel inuti hello ”riktigt” indata.</span><span class="sxs-lookup"><span data-stu-id="16c35-271">hello setting **Padding** = true allows as much padding as is needed tookeep hello "center" of hello kernel inside hello "real" input.</span></span> <span data-ttu-id="16c35-272">Hello matematiska lite för datoranvändning hello storlek ändras.</span><span class="sxs-lookup"><span data-stu-id="16c35-272">This changes hello math a bit for computing hello output size.</span></span> <span data-ttu-id="16c35-273">I allmänhet storleken på utdata hello *D* beräknas som *D = (I - K) / S + 1*, där *jag* är hello inkommande storlek *K* hello kernel storlek *S* är hello stride och  */*  är Heltalsdivision (avrunda mot noll).</span><span class="sxs-lookup"><span data-stu-id="16c35-273">Generally, hello output size *D* is computed as *D = (I - K) / S + 1*, where *I* is hello input size, *K* is hello kernel size, *S* is hello stride, and */* is integer division (round toward zero).</span></span> <span data-ttu-id="16c35-274">Om du ställer in UpperPad = [1, 1] hello indata storlek *jag* är i praktiken 29, och därmed *D = (29-5) / 2 + 1 = 13*.</span><span class="sxs-lookup"><span data-stu-id="16c35-274">If you set UpperPad = [1, 1], hello input size *I* is effectively 29, and thus *D = (29 - 5) / 2 + 1 = 13*.</span></span> <span data-ttu-id="16c35-275">Men när **utfyllnad** = true, i stort sett *jag* hämtar ökar av *K - 1*; därför *D = ((28 + 4) - 5) / 27 + 1 = 2 / 2 + 1 = 13 + 1 = 14*.</span><span class="sxs-lookup"><span data-stu-id="16c35-275">However, when **Padding** = true, essentially *I* gets bumped up by *K - 1*; hence *D = ((28 + 4) - 5) / 2 + 1 = 27 / 2 + 1 = 13 + 1 = 14*.</span></span> <span data-ttu-id="16c35-276">Genom att ange värden för **UpperPad** och **LowerPad** du får mycket mer kontroll över hello utfyllnad än om du just ställt **utfyllnad** = true.</span><span class="sxs-lookup"><span data-stu-id="16c35-276">By specifying values for **UpperPad** and **LowerPad** you get much more control over hello padding than if you just set **Padding** = true.</span></span>

<span data-ttu-id="16c35-277">Mer information om convolutional nätverk och deras program finns i de här artiklarna:</span><span class="sxs-lookup"><span data-stu-id="16c35-277">For more information about convolutional networks and their applications, see these articles:</span></span>  

* [<span data-ttu-id="16c35-278">http://deeplearning.NET/Tutorial/lenet.HTML</span><span class="sxs-lookup"><span data-stu-id="16c35-278">http://deeplearning.net/tutorial/lenet.html </span></span>](http://deeplearning.net/tutorial/lenet.html)
* [<span data-ttu-id="16c35-279">http://Research.microsoft.com/pubs/68920/icdar03.PDF</span><span class="sxs-lookup"><span data-stu-id="16c35-279">http://research.microsoft.com/pubs/68920/icdar03.pdf</span></span>](http://research.microsoft.com/pubs/68920/icdar03.pdf) 
* [<span data-ttu-id="16c35-280">http://People.csail.MIT.edu/jvb/Papers/cnn_tutorial.PDF</span><span class="sxs-lookup"><span data-stu-id="16c35-280">http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf</span></span>](http://people.csail.mit.edu/jvb/papers/cnn_tutorial.pdf)  

## <a name="pooling-bundles"></a><span data-ttu-id="16c35-281">Poolning paket</span><span class="sxs-lookup"><span data-stu-id="16c35-281">Pooling bundles</span></span>
<span data-ttu-id="16c35-282">En **poolning paket** gäller geometri liknande tooconvolutional anslutning, men med fördefinierade funktioner toosource nod värden tooderive hello mål nodvärde.</span><span class="sxs-lookup"><span data-stu-id="16c35-282">A **pooling bundle** applies geometry similar tooconvolutional connectivity, but it uses predefined functions toosource node values tooderive hello destination node value.</span></span> <span data-ttu-id="16c35-283">Därför har anslutningspoolen paket inga trainable tillstånd (vikterna eller eventuella fördomar).</span><span class="sxs-lookup"><span data-stu-id="16c35-283">Hence, pooling bundles have no trainable state (weights or biases).</span></span> <span data-ttu-id="16c35-284">Poolning paket stöd för alla hello convolutional attribut utom **delning**, **MapCount**, och **vikterna**.</span><span class="sxs-lookup"><span data-stu-id="16c35-284">Pooling bundles support all hello convolutional attributes except **Sharing**, **MapCount**, and **Weights**.</span></span>  

<span data-ttu-id="16c35-285">Normalt hello kärnor sammanfattning av intilliggande anslutningspoolen enheter inte överlappar varandra.</span><span class="sxs-lookup"><span data-stu-id="16c35-285">Typically, hello kernels summarized by adjacent pooling units do not overlap.</span></span> <span data-ttu-id="16c35-286">Om Stride [d] lika tooKernelShape [d] i varje dimension är hello layer fick hello traditionella lokala anslutningspoolen lager, som ofta används i convolutional neurala nätverk.</span><span class="sxs-lookup"><span data-stu-id="16c35-286">If Stride[d] is equal tooKernelShape[d] in each dimension, hello layer obtained is hello traditional local pooling layer, which is commonly employed in convolutional neural networks.</span></span> <span data-ttu-id="16c35-287">Varje målnoden beräknar hello maximala eller hello medelvärdet av hello aktiviteter för dess kernel i hello källa lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-287">Each destination node computes hello maximum or hello mean of hello activities of its kernel in hello source layer.</span></span>  

<span data-ttu-id="16c35-288">hello följande exempel illustrerar ett anslutningspoolen paket:</span><span class="sxs-lookup"><span data-stu-id="16c35-288">hello following example illustrates a pooling bundle:</span></span> 

    hidden P1 [5, 12, 12]
      from C1 max pool {
        InputShape  = [ 5, 24, 24];
        KernelShape = [ 1,  2,  2];
        Stride      = [ 1,  2,  2];
      }  

* <span data-ttu-id="16c35-289">hello aritet för hello-paket är 3 (hello längden på hello tupplar **InputShape**, **KernelShape**, och **Stride**).</span><span class="sxs-lookup"><span data-stu-id="16c35-289">hello arity of hello bundle is 3 (hello length of hello tuples **InputShape**, **KernelShape**, and **Stride**).</span></span> 
* <span data-ttu-id="16c35-290">hello antalet noder i hello källa lagret är *5 * 24 * 24 = 2 880*.</span><span class="sxs-lookup"><span data-stu-id="16c35-290">hello number of nodes in hello source layer is *5 * 24 * 24 = 2880*.</span></span> 
* <span data-ttu-id="16c35-291">Detta är ett vanligt lokala anslutningspoolen lager eftersom **KernelShape** och **Stride** är lika.</span><span class="sxs-lookup"><span data-stu-id="16c35-291">This is a traditional local pooling layer because **KernelShape** and **Stride** are equal.</span></span> 
* <span data-ttu-id="16c35-292">hello antalet noder i hello mållagret är *5 * 12 * 12 = 1440*.</span><span class="sxs-lookup"><span data-stu-id="16c35-292">hello number of nodes in hello destination layer is *5 * 12 * 12 = 1440*.</span></span>  

<span data-ttu-id="16c35-293">Mer information om anslutningspoolen lager finns dessa artiklar:</span><span class="sxs-lookup"><span data-stu-id="16c35-293">For more information about pooling layers, see these articles:</span></span>  

* <span data-ttu-id="16c35-294">[http://www.CS.Toronto.edu/~hinton/absps/imagenet.PDF](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf) (punkt 3.4)</span><span class="sxs-lookup"><span data-stu-id="16c35-294">[http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf) (Section 3.4)</span></span>
* [<span data-ttu-id="16c35-295">http://CS.nyu.edu/~koray/publis/lecun-iscas-10.PDF</span><span class="sxs-lookup"><span data-stu-id="16c35-295">http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf</span></span>](http://cs.nyu.edu/~koray/publis/lecun-iscas-10.pdf) 
* [<span data-ttu-id="16c35-296">http://CS.nyu.edu/~koray/publis/jarrett-iccv-09.PDF</span><span class="sxs-lookup"><span data-stu-id="16c35-296">http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf</span></span>](http://cs.nyu.edu/~koray/publis/jarrett-iccv-09.pdf)

## <a name="response-normalization-bundles"></a><span data-ttu-id="16c35-297">Svaret normalisering paket</span><span class="sxs-lookup"><span data-stu-id="16c35-297">Response normalization bundles</span></span>
<span data-ttu-id="16c35-298">**Svaret normalisering** är en lokal normalisering schema som introducerades av Geoffrey Hinton et al i hello dokumentet [ImageNet Classiﬁcation med djupa Neurala nätverk för Convolutional](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf).</span><span class="sxs-lookup"><span data-stu-id="16c35-298">**Response normalization** is a local normalization scheme that was first introduced by Geoffrey Hinton, et al, in hello paper [ImageNet Classiﬁcation with Deep Convolutional Neural Networks](http://www.cs.toronto.edu/~hinton/absps/imagenet.pdf).</span></span> <span data-ttu-id="16c35-299">Svaret normalisering är används tooaid generalisering i neural nät.</span><span class="sxs-lookup"><span data-stu-id="16c35-299">Response normalization is used tooaid generalization in neural nets.</span></span> <span data-ttu-id="16c35-300">När en neuron startar på en aktivering av mycket hög nivå, Undertrycker ett lager för lokala svar normalisering hello aktivering andelen hello omgivande neurons.</span><span class="sxs-lookup"><span data-stu-id="16c35-300">When one neuron is firing at a very high activation level, a local response normalization layer suppresses hello activation level of hello surrounding neurons.</span></span> <span data-ttu-id="16c35-301">Detta görs med hjälp av tre parametrar (***α***, ***β***, och ***k***) och en convolutional struktur (eller nätverket form).</span><span class="sxs-lookup"><span data-stu-id="16c35-301">This is done by using three parameters (***α***, ***β***, and ***k***) and a convolutional structure (or neighborhood shape).</span></span> <span data-ttu-id="16c35-302">Varje neuron i hello mållagret ***y*** motsvarar tooa neuron ***x*** i hello källa lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-302">Every neuron in hello destination layer ***y*** corresponds tooa neuron ***x*** in hello source layer.</span></span> <span data-ttu-id="16c35-303">Hej aktivering andelen ***y*** ges genom följande formel, hello där ***f*** är hello aktivering i en neuron och ***Nx*** hello kernel (eller hello uppsättning som innehåller hello neurons i hello nätverket av ***x***), enligt följande convolutional struktur hello:</span><span class="sxs-lookup"><span data-stu-id="16c35-303">hello activation level of ***y*** is given by hello following formula, where ***f*** is hello activation level of a neuron, and ***Nx*** is hello kernel (or hello set that contains hello neurons in hello neighborhood of ***x***), as defined by hello following convolutional structure:</span></span>  

![][1]  

<span data-ttu-id="16c35-304">Svaret normalisering paket stöder alla hello convolutional attribut utom **delning**, **MapCount**, och **vikterna**.</span><span class="sxs-lookup"><span data-stu-id="16c35-304">Response normalization bundles support all hello convolutional attributes except **Sharing**, **MapCount**, and **Weights**.</span></span>  

* <span data-ttu-id="16c35-305">Om hello kernel innehåller neurons i hello mappa samma som ***x***, hello normalisering schemat är refererad tooas **samma mappa normalisering**.</span><span class="sxs-lookup"><span data-stu-id="16c35-305">If hello kernel contains neurons in hello same map as ***x***, hello normalization scheme is referred tooas **same map normalization**.</span></span> <span data-ttu-id="16c35-306">toodefine samma mappa normalisering hello första koordinaten i **InputShape** måste ha hello värdet 1.</span><span class="sxs-lookup"><span data-stu-id="16c35-306">toodefine same map normalization, hello first coordinate in **InputShape** must have hello value 1.</span></span>
* <span data-ttu-id="16c35-307">Om hello kernel innehåller neurons i hello samma spatial position som ***x***, men hello neurons finns i andra mappar, hello normalisering schemat kallas **tvärs över mappar normalisering**.</span><span class="sxs-lookup"><span data-stu-id="16c35-307">If hello kernel contains neurons in hello same spatial position as ***x***, but hello neurons are in other maps, hello normalization scheme is called **across maps normalization**.</span></span> <span data-ttu-id="16c35-308">Den här typen av svar normalisering implementerar en form av laterala inhibition inspirerat av hello typ hittades i verkliga neurons skapar konkurrens om stora aktivering nivåer bland neuron utdata beräknad på olika maps.</span><span class="sxs-lookup"><span data-stu-id="16c35-308">This type of response normalization implements a form of lateral inhibition inspired by hello type found in real neurons, creating competition for big activation levels amongst neuron outputs computed on different maps.</span></span> <span data-ttu-id="16c35-309">toodefine över mappar normalisering hello första koordinat måste vara ett heltal större än ett och inte större än hello antalet maps och hello resten av hello koordinater måste ha hello värdet 1.</span><span class="sxs-lookup"><span data-stu-id="16c35-309">toodefine across maps normalization, hello first coordinate must be an integer greater than one and no greater than hello number of maps, and hello rest of hello coordinates must have hello value 1.</span></span>  

<span data-ttu-id="16c35-310">Eftersom svaret normalisering paket gäller en fördefinierad funktion toosource nod värden toodetermine hello mål nodvärde, har de inget trainable tillstånd (vikt eller eventuella fördomar).</span><span class="sxs-lookup"><span data-stu-id="16c35-310">Because response normalization bundles apply a predefined function toosource node values toodetermine hello destination node value, they have no trainable state (weights or biases).</span></span>   

<span data-ttu-id="16c35-311">**Varning**: hello noder i hello mållagret motsvarar tooneurons som är centrala hello-noder i hello kärnor.</span><span class="sxs-lookup"><span data-stu-id="16c35-311">**Alert**: hello nodes in hello destination layer correspond tooneurons that are hello central nodes of hello kernels.</span></span> <span data-ttu-id="16c35-312">Om KernelShape [d] är udda, till exempel *KernelShape [d] / 2* motsvarar toohello centrala kernel-nod.</span><span class="sxs-lookup"><span data-stu-id="16c35-312">For example, if KernelShape[d] is odd, then *KernelShape[d]/2* corresponds toohello central kernel node.</span></span> <span data-ttu-id="16c35-313">Om *KernelShape [d]* är jämnt, hello centrala noden är på *KernelShape [d] / 2-1*.</span><span class="sxs-lookup"><span data-stu-id="16c35-313">If *KernelShape[d]* is even, hello central node is at *KernelShape[d]/2 - 1*.</span></span> <span data-ttu-id="16c35-314">Därför om **utfyllnad**[d] har värdet False hello först och hello senast *KernelShape [d] / 2* noder har inte motsvarande noder i hello mållagret.</span><span class="sxs-lookup"><span data-stu-id="16c35-314">Therefore, if **Padding**[d] is False, hello first and hello last *KernelShape[d]/2* nodes do not have corresponding nodes in hello destination layer.</span></span> <span data-ttu-id="16c35-315">tooavoid den här situationen kan definiera **utfyllnad** som [true, true,..., true].</span><span class="sxs-lookup"><span data-stu-id="16c35-315">tooavoid this situation, define **Padding** as [true, true, …, true].</span></span>  

<span data-ttu-id="16c35-316">Dessutom beskrivs toohello fyra attribut tidigare svar normalisering paket också stöd hello följande attribut:</span><span class="sxs-lookup"><span data-stu-id="16c35-316">In addition toohello four attributes described earlier, response normalization bundles also support hello following attributes:</span></span>  

* <span data-ttu-id="16c35-317">**Alpha**: (obligatoriskt) anger ett värde som motsvarar för***α*** i hello tidigare formel.</span><span class="sxs-lookup"><span data-stu-id="16c35-317">**Alpha**: (required) Specifies a floating-point value that corresponds too***α*** in hello previous formula.</span></span> 
* <span data-ttu-id="16c35-318">**Beta**: (obligatoriskt) anger ett värde som motsvarar för***β*** i hello tidigare formel.</span><span class="sxs-lookup"><span data-stu-id="16c35-318">**Beta**: (required) Specifies a floating-point value that corresponds too***β*** in hello previous formula.</span></span> 
* <span data-ttu-id="16c35-319">**Förskjutning**: (valfritt) anger ett värde som motsvarar för***k*** i hello tidigare formel.</span><span class="sxs-lookup"><span data-stu-id="16c35-319">**Offset**: (optional) Specifies a floating-point value that corresponds too***k*** in hello previous formula.</span></span> <span data-ttu-id="16c35-320">Too1 standardvärdet.</span><span class="sxs-lookup"><span data-stu-id="16c35-320">It defaults too1.</span></span>  

<span data-ttu-id="16c35-321">hello definierar följande exempel ett svar normalisering paket med hjälp av dessa attribut:</span><span class="sxs-lookup"><span data-stu-id="16c35-321">hello following example defines a response normalization bundle using these attributes:</span></span>  

    hidden RN1 [5, 10, 10]
      from P1 response norm {
        InputShape  = [ 5, 12, 12];
        KernelShape = [ 1,  3,  3];
        Alpha = 0.001;
        Beta = 0.75;
      }  

* <span data-ttu-id="16c35-322">hello källa layer innehåller fem kartor, med aof dimension 12 x 12 summering 1440 noder.</span><span class="sxs-lookup"><span data-stu-id="16c35-322">hello source layer includes five maps, each with aof dimension of 12x12, totaling in 1440 nodes.</span></span> 
* <span data-ttu-id="16c35-323">Hej värdet för **KernelShape** anger att detta är en samma normalisering kartskiktet, där hello nätverket är en rektangel 3 x 3.</span><span class="sxs-lookup"><span data-stu-id="16c35-323">hello value of **KernelShape** indicates that this is a same map normalization layer, where hello neighborhood is a 3x3 rectangle.</span></span> 
* <span data-ttu-id="16c35-324">Hej standardvärdet **utfyllnad** är False, vilket hello mållagret har bara 10 noder i varje dimension.</span><span class="sxs-lookup"><span data-stu-id="16c35-324">hello default value of **Padding** is False, thus hello destination layer has only 10 nodes in each dimension.</span></span> <span data-ttu-id="16c35-325">tooinclude en nod i hello mållagret som motsvarar tooevery nod i hello källa layer utfyllnad = [true, true, true]; och ändra hello storleken på RN1 för [5, 12, 12].</span><span class="sxs-lookup"><span data-stu-id="16c35-325">tooinclude one node in hello destination layer that corresponds tooevery node in hello source layer, add Padding = [true, true, true]; and change hello size of RN1 too[5, 12, 12].</span></span>  

## <a name="share-declaration"></a><span data-ttu-id="16c35-326">Dela förklaring</span><span class="sxs-lookup"><span data-stu-id="16c35-326">Share declaration</span></span>
<span data-ttu-id="16c35-327">NET # stöder definiera flera paket med delade vikter.</span><span class="sxs-lookup"><span data-stu-id="16c35-327">Net# optionally supports defining multiple bundles with shared weights.</span></span> <span data-ttu-id="16c35-328">hello vikten av alla två paket kan delas om deras strukturer är hello samma.</span><span class="sxs-lookup"><span data-stu-id="16c35-328">hello weights of any two bundles can be shared if their structures are hello same.</span></span> <span data-ttu-id="16c35-329">hello följande syntax definierar paket med delade vikter:</span><span class="sxs-lookup"><span data-stu-id="16c35-329">hello following syntax defines bundles with shared weights:</span></span>  

    share-declaration:
        share    {    layer-list    }
        share    {    bundle-list    }
       share    {    bias-list    }

    layer-list:
        layer-name    ,    layer-name
        layer-list    ,    layer-name

    bundle-list:
       bundle-spec    ,    bundle-spec
        bundle-list    ,    bundle-spec

    bundle-spec:
       layer-name    =>     layer-name

    bias-list:
        bias-spec    ,    bias-spec
        bias-list    ,    bias-spec

    bias-spec:
        1    =>    layer-name

    layer-name:
        identifier  

<span data-ttu-id="16c35-330">Till exempel hello följande resurs-deklaration anger hello lagernamn som anger att både vikterna och eventuella fördomar ska delas:</span><span class="sxs-lookup"><span data-stu-id="16c35-330">For example, hello following share-declaration specifies hello layer names, indicating that both weights and biases should be shared:</span></span>  

    Const {
      InputSize = 37;
      HiddenSize = 50;
    }
    input {
      Data1 [InputSize];
      Data2 [InputSize];
    }
    hidden {
      H1 [HiddenSize] from Data1 all;
      H2 [HiddenSize] from Data2 all;
    }
    output Result [2] {
      from H1 all;
      from H2 all;
    }
    share { H1, H2 } // share both weights and biases  

* <span data-ttu-id="16c35-331">hello inkommande funktioner delas upp i två lika storlek inkommande lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-331">hello input features are partitioned into two equal sized input layers.</span></span> 
* <span data-ttu-id="16c35-332">hello dolda lager för att beräkna högre nivå funktioner på hello två inkommande lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-332">hello hidden layers then compute higher level features on hello two input layers.</span></span> 
* <span data-ttu-id="16c35-333">hello resurs-deklarationen anger att *H1* och *H2* måste beräknas i hello samma sätt från deras respektive indata.</span><span class="sxs-lookup"><span data-stu-id="16c35-333">hello share-declaration specifies that *H1* and *H2* must be computed in hello same way from their respective inputs.</span></span>  

<span data-ttu-id="16c35-334">Du kan också anges detta med två olika resurs-deklarationer enligt följande:</span><span class="sxs-lookup"><span data-stu-id="16c35-334">Alternatively, this could be specified with two separate share-declarations as follows:</span></span>  

    share { Data1 => H1, Data2 => H2 } // share weights  

<!-- -->

    share { 1 => H1, 1 => H2 } // share biases  

<span data-ttu-id="16c35-335">Du kan använda hello kort form endast när hello lager innehåller ett paket.</span><span class="sxs-lookup"><span data-stu-id="16c35-335">You can use hello short form only when hello layers contain a single bundle.</span></span> <span data-ttu-id="16c35-336">I allmänhet är delning endast möjligt när hello relevanta strukturen är identiska, vilket innebär att de har hello samma storlek, samma convolutional geometri, och så vidare.</span><span class="sxs-lookup"><span data-stu-id="16c35-336">In general, sharing is possible only when hello relevant structure is identical, meaning that they have hello same size, same convolutional geometry, and so forth.</span></span>  

## <a name="examples-of-net-usage"></a><span data-ttu-id="16c35-337">Exempel på användning av Net #</span><span class="sxs-lookup"><span data-stu-id="16c35-337">Examples of Net# usage</span></span>
<span data-ttu-id="16c35-338">Det här avsnittet innehåller några exempel på hur du kan använda Net # tooadd dolda lager, definiera hello sätt att dolda lager interagera med andra lager och bygga convolutional nätverk.</span><span class="sxs-lookup"><span data-stu-id="16c35-338">This section provides some examples of how you can use Net# tooadd hidden layers, define hello way that hidden layers interact with other layers, and build convolutional networks.</span></span>   

### <a name="define-a-simple-custom-neural-network-hello-world-example"></a><span data-ttu-id="16c35-339">Definiera en enkel anpassade neurala nätverket: ”Hello World”-exempel</span><span class="sxs-lookup"><span data-stu-id="16c35-339">Define a simple custom neural network: "Hello World" example</span></span>
<span data-ttu-id="16c35-340">Det här enkla exemplet visar hur toocreate en neurala nätverk modellen som har ett dolt lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-340">This simple example demonstrates how toocreate a neural network model that has a single hidden layer.</span></span>  

    input Data auto;
    hidden H [200] from Data all;
    output Out [10] sigmoid from H all;  

<span data-ttu-id="16c35-341">hello exemplet vissa grundläggande kommandon på följande sätt:</span><span class="sxs-lookup"><span data-stu-id="16c35-341">hello example illustrates some basic commands as follows:</span></span>  

* <span data-ttu-id="16c35-342">hello första raden definierar hello inkommande lager (med namnet *Data*).</span><span class="sxs-lookup"><span data-stu-id="16c35-342">hello first line defines hello input layer (named *Data*).</span></span> <span data-ttu-id="16c35-343">När du använder hello **automatisk** nyckelordet hello neurala nätverket inkluderar automatiskt alla kolumner i funktionen i hello inkommande exempel.</span><span class="sxs-lookup"><span data-stu-id="16c35-343">When you use hello  **auto** keyword, hello neural network automatically includes all feature columns in hello input examples.</span></span> 
* <span data-ttu-id="16c35-344">hello andra raden skapar hello dolda lagret.</span><span class="sxs-lookup"><span data-stu-id="16c35-344">hello second line creates hello hidden layer.</span></span> <span data-ttu-id="16c35-345">hello namnet *H* tilldelas toohello dolda lagret, vilket har 200 noder.</span><span class="sxs-lookup"><span data-stu-id="16c35-345">hello name *H* is assigned toohello hidden layer, which has 200 nodes.</span></span> <span data-ttu-id="16c35-346">Det här lagret är fullt ansluten toohello inkommande lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-346">This layer is fully connected toohello input layer.</span></span>
* <span data-ttu-id="16c35-347">hello tredje raden definierar hello utdata layer (med namnet *O*), som innehåller 10 utdata-noder.</span><span class="sxs-lookup"><span data-stu-id="16c35-347">hello third line defines hello output layer (named *O*), which contains 10 output nodes.</span></span> <span data-ttu-id="16c35-348">Om hello neurala nätverket används för klassificering, är det en utdata nod per klass.</span><span class="sxs-lookup"><span data-stu-id="16c35-348">If hello neural network is used for classification, there is one output node per class.</span></span> <span data-ttu-id="16c35-349">Hej nyckelordet **sigmoid** anger hello utdata är tillämpade toohello utdata lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-349">hello keyword **sigmoid** indicates that hello output function is applied toohello output layer.</span></span>   

### <a name="define-multiple-hidden-layers-computer-vision-example"></a><span data-ttu-id="16c35-350">Definiera flera dolda lager: datorn vision exempel</span><span class="sxs-lookup"><span data-stu-id="16c35-350">Define multiple hidden layers: computer vision example</span></span>
<span data-ttu-id="16c35-351">hello exemplet nedan visar hur toodefine ett lite mer komplext neurala nätverk med flera anpassade dolda lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-351">hello following example demonstrates how toodefine a slightly more complex neural network, with multiple custom hidden layers.</span></span>  

    // Define hello input layers 
    input Pixels [10, 20];
    input MetaData [7];

    // Define hello first two hidden layers, using data only from hello Pixels input
    hidden ByRow [10, 12] from Pixels where (s,d) => s[0] == d[0];
    hidden ByCol [5, 20] from Pixels where (s,d) => abs(s[1] - d[1]) <= 1;

    // Define hello third hidden layer, which uses as source hello hidden layers ByRow and ByCol
    hidden Gather [100] 
    {
      from ByRow all;
      from ByCol all;
    }

    // Define hello output layer and its sources
    output Result [10]  
    {
      from Gather all;
      from MetaData all;
    }  

<span data-ttu-id="16c35-352">Det här exemplet visar flera funktioner i hello neurala nätverk specifikationsspråk:</span><span class="sxs-lookup"><span data-stu-id="16c35-352">This example illustrates several features of hello neural networks specification language:</span></span>  

* <span data-ttu-id="16c35-353">hello har två inkommande lager *bildpunkter* och *MetaData*.</span><span class="sxs-lookup"><span data-stu-id="16c35-353">hello structure has two input layers, *Pixels* and *MetaData*.</span></span>
* <span data-ttu-id="16c35-354">Hej *bildpunkter* layer är ett skikt som källa för två anslutning paket, med målet lager *ByRow* och *ByCol*.</span><span class="sxs-lookup"><span data-stu-id="16c35-354">hello *Pixels* layer is a source layer for two connection bundles, with destination layers, *ByRow* and *ByCol*.</span></span>
* <span data-ttu-id="16c35-355">Hej lager *samla in* och *resultatet* är målet lager i flera paket för anslutningen.</span><span class="sxs-lookup"><span data-stu-id="16c35-355">hello layers *Gather* and *Result* are destination layers in multiple connection bundles.</span></span>
* <span data-ttu-id="16c35-356">hello utdata layer *resultatet*, är en mållagret i två anslutning paket; en med hello andra nivå dolda (samla) som en mållagret och hello andra hello inkommande nivå (MetaData) som ett mål-lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-356">hello output layer, *Result*, is a destination layer in two connection bundles; one with hello second level hidden (Gather) as a destination layer, and hello other with hello input layer (MetaData) as a destination layer.</span></span>
* <span data-ttu-id="16c35-357">Hej dolda lager *ByRow* och *ByCol*, ange filtrerad anslutning med hjälp av predikatuttryck.</span><span class="sxs-lookup"><span data-stu-id="16c35-357">hello hidden layers, *ByRow* and *ByCol*, specify filtered connectivity by using predicate expressions.</span></span> <span data-ttu-id="16c35-358">Mer exakt hello nod i *ByRow* på [x, y] är anslutna toohello noder i *bildpunkter* som har hello första index koordinaten lika toohello nodens första samordna x.</span><span class="sxs-lookup"><span data-stu-id="16c35-358">More precisely, hello node in *ByRow* at [x, y] is connected toohello nodes in *Pixels* that have hello first index coordinate equal toohello node's first coordinate, x.</span></span> <span data-ttu-id="16c35-359">På liknande sätt hello nod i *ByCol på [x, y] är anslutna toohello noder i _Pixels* som har hello andra index koordinat inom ett hello nodens andra koordinat, y.</span><span class="sxs-lookup"><span data-stu-id="16c35-359">Similarly, hello node in *ByCol at [x, y] is connected toohello nodes in _Pixels* that have hello second index coordinate within one of hello node's second coordinate, y.</span></span>  

### <a name="define-a-convolutional-network-for-multiclass-classification-digit-recognition-example"></a><span data-ttu-id="16c35-360">Ange ett convolutional nätverk för multiklass-baserad klassificering: siffra recognition exempel</span><span class="sxs-lookup"><span data-stu-id="16c35-360">Define a convolutional network for multiclass classification: digit recognition example</span></span>
<span data-ttu-id="16c35-361">hello definitionen av hello följande nätverk är utformad toorecognize siffror och det visar att vissa avancerade tekniker för att anpassa en neurala nätverket.</span><span class="sxs-lookup"><span data-stu-id="16c35-361">hello definition of hello following network is designed toorecognize numbers, and it illustrates some advanced techniques for customizing a neural network.</span></span>  

    input Image [29, 29];
    hidden Conv1 [5, 13, 13] from Image convolve 
    {
       InputShape  = [29, 29];
       KernelShape = [ 5,  5];
       Stride      = [ 2,  2];
       MapCount    = 5;
    }
    hidden Conv2 [50, 5, 5]
    from Conv1 convolve 
    {
       InputShape  = [ 5, 13, 13];
       KernelShape = [ 1,  5,  5];
       Stride      = [ 1,  2,  2];
       Sharing     = [false, true, true];
       MapCount    = 10;
    }
    hidden Hid3 [100] from Conv2 all;
    output Digit [10] from Hid3 all;  


* <span data-ttu-id="16c35-362">hello-strukturen har ett enda inkommande lager *bild*.</span><span class="sxs-lookup"><span data-stu-id="16c35-362">hello structure has a single input layer, *Image*.</span></span>
* <span data-ttu-id="16c35-363">Hej nyckelordet **convolve** betyder att hello lager som heter *Conv1* och *Conv2* är convolutional lager.</span><span class="sxs-lookup"><span data-stu-id="16c35-363">hello keyword **convolve** indicates that hello layers named *Conv1* and *Conv2* are convolutional layers.</span></span> <span data-ttu-id="16c35-364">Var och en av dessa lager-deklarationer följs av en lista över hello Faltning attribut.</span><span class="sxs-lookup"><span data-stu-id="16c35-364">Each of these layer declarations is followed by a list of hello convolution attributes.</span></span>
* <span data-ttu-id="16c35-365">hello net har en tredje dolda lagret, *Hid3*, som är fullständigt ansluten toohello andra dolda lagret, *Conv2*.</span><span class="sxs-lookup"><span data-stu-id="16c35-365">hello net has a third hidden layer, *Hid3*, which is fully connected toohello second hidden layer, *Conv2*.</span></span>
* <span data-ttu-id="16c35-366">hello utdata layer *siffra*, är anslutet endast toohello tredje dolda lagret, *Hid3*.</span><span class="sxs-lookup"><span data-stu-id="16c35-366">hello output layer, *Digit*, is connected only toohello third hidden layer, *Hid3*.</span></span> <span data-ttu-id="16c35-367">Hej nyckelordet **alla** visar hello utdata lagret är helt ansluten för*Hid3*.</span><span class="sxs-lookup"><span data-stu-id="16c35-367">hello keyword **all** indicates that hello output layer is fully connected too*Hid3*.</span></span>
* <span data-ttu-id="16c35-368">hello aritet av hello Faltning är tre (hello längden på hello tupplar **InputShape**, **KernelShape**, **Stride**, och **delning**).</span><span class="sxs-lookup"><span data-stu-id="16c35-368">hello arity of hello convolution is three (hello length of hello tuples **InputShape**, **KernelShape**, **Stride**, and **Sharing**).</span></span> 
* <span data-ttu-id="16c35-369">hello antalet vikter per kernel är *1 + **KernelShape**\[0] * **KernelShape**\[1] * **KernelShape** \[2] = 1 + 1 * 5 * 5 = 26. Eller 26 * 50 = 1300*.</span><span class="sxs-lookup"><span data-stu-id="16c35-369">hello number of weights per kernel is *1 + **KernelShape**\[0] * **KernelShape**\[1] * **KernelShape**\[2] = 1 + 1 * 5 * 5 = 26. Or 26 * 50 = 1300*.</span></span>
* <span data-ttu-id="16c35-370">Du kan beräkna hello noder i varje dolda lagret på följande sätt:</span><span class="sxs-lookup"><span data-stu-id="16c35-370">You can calculate hello nodes in each hidden layer as follows:</span></span>
  * <span data-ttu-id="16c35-371">**NodeCount**\[0] = (5 - 1) / 1 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="16c35-371">**NodeCount**\[0] = (5 - 1) / 1 + 1 = 5.</span></span>
  * <span data-ttu-id="16c35-372">**NodeCount**\[1] = (13-5) / 2 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="16c35-372">**NodeCount**\[1] = (13 - 5) / 2 + 1 = 5.</span></span> 
  * <span data-ttu-id="16c35-373">**NodeCount**\[2] = (13-5) / 2 + 1 = 5.</span><span class="sxs-lookup"><span data-stu-id="16c35-373">**NodeCount**\[2] = (13 - 5) / 2 + 1 = 5.</span></span> 
* <span data-ttu-id="16c35-374">hello Totalt antal noder kan beräknas med hjälp av hello deklarerats dimensionaliteten för hello layer, [50, 5, 5], enligt följande:  ***MapCount** * **NodeCount** \[ 0] * **NodeCount**\[1] * **NodeCount**\[2] = 10 * 5 * 5 * 5*</span><span class="sxs-lookup"><span data-stu-id="16c35-374">hello total number of nodes can be calculated by using hello declared dimensionality of hello layer, [50, 5, 5], as follows: ***MapCount** * **NodeCount**\[0] * **NodeCount**\[1] * **NodeCount**\[2] = 10 * 5 * 5 * 5*</span></span>
* <span data-ttu-id="16c35-375">Eftersom **delning**[d] har värdet False för *d == 0*, hello antalet kärnor är  ***MapCount** * **NodeCount** \[0] = 10 * 5 = 50*.</span><span class="sxs-lookup"><span data-stu-id="16c35-375">Because **Sharing**[d] is False only for *d == 0*, hello number of kernels is ***MapCount** * **NodeCount**\[0] = 10 * 5 = 50*.</span></span> 

## <a name="acknowledgements"></a><span data-ttu-id="16c35-376">Bekräftelser</span><span class="sxs-lookup"><span data-stu-id="16c35-376">Acknowledgements</span></span>
<span data-ttu-id="16c35-377">hello Net # språk för att anpassa hello arkitekturen för neurala nätverk har utvecklats på Microsoft av Shon Katzenberger (systemarkitekt, Machine Learning) och Alexey Kamenev (programvara tekniker, Microsoft Research).</span><span class="sxs-lookup"><span data-stu-id="16c35-377">hello Net# language for customizing hello architecture of neural networks was developed at Microsoft by Shon Katzenberger (Architect, Machine Learning) and Alexey Kamenev (Software Engineer, Microsoft Research).</span></span> <span data-ttu-id="16c35-378">Det används internt för maskininlärning projekt och program, från avbildningen identifiering tootext analytics.</span><span class="sxs-lookup"><span data-stu-id="16c35-378">It is used internally for machine learning projects and applications ranging from image detection tootext analytics.</span></span> <span data-ttu-id="16c35-379">Mer information finns i [Neural nät i Azure ML - introduktion tooNet #](http://blogs.technet.com/b/machinelearning/archive/2015/02/16/neural-nets-in-azure-ml-introduction-to-net.aspx)</span><span class="sxs-lookup"><span data-stu-id="16c35-379">For more information, see [Neural Nets in Azure ML - Introduction tooNet#](http://blogs.technet.com/b/machinelearning/archive/2015/02/16/neural-nets-in-azure-ml-introduction-to-net.aspx)</span></span>

[1]:./media/machine-learning-azure-ml-netsharp-reference-guide/formula_large.gif

